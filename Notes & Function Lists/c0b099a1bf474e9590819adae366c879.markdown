> Анализ данных

+-----------------------------------+-----------------------------------+
| > **Анализ данных**\              | > **1**\                          |
| > (19.04.24) Лекция 4.1\          | > 2\                              |
| > (23.04.24) Лекция 4.2\          | > 16\                             |
| > Лабораторная работа №1\         | > 44\                             |
| > (26.04.24) Семинар 4.1\         | > 49\                             |
| > jupyter notebook - bike\        | > 49\                             |
| > Лабораторная работа №2\         | > 51\                             |
| > (17.05.24) Семинар 4.2\         | > 64\                             |
| > (21.05.24) Лекция 4.3\          | > 65\                             |
| > jupyter notebook - regression\  | > 97\                             |
| > (28.05.24) Лекция 4.4\          | > 100\                            |
| > jupyter notebook -              | > 111\                            |
| > classification_ed (31.05.24)    | > 112\                            |
| > Семинар 4.3\                    | > 113\                            |
| > Лабораторная работа №3\         | > 115\                            |
| > (03.06.24) Лекция 4.5\          | > 128\                            |
| > jupyter notebook - Лекция 5\    | > 129                             |
| > (07.06.24) Семинар 4.4          |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> (19.04.24) Лекция 4.1
>
> **Преподаватель**\
> Багаутдинова Эльмира Рафиковна - -
>
> **Оценки**\
> Лабораторная работа №1 - 3 балла\
> Лабораторная работа №2 - 3 балла\
> Выполнение задач курса Подготовка к НЭ по АД - 2 баллаЭкзамен - 2
> балла
>
> **Автомат:**\
> Выполнение задач курса Подготовка к НЭ по АД - 2 баллаВаша задача
> (анализ данных + модель) - 8 баллов
>
> **Data Science**\
> Наука о данных, занимающаяся изучением проблем анализа, обработки
> ипредставления данных в цифровой форме.
>
> Это наука на стыке других наук - математики, информатики, экономики,
> лингвистики,биологии и тд.
>
> **Big Data**\
> совокупность методов и технологий, которые позволяют извлекать из
> данных ранеенеизвестные, нетривиальные, практически полезные и
> доступные для интерпретациизнания, необходимых для принятия решений в
> различных сферах человеческойдеятельности.
>
> **Data Mining**\
> это процесс обнаружения в «сырых» данных ранее неизвестных,
> нетривиальных,практически полезных и доступных для интерпретации
> знаний, необходимых дляпринятия решений в различных сферах
> человеческой деятельности
>
> **Анализ данных - это...**\
> процесс поиска закономерностей в данных при помощи\
> ● средств визуализации данных,\
> ● математических методов,\
> ● программных алгоритмов
>
> **Отличительная особенность:** нет четко зафиксированного ответа на
> каждыйвходящий объект.
>
> **Что можно почитать:**\
> **Анализ данных** - основы и терминология\
> Всё, что вам нужно знать об ИИ - за несколько минут
>
> **Обзор задач анализа данных**

+-----------------------------------+-----------------------------------+
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474      |                                   |
| e9590819adae366c879/media/image1. |                                   |
| png){width="2.0513877952755903in" |                                   |
|   height="1.4472222222222222in"}  |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+===================================+===================================+
|   ----------------                | > **Точечное оценивание**         |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c                  |                                   |
| 0b099a1bf474e9590819adae366c879/m |                                   |
| edia/image2.png){width="2.0625in" |                                   |
|   height="1.4375in"}              |                                   |
|   ----------------                |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------                |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+
|   ----------------                | > **Выбросы**                     |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c                  |                                   |
| 0b099a1bf474e9590819adae366c879/m |                                   |
| edia/image3.png){width="2.0625in" |                                   |
|   height="1.4583333333333333in"}  |                                   |
|   ----------------                |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------                |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474      |                                   |
| e9590819adae366c879/media/image4. |                                   |
| png){width="2.0513877952755903in" |                                   |
|   height="1.4375in"}              |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+
|   ----------------                | > **Интервальное оценивание**     |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c                  |                                   |
| 0b099a1bf474e9590819adae366c879/m |                                   |
| edia/image5.png){width="2.0625in" |                                   |
|   height="1.4583333333333333in"}  |                                   |
|   ----------------                |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------                |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+

+-----------------------------------+-----------------------------------+
|   ----------------------------    | > **Непараметрическое             |
| --------------------------------- | > оценивание**                    |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474      |                                   |
| e9590819adae366c879/media/image6. |                                   |
| png){width="2.1041666666666665in" |                                   |
|   height="1.4805555555555556in"}  |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+===================================+===================================+
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474      |                                   |
| e9590819adae366c879/media/image7. |                                   |
| png){width="2.1041666666666665in" |                                   |
|   height="1.4694444444444446in"}  |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474      |                                   |
| e9590819adae366c879/media/image8. |                                   |
| png){width="2.1041666666666665in" |                                   |
|   height="1.4680544619422573in"}  |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474      |                                   |
| e9590819adae366c879/media/image9. |                                   |
| png){width="2.0833333333333335in" |                                   |
|   height="1.4583333333333333in"}  |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+
|   -----------------------------   | > **Статистические гипотезы,      |
| --------------------------------- | > AB-тесты**                      |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474e     |                                   |
| 9590819adae366c879/media/image10. |                                   |
| png){width="2.0930544619422573in" |                                   |
|   height="1.4791666666666667in"}  |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+

+-----------------------------------+-----------------------------------+
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474e     |                                   |
| 9590819adae366c879/media/image11. |                                   |
| png){width="2.1041666666666665in" |                                   |
|   height="1.4694444444444446in"}  |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+===================================+===================================+
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474e     |                                   |
| 9590819adae366c879/media/image12. |                                   |
| png){width="2.1041666666666665in" |                                   |
|   height="1.4680555555555554in"}  |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+
|   -----------------------------   | > **Корреляционный анализ**       |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474e     |                                   |
| 9590819adae366c879/media/image13. |                                   |
| png){width="2.1041666666666665in" |                                   |
|   height="1.4902777777777778in"}  |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474e     |                                   |
| 9590819adae366c879/media/image14. |                                   |
| png){width="2.1041666666666665in" |                                   |
|   height="1.4694444444444446in"}  |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   -----------------------------   |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+

> **Книга с похожим содержанием**
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image15.png){width="1.323611111111111in"
> height="2.1138877952755903in"}
>
> **Генеральная совокупность**\
> это полный набор всех возможных объектов или событий, имеющих
> определенныеобщие характеристики, которые подлежат исследованию. В
> статистике и методахисследования генеральная совокупность может
> включать людей, случаи заболеваний,географические точки и так далее, в
> зависимости от цели исследования.
>
> **Примеры генеральной совокупности:**\
> ● Все граждане определенной страны;\
> ● Все деревья в лесу;\
> ● Все продажи в магазине за год.
>
> **Выборка**\
> это подмножество генеральной совокупности, выбранное для наблюдения и
> анализа.
>
> Выборка используется для сбора данных и получения выводов о
> генеральнойсовокупности, когда исследование всех ее элементов
> невозможно или\
> нецелесообразно по причинам времени, стоимости или практической
> невозможности.
>
> **Примеры выборки:**\
> ● Все граждане России;\
> ● Сосны в лесу;\
> ● Продажи апельсинов в магазине за год.
>
> **Репрезентативность выборки**\
> это степень, в которой выборка адекватно отражает распределение
> характеристик вгенеральной совокупности. Репрезентативная выборка
> позволяет делать обобщения ивыводы о генеральной совокупности на
> основе анализа выборки, с минимальнойстепенью искажения и ошибок.
>
> **Вот основные критерии репрезентативности:**\
> **1.** **Соответствие размера выборки**\
> - Размер выборки должен быть достаточным для обеспечения
> статистической мощности исследования. Слишком маленькая выборка может
> привести к недостаточной точности, в то время как слишком большая - к
> избыточным затратам ресурсов.
>
> **2.** **Структурное соответствие**\
> - Структура выборки должна соответствовать структуре генеральной\
> совокупности по ключевым характеристикам (например, пол, возраст,
> социально-экономический статус). Это можно достичь через стратификацию
> или квотирование.
>
> **3.** **Географическое соответствие**\
> - Для исследований, где географическое расположение играет роль,
> выборка должна адекватно представлять различные географические регионы
> совокупности.
>
> **4.** **Временное соответствие**\
> - Выборка должна быть актуальной и отражать текущее состояние
> генеральной совокупности. Изменения во времени могут влиять на
> репрезентативность исторических данных.

+-----------------------------------+-----------------------------------+
| > **5.**\                         | > **Случайность отбора**\         |
| > -                               | > Случайный отбор участников      |
|                                   | > уменьшает риск предвзятости и   |
|                                   | > повышает                        |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> вероятность того, что выборка будет репрезентативной. Каждый
> членсовокупности должен иметь равный шанс быть включенным в выборку.
>
> **6.** **Отсутствие систематической ошибки**\
> - В процессе отбора и сбора данных должны быть минимизированы\
> систематические ошибки, такие как ошибки измерения или неполный
> отклик, которые могут исказить репрезентативность.
>
> **7.** **Анализ распределения характеристик**\
> - Проведение статистического анализа для сравнения распределений
> ключевых характеристик в выборке и генеральной совокупности может
> помочь оценить репрезентативность.

+-----------------------------------+-----------------------------------+
| > **Задание:** оценить уровень\   | ![](vertopal_c0b099a1bf474e       |
| > самооценки знаний студентов     | 9590819adae366c879/media/image16. |
| > курсаанализа данных.            | png){width="3.1888877952755905in" |
| >                                 | height="2.0833333333333335in"}    |
| > **Как правильно сделать:**\     |                                   |
| > Предположим, что мы провели     |                                   |
| > опроссреди 100 студентов курса  |                                   |
| > по анализуданных, спрашивая их  |                                   |
| > самооценкузнаний по шкале от 1  |                                   |
| > до 5, где 1 -\                  |                                   |
| > начинающий, а 5 - эксперт.      |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Частотные распределения**

+-----------------------------------+-----------------------------------+
| > это метод организации данных по | ![](vertopal_c0b099a1bf474        |
| > количествураз, которое каждое   | e9590819adae366c879/media/image17 |
| > значение встречается(частота) в | .png){width="2.676388888888889in" |
| > наборе данных. Это              | height="2.1666666666666665in"}    |
| > позволяетисследователям легко   |                                   |
| > определить или\                 |                                   |
| > визуализировать, какие значения |                                   |
| > являютсянаиболее или наименее\  |                                   |
| > распространенными.              |                                   |
| >                                 |                                   |
| > **Создание частотного           |                                   |
| > распределения** ● Определите    |                                   |
| > набор данных, который будете    |                                   |
| > анализировать.                  |                                   |
| >                                 |                                   |
| > ● Разделите данные на классы\   |                                   |
| > (интервалы). Количество классов |                                   |
| > обычно зависит от размера       |                                   |
| > набора данных.                  |                                   |
| >                                 |                                   |
| > ● Подсчитайте частоту для       |                                   |
| > каждого класса, т.е., сколько   |                                   |
| > раз каждое значение встречается |                                   |
| > в данных.                       |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Частотные распределения: Диаграммы**

+-----------------------------------+-----------------------------------+
| > **Гистограммы**\                | ![](vertopal_c0b099a1bf474        |
| > это тип диаграммы, используемый | e9590819adae366c879/media/image18 |
| > для\                            | .png){width="2.698611111111111in" |
| > представления частотного        | height="2.1458333333333335in"}    |
| > распределения.Она состоит из    |                                   |
| > прямоугольников, где            |                                   |
| > высотакаждого прямоугольника    |                                   |
| > пропорциональначастоте значений |                                   |
| > в данном интервале.             |                                   |
| >                                 |                                   |
| > ● **Применение:** Гистограммы   |                                   |
| > часто используются для          |                                   |
| > визуализации распределения      |                                   |
| > количественных данных.          |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Нормальное распределение**

+-----------------------+-----------------------+-----------------------+
| > **Закон нормального | ![](verto             |                       |
| > распределения** -   | pal_c0b099a1bf474e959 |                       |
| > этостатистический   | 0819adae366c879/media |                       |
| > закон, который      | /image19.png){width=" |                       |
| > описывает,как часто | 2.8222222222222224in" |                       |
| > различные значения  | height="1             |                       |
| > случайнойвеличины   | .6666666666666667in"} |                       |
| > встречаются в       |                       |                       |
| > наборе данных.Он    |                       |                       |
| > также известен как  |                       |                       |
| > «закон Гаусса»,     |                       |                       |
| > или«закон           |                       |                       |
| > распределения       |                       |                       |
| > Гаусса».            |                       |                       |
+=======================+=======================+=======================+
|                       |                       |                       |
+-----------------------+-----------------------+-----------------------+
| ![](vert              |                       |                       |
| opal_c0b099a1bf474e95 |                       |                       |
| 90819adae366c879/medi |                       |                       |
| a/image20.png){width= |                       |                       |
| "6.188888888888889in" |                       |                       |
| height="              |                       |                       |
| 4.395833333333333in"} |                       |                       |
+-----------------------+-----------------------+-----------------------+

> **Частотные распределения: Диаграммы**

+-----------------------------------+-----------------------------------+
| > **Столбчатые диаграммы**\       | > ![](vertopal_c0b099a1bf474e     |
| > Столбчатая диаграмма похожа на\ | 9590819adae366c879/media/image21. |
| > гистограмму, но используется    | png){width="2.6041666666666665in" |
| > для\                            | > height="2.1041666666666665in"}  |
| > категориальных данных. Каждый   |                                   |
| > столбецпредставляет категорию,  |                                   |
| > и его высотаотражает частоту    |                                   |
| > или процент даннойкатегории в   |                                   |
| > наборе данных.                  |                                   |
| >                                 |                                   |
| > **Применение:** Столбчатые●\    |                                   |
| > диаграммы идеально подходят     |                                   |
| > длясравнения количества или\    |                                   |
| > процентного соотношения         |                                   |
| > междукатегориями.               |                                   |
+===================================+===================================+
| > **Круговые диаграммы**\         | > ![](vertopal_c0b099a1bf474e     |
| > Круговая диаграмма показывает\  | 9590819adae366c879/media/image22. |
| > относительную частоту каждой    | png){width="2.6458333333333335in" |
| > категории ввиде секторов круга, | > height="1.9486100174978127in"}  |
| > где размер                      |                                   |
| > секторапропорционален частоте   |                                   |
| > категории.                      |                                   |
| >                                 |                                   |
| > ● **Применение:** Круговые      |                                   |
| > диаграммы хорошо подходят для   |                                   |
| > демонстрации доли каждой        |                                   |
| > категории от целого, особенно   |                                   |
| > когда категорий не\             |                                   |
| > слишком много.                  |                                   |
+-----------------------------------+-----------------------------------+

> **Меры центральной тенденции**\
> **Среднее значение (арифметическое среднее)/Математическое
> ожидание**Среднее значение является наиболее широко используемой мерой
> центральнойтенденции. Оно рассчитывается путем суммирования всех
> значений в наборе данныхи деления полученной суммы на количество
> значений.
>
> **Формула:**\
> X - значение каждого наблюдения, а n - количество наблюдений в наборе
> данных.

  ---------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image23.png){width="2.75in"
  height="0.625in"}
  ---------------------------------------------------------------------------------

  ---------------------------------------------------------------------------------

> **Медиана**\
> **Медиана** - это значение, которое делит упорядоченный набор данных
> на две равныечасти. Если количество значений в наборе нечетное,
> медианой будет значение,находящееся посередине. Если количество
> значений четное, медианой будет среднеезначение двух центральных
> чисел.
>
> **Мода**\
> **Мода** - это значение в наборе данных, которое встречается чаще
> всего. Набор данныхможет иметь одну моду, несколько мод или не иметь
> моды вовсе, если все значенияуникальны.

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image24.png){width="4.761111111111111in"
  height="3.0305555555555554in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image25.png){width="5.980555555555555in"
  height="1.9902777777777778in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

> **Меры вариативности**\
> **Меры вариативности (или меры разброса)** - это статистические
> показатели,описывающие степень разнообразия или разброса значений в
> наборе данных. Ониважны для понимания общего характера распределения
> данных, так как позволяютоценить, насколько данные отличаются друг от
> друга и от среднего значения.
>
> **Основные меры вариативности**\
> **1.** **Размах**\
> **Размах** - это самая простая мера вариативности, представляющая
> собой разницу между максимальным и минимальным значениями в наборе
> данных.
>
> **Формула:** Размах = Максимальное значение - Минимальное значение

  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image26.png){width="2.6861100174978128in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image27.png){width="2.686111111111111in"
  height="1.625in"}                                                                               height="1.5944433508311462in"}
  ----------------------------------------------------------------------------------------------- ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

+-----------------------------------+-----------------------------------+
| **2.**                            | > **Дисперсия**                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Дисперсия** - это мера, показывающая средний квадрат отклонений
> значений внаборе данных от их среднего значения. Она дает
> представление о том,насколько данные разбросаны вокруг
> среднего/математического ожидания.

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image28.png){width="2.948611111111111in"
  height="1.2083333333333333in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

+-----------------------------------+-----------------------------------+
| **3.**                            | > **Стандартное отклонение**      |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Стандартное отклонение** - это корень квадратный из дисперсии. Это
> наиболеешироко используемая мера вариативности, так как она выражена в
> тех жеединицах измерения, что и исходные данные, что облегчает
> интерпретацию.

+-----------------------------------+-----------------------------------+
| > ![](vertopal_c0b099a1bf474e     | > ![](vertopal_c0b099a1bf474e     |
| 9590819adae366c879/media/image29. | 9590819adae366c879/media/image30. |
| png){width="1.3527777777777779in" | png){width="2.4069444444444446in" |
| > height="0.5111100174978128in"}  | > height="1.1986100174978127in"}  |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **4.** **Квартили и интерквартильный размах**

+-----------------------------------+-----------------------------------+
| > **Квартили** - это значения,    | > В нормально                     |
| > которые делятупорядоченный      | > распределенныхданных            |
| > набор данных на четыреравные    | > соотношение междуIQR и SD может |
| > части. Самыми важными           | > быть\                           |
| > являютсяпервый квартиль (Q1),   | > приблизительно\                 |
| > медиана или второйквартиль      | > фиксированным, потому чтоформа  |
| > (Q2), и третий квартиль (Q3).   | > распределения\                  |
| >                                 | > определена стандартным\         |
| > **Интерквартильный размах       | > отклонением. В таких случаяхIQR |
| > (IQR)** - эторазность между     | > примерно равен 1.35 SD.         |
| > третьим и первым\               |                                   |
| > квартилями и описывает разброс  |                                   |
| > средних50% данных.              |                                   |
| >                                 |                                   |
| > **Формула:** IQR = Q3 - Q1      |                                   |
+===================================+===================================+
|   -----------------------------   |   -----------------------------   |
| --------------------------------- | --------------------------------- |
| --------------------------------- | --------------------------------- |
|   ![](vertopal_c0b099a1bf474e     |   ![](vertopal_c0b099a1bf474e     |
| 9590819adae366c879/media/image31. | 9590819adae366c879/media/image32. |
| png){width="2.4791666666666665in" | png){width="1.8430544619422573in" |
|   height="1.7402766841644794in"}  |   height="1.9791666666666667in"}  |
|   -----------------------------   |   -----------------------------   |
| --------------------------------- | --------------------------------- |
| --------------------------------- | --------------------------------- |
|                                   |                                   |
|   -----------------------------   |   -----------------------------   |
| --------------------------------- | --------------------------------- |
| --------------------------------- | --------------------------------- |
+-----------------------------------+-----------------------------------+

+-----------------------------------+-----------------------------------+
| **5.**                            | > **Сравните разброс (стандартное |
|                                   | > отклонение) в выборках**        |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

  ---------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image33.png){width="5.75in"
  height="3.8125in"}
  ---------------------------------------------------------------------------------

  ---------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image34.png){width="5.740277777777778in"
  height="3.073610017497813in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

> **Z-оценка и выбросы**\
> **Z-оценка**\
> **Z-оценка (стандартное отклонение)** - это мера, показывающая,
> насколько далекоконкретное значение находится от среднего значения
> генеральной совокупности иливыборки, выраженное в единицах
> стандартного отклонения.

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image35.png){width="3.9069444444444446in"
  height="1.5305544619422573in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Интерпретация Z-оценок**\
> ● Z-оценка **равная 0** указывает, что значение переменной совпадает
> со средним значением.
>
> ● Z-оценка **больше 0** говорит о том, что значение переменной выше
> среднего.
>
> ● Z-оценка **меньше 0** означает, что значение переменной ниже
> среднего.
>
> ● Значения Z-оценки, которые **выходят за пределы ±2** (или **±3** для
> более строгой оценки), часто рассматриваются как выбросы.
>
> **Выбросы**\
> **Выбросы** - это значения данных, которые сильно отличаются от
> большинства другихзначений в наборе данных. Выбросы могут возникать по
> разным причинам, включаяошибки ввода данных, ошибки измерения или они
> могут быть результатом\
> естественного разнообразия в данных.
>
> **Обнаружение выбросов**\
> ● **Графический метод:** Использование ящиков с усами (box plot),
> гистограмм и диаграмм рассеивания для визуального обнаружения
> выбросов.
>
> ● **Статистический метод:** Использование Z-оценок для идентификации
> выбросов. Значения, Z-оценка которых выходит за пределы ±2 или ±3,
> могут рассматриваться как выбросы.

+-----------------------------------+-----------------------------------+
| > ![](vertopal_c0b099a1bf474e     | > ![](vertopal_c0b099a1bf474      |
| 9590819adae366c879/media/image36. | e9590819adae366c879/media/image37 |
| png){width="2.1555544619422573in" | .png){width="2.948611111111111in" |
| > height="2.3013877952755903in"}  | > height="2.322221128608924in"}   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e       | > ![](vertopal_c0b099a1bf474e     |
| 9590819adae366c879/media/image38. | 9590819adae366c879/media/image39. |
| png){width="2.7277766841644793in" | png){width="2.6444444444444444in" |
| height="2.0527777777777776in"}    | > height="1.9791666666666667in"}  |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Корреляция**\
> **Корреляция** - это статистический инструмент, который измеряет
> степень и\
> направление взаимосвязи между двумя переменными. В контексте анализа
> данныхкорреляция помогает понять, как один признак может изменяться в
> ответ на изменениедругого.
>
> **Коэффициент корреляции**\
> Коэффициент корреляции Пирсона варьируется от -1 до 1: ● 1 означает
> идеальную положительную корреляцию, ● 0 означает отсутствие
> корреляции,\
> ● -1 означает идеальную отрицательную корреляцию.
>
> **Интерпретация корреляции**\
> Коэффициент корреляции указывает не только на силу связи, но и на ее
> направление: ● **Положительная корреляция:** когда одна переменная
> увеличивается, другая также увеличивается.
>
> ● **Отрицательная корреляция:** когда одна переменная увеличивается,
> другая уменьшается.
>
> **Ограничения корреляции**\
> Корреляция не подразумевает причинно-следственную связь и может
> бытьподвержена проблеме \"ложной корреляции\", когда две переменные
> связаны черезтретью, неучтенную переменную.
>
> **Регрессия**

+-----------------------------------+-----------------------------------+
| > **Регрессионный анализ** - это  | > ![](vertopal_c0b099a1bf474e     |
| > методмоделирования взаимосвязи  | 9590819adae366c879/media/image40. |
| > междузависимой (целевой) и      | png){width="3.1555555555555554in" |
| > одной илинесколькими            | > height="1.7708333333333333in"}  |
| > независимыми\                   |                                   |
| > (предикторами) переменными.     |                                   |
| >                                 |                                   |
| > **Цель регрессии** -            |                                   |
| > предсказать\                    |                                   |
| > значения зависимой переменной   |                                   |
| > илипонять характер              |                                   |
| > взаимосвязей\                   |                                   |
| > между переменными.              |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Линейная регрессия**\
> Линейная регрессия ищет линейную связь между переменными. Простая
> линейнаярегрессия включает две переменные и описывается
> уравнением:![](vertopal_c0b099a1bf474e9590819adae366c879/media/image42.png){width="6.936111111111111in"
> height="6.168903105861768in"}
>
> **Множественная регрессия**\
> В множественной регрессии зависимая переменная моделируется на
> основенескольких независимых переменных.
>
> Уравнение может быть расширено до формы:
>
> **Линия тренда и предсказание значений признака**

+-----------------------------------+-----------------------------------+
| > **Линия тренда** в              |                                   |
| > регрессионном анализепоказывает |                                   |
| > общую тенденцию данных.         |                                   |
| > Этоможет быть линия, наилучшим  |                                   |
| > образомописывающая данные на    |                                   |
| > диаграмме\                      |                                   |
| > рассеивания. Линия тренда       |                                   |
| > используетсядля предсказания    |                                   |
| > будущих значений.               |                                   |
| >                                 |                                   |
| > Например, зная угловой          |                                   |
| > коэффициент иинтерцепт, можно   |                                   |
| > предсказать значение yдля       |                                   |
| > нового значения x               |                                   |
+===================================+===================================+
| ![](vertopal_c0b099a1bf474        |                                   |
| e9590819adae366c879/media/image41 |                                   |
| .png){width="6.102777777777778in" |                                   |
| height="3.073611111111111in"}     |                                   |
+-----------------------------------+-----------------------------------+

> (23.04.24) Лекция 4.2
>
> **Что такое искусственный интеллект?**
>
> ● **Искусственный интеллект** - свойство интеллектуальных систем
> выполнять творческие функции, которые традиционно считаются
> прерогативой человека ○ **Машинное обучение** - обучение за счет
> применения решений\
> множества сходных задач\
> **Глубокое обучение** - нелинейные преобразования и модельные■\
> абстракции высокого уровня на больших базах данных
>
> **Искусственный интеллект** - это научная область, которая занимается
> разработкойинтеллектуальных компьютерных систем, то есть систем,
> обладающих возможностями,которые мы традиционно связываем с
> человеческим разумом - понимание языка,обучение, способность
> рассуждать, решать проблемы и т.д.
>
> **Машинное обучение**\
> - Раздел искусственного интеллекта, очень важный, но не единственный,
> который представляет собой науку и искусство программирования
> компьютеров для того, чтобы они могли обучаться решению различных
> задач на основе данных.
>
> \- Представлен в 1959 г. **Артуром Самуэлем**.
>
> \[**Машинное обучение** - это\] научная дисциплина, которая наделяет\
> компьютеры способностью учиться, не будучи явно запрограммированными.
>
> \- В 1997 г. **Том М. Митчелл** предоставил формальное
> **определение**\
> **алгоритмов**, в области машинного обучения:\
> «Говорят, что компьютерная программа учится на опыте E в отношении
> некоторого класса задач T и показателя производительности P, если ее
> производительность по задачам в T , измеренная P , улучшается с опытом
> E \".
>
> \- Первое приложение, которое формально классифицируется как
> приложение с МО и которое действительно получило широкое
> распространение, увидело свет еще в 1990-х годах: это был фильтр
> спама.
>
> \- **Артур Самуэль** (5 декабря 1901 - 29 июля 1990) был пионером в
> области компьютерных игр, искусственного интеллекта и машинного
> обучения.
>
> Его программа **Checkers-playing** - одна из первых самообучающихся
> программв мире, и является одной из первых демонстраций базовых
> понятий\
> искусственного интеллекта.
>
> \- **Том Митчелл** (9 августа 1951) - американский ученый, профессор
> Университета Карнеги-Меллон, основатель первой в мире кафедры
> машинного обучения и автор первого учебника по этому предмету.
>
> **Этапы развития ИИ и машинного обучения**

+-----------------------------------+-----------------------------------+
| > **1.**\                         | > Простейшие алгоритмы (1950-е)\  |
| > **2.**\                         | > Байесовские методы (1960-е)\    |
| > **3.**\                         | > Время сомнений в ИИ (1970-е)\   |
| > **4.**\                         | > Возрождение(1980-е)\            |
| > **5.**\                         | > Data-driven approach (1990-е)\  |
| > **6.**\                         | > Алгоритмы обучения с учителем   |
| > **7.**                          | > (2000-е)Глубокое обучение       |
|                                   | > (2010-е)                        |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Начало исследований в области ИИ - 50-ые годы 20 века**\
> - **Алан Тьюринг** \"Вычислительные машины и разум\"\
> - **Проблема** \"может ли машина мыслить?\"\
> - **Тест Тьюринга:** «Человек взаимодействует с одним компьютером и
> одним человеком. На основании ответов на вопросы он должен определить,
> с кем он разговаривает: с человеком или компьютерной программой.
> Задача\
> компьютерной программы --- ввести человека в заблуждение, заставив
> сделать неверный выбор».
>
> **ИИ Google Lamda, который называет себя Человеком**

  --------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image43.png){width="6.0in"
  height="2.625in"}
  --------------------------------------------------------------------------------

  --------------------------------------------------------------------------------

> **Разочарование в ИИ**\
> Во время холодной войны правительство США было особенно заинтересовано
> вавтоматическом, мгновенном переводе русских документов и научных
> докладов.Однако в своем отчете 1966 года комитет по автоматической
> обработке языков пришелк выводу, что машинный перевод оказался более
> дорогим, менее точным и болеемедленным, чем человеческий перевод.
> Потратив около 20 миллионов долларов,комитет свернул все разработки.
>
> **Причина:**\
> «the spirit is willing but the flesh is weak» (дух желает, но плоть
> слаба) при переводе нарусский и потом обратно на английский
> превратилась в «the vodka is good but the meat is rotten» (водка
> хорошая, но мясо гнилое), «out of sight, out of mind» (с глаз долой,
> изсердца вон) - в «blind idiot» (слепой идиот).
>
> В 1973 году в британском парламенте был представлен отчет профессора
> ДжеймсаЛайтхилла о состоянии исследований искусственного интеллекта в
> Великобритании.Его отчет описывал полную неспособность искусственного
> интеллекта достичь своих«грандиозных целей» - все то, что может делать
> ИИ, может быть сделано другиминауками, иногда лучше, быстрее и
> дешевле.
>
> Отчет Лайтхилла привел к прекращению большинства исследований в сфере
> ИИ вВеликобритании. Это привело к сокращению финансирования разработок
> ИИ по всейЕвропе.
>
> **Причина:**\
> особый упор в отчете был сделан на проблему «комбинаторного взрыва»
> (резкогороста временной сложности алгоритма при увеличении размера
> входных данных),которая показывала, что большинство самых успешных
> алгоритмов ИИ годились лишьдля решения «игрушечных» задач, а на
> реальных практических задачах они неработали
>
> **Возможности ИИ**

+-----------------------------------+-----------------------------------+
| > 1.\                             | > Image recognition\              |
| > 2.\                             | > Customization\                  |
| > 3.\                             | > Voice recognition\              |
| > 4.\                             | > Data analysis\                  |
| > 5.\                             | > Optical recognition\            |
| > 6.                              | > Memory data                     |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Цифровой след**\
> *Цифровой след обычного человека* - годовой объем данных, создаваемых
> в мире надушу населения.
>
> Цифровой след человечества по данным компании IDC (International Data
> Corporation):

+-----------------------------------+-----------------------------------+
| > ●\                              | > 2003 год - 5 эксабайтов данных  |
| > ●\                              | > (1 ЭБ = 1 млрд гигабайтов).     |
| > ●\                              | >                                 |
| > ●\                              | > 2005 год - 130 эксабайт\        |
| > ●\                              | > 2008 год - 0,18 зеттабайта (1   |
| > ●\                              | > ЗБ = 1024 эксабайта) 2011 год - |
| > ●                               | > 1,76 зеттабайта\                |
|                                   | > 2013 год - 4,4 зеттабайта.      |
|                                   | >                                 |
|                                   | > В мае 2015 года глобальное      |
|                                   | > количество данных превысило 6,5 |
|                                   | > зеттабайта.                     |
|                                   | >                                 |
|                                   | > К 2020 году, по прогнозам,      |
|                                   | > человечество сформирует 40-44   |
|                                   | > зеттабайтов                     |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> информации.
>
> Естественно возникает потребность не только хранить, но и извлекать из
> этих данныхполезную информацию, обрабатывать и анализировать ее.
>
> **Big Data**\
> **●** **Volume**\
> - **Объем** - накопленная база данных представляет собой большой объем
> информации, который трудоемко обрабатывать и хранить традиционными
> способами, для них требуются новый подход и усовершенствованные
> инструменты
>
> **●** **Velocity**\
> - **Скорость** - данный признак указывает как на увеличивающуюся
> скорость накопления данных, так и на скорость обработки данных, в
> последнее время стали более востребованы технологии обработки данных в
> реальном времени.
>
> **●** **Variety**\
> - **Многообразие** - возможность одновременной обработки
> структурированных и неструктурированных разноформатных данных.

На сегодняшний день 80% данных входит в группу неструктурированных.

> **ИИ в прикладной сфере**\
> **IBM Watson (2006)**

+-----------------------+-----------------------+-----------------------+
| > **Суперкомпьютер с  | > **Watson Studio**\  | > **Watson SDK**\     |
| > ИИ**\               | > Построение          | > Доступ к\           |
| > Понимать вопросы,\  | > моделеймашинного    | >                     |
| > сформулированные    | > обучения            |  интернет-сервисамIBM |
| > на\                 |                       | > Watson              |
| > естественном языке, |                       |                       |
| > и находитьна них    |                       |                       |
| > ответы с помощью ИИ |                       |                       |
+=======================+=======================+=======================+
| > **Стадии**          | > **IBM Watson        | > **Применение**      |
| >                     | > Health** - анализ\  | >                     |
| > \- исследование     | > текстовой\          | > \- онкология        |
| > вопроса;            | > информации          | >                     |
| >                     | > (электронные        | > \- ортопедия        |
| > \- первичный поиск  | > карты)\             | >                     |
| > и                   | > -\                  | > \- геномные         |
| >                     | > графические         |                       |
| > генерацию гипотез;  | > медицинские данные  | заболевания           |
| >                     |                       |                       |
| > \- фильтрацию       |                       | > \- кожные           |
| > результатов;        |                       |                       |
| >                     |                       | заболевания           |
| > \- выборку фактов и |                       |                       |
| > анализ              |                       | > \- создание новых   |
| >                     |                       |                       |
| > их качества;        |                       | лекарств              |
| >                     |                       |                       |
| > \- объединение      |                       |                       |
| > результатов и       |                       |                       |
| >                     |                       |                       |
| > их оценку.          |                       |                       |
+-----------------------+-----------------------+-----------------------+

> **Google Deepmind (2010)**

+-----------------------+-----------------------+-----------------------+
| > **Демис             | > **Универсальный     | > **AlphaFold**\      |
| > Хассабис**великий   | > ИИ**\               | > точное\             |
| > интеллект,который   | > Мы нуждаемся в      | > прогн               |
| > создал\             | > экспоненциальном\   | озированиетрехмерных\ |
| > великий интеллект   | > улучшении           | > моделей             |
|                       | > человеческого       | > белковыхструктур    |
|                       | > поведения илив      |                       |
|                       | > экспоненциальном    |                       |
|                       | > улучшении\          |                       |
|                       | > технологий, и мир   |                       |
|                       | > не выглядит так,    |                       |
|                       | > какбудто он         |                       |
|                       | > действует по        |                       |
|                       | > первому принципу.   |                       |
+=======================+=======================+=======================+
| > **WaveNet**\        | > **AlphaGo**\        | > **Open Source**     |
| > естественное\       | > сильнейший игрок в  |                       |
| > звучание\           | > го в истории\       |                       |
| > нечеловеческойречи  | > победил мирового    |                       |
|                       | > чемпиона игры в го  |                       |
+-----------------------+-----------------------+-----------------------+

> **Medymatch technology MAXQ-AI (2016)**

+-----------------------------------+-----------------------------------+
| > **Accipio**\                    | > **Помощь врачам** - выявляет    |
| > Бренд для программногопакета    | > признаки                        |
| > MaxQ AI                         | > внутричерепныхкровоизлияний,    |
|                                   | > которые трудно диагностировать  |
|                                   | > толькопри стандартном анализе   |
|                                   | > данных визуализации             |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Ориентация на пациента**\
> **AliveCor**\
> - ЭКГ в домашних условия на экране смартфона
>
> **Sensely**\
> - пятиминутный опрос пациентов о том, как они себя чувствуют.
>
> \- приложение распознает речь и общается с пациентами сопереживающим
> голосом.
>
> \- полученная информация оформляется в медицинскую запись, доступ к
> которой имеют только сотрудники медицинских учреждений
>
> **Mendel.ai**\
> - понимает естественный язык, на котором написана медицинская карта
> пациента и описаны испытания на сайте\
> - с помощью обученной нейросети предлагает подходящие варианты.
>
> \- онкологические больные бесплатно получают лечение, которое будет
> доступно через несколько лет
>
> **В отделениях реанимации и интенсивной терапии**\
> *Университет Сан-Франциско, Университет Дьюка, Госпиталь Джона
> Хонкинса*
>
> Прогноз развития сепсиса по ряду параметров (АД, частота сердечных
> сокращений,температура тела, частоты дыхания, SpO2, количество
> лейкоцитов, возраст пациентаи другие параметры)
>
> Удалось снизить уровень смертности в стационаре на ≥12%
>
> *Корея, 2019*\
> Прогноз внезапной остановки сердца
>
> **Реабилитация больных**\
> **Интернет вещей (IoT)**\
> **Intrabody networks** - управление из макро мира наноустройствами
> внутри человека
>
> **Поиск и найм персонала**\
> *Sever.ai (IT-холдинг TalentTech)*\
> Главного врача Центральной районный больницы Вологодской области
> наняли спомощью ИИ. По заявлению авторов разработки - впервые в России
> ее использовалидля поиска и трудоустройства специалиста такой
> компетенции. (2019)
>
> 1\. На первом этапе проскринили 295 резюме, размещенных соискателями
> из Вологодской области -- подходящих не нашлось.
>
> 2\. На втором этапе -- искали врача в соседних регионах.
>
> 3\. Далее робот звонил кандидатам и отсеивал их, если резюме совпадало
> менее чем на 75% с заявленными требованиями работодателя.
>
> Специалист с релевантным опытом нашелся в Ярославле.
>
> Он прошел интервью и был утвержден на должность в департамента
> здравоохраненияобласти, после чего релоцировался и приступил к работе.
>
> **●** **Прочитывает**\
> - Сам прочитывает текст и оценивает его, например, оценивает резюме и
> определяет насколько оно подходит к вакансии
>
> **●** **Коммуницирует**\
> - Отправляет СМС, звонит, задает вопросы, обрабатывает ответы, в
> зависимости от сценария приглашает на встречу, либо на видеоинтервью
>
> **●** **Проводит видеоинтервью**\
> - Записывает видеоинтервью, анализирует, оценивает по голову,
> видеоряду, и смысл ответов по тексту
>
> **Какие задачи решает ИИ?**
>
> **Магазины знают о нас все**\
> - **Прогнозная аналитика** - разработка стратегии эффективного
> продвижения товаров или услуг.
>
> \- Система прогнозирования беременности (pregnancy prediction system),
> разработанная аналитиком компании Target Эндрю Полом.
>
> \- Работает с покупательскими привычками и поведением в целом. В
> расчет принимается каждый совершаемый вами шаг: расплачиваетесь ли вы
> кредиткой, открываете e-mail с предложением скидки или звоните на
> линию обслуживания.
>
> \- Все это регистрируется в системе сбора и анализа данных; каждый
> покупатель имеет уникальный идентификатор в такой системе.
>
> \- В частности, проанализировав покупательские привычки беременных
> женщин, аналитиками была разработана система прогнозирования
> беременности.
>
> **Анализ тональности текста**

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image44.png){width="3.261111111111111in"
  height="1.8847211286089238in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image45.png){width="2.5944444444444446in"
  height="1.0305555555555554in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Еще задачи**

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image46.png){width="2.3958333333333335in"
  height="1.0527766841644794in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Особенности**\
> ● Везде очень сложные неявные зависимости\
> ● Нельзя выразить данные зависимости формулой\
> ● Но есть некоторое число примеров, на которых ответ известен
> (например, тексты с известным эмоциональным окрасом)

+-----------------------------------+-----------------------------------+
| ●                                 | > Поэтому будем приближать        |
|                                   | > зависимости, используя примеры  |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **МО подходит для задачи, если**\
> ● существующие решения задачи требуют большого объема ручной настройки
> или длинных списков правил - один алгоритм МО часто способен упростить
> код и выполняться лучше\
> ● традиционный подход вообще не предлагает хороших решений - лучшие
> приемы МО могут найти решение

+-----------------------------------+-----------------------------------+
| > ●\                              | > изменяющиеся среды - система МО |
| > ●                               | > способна адаптироваться к новым |
|                                   | > даннымработа с крупными         |
|                                   | > объемами данных                 |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image47.png){width="2.9361100174978128in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image48.png){width="2.977777777777778in"
  height="1.958332239720035in"}                                                                   height="2.083332239720035in"}
  ----------------------------------------------------------------------------------------------- ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> **Общепринятые сокращения:**

+-----------------------------------+-----------------------------------+
| > ●\                              | > ИИ, AI - искусственный          |
| > ●\                              | > интеллект (англ. Artificial     |
| > ●\                              | > Intelligence)\                  |
| > ●\                              | > ML - Машинное обучение (англ.   |
| > ●                               | > Machine Learning)\              |
|                                   | > DL - Глубокое обучение (англ.   |
|                                   | > Deep Learning)\                 |
|                                   | > DS - Наука о данных (англ. Data |
|                                   | > Science)\                       |
|                                   | > EDA - Разведочный анализ данных |
|                                   | > (англ. Exploratory Data         |
|                                   | > Analysis)                       |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Кривая гартнера**

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image49.png){width="5.219444444444444in"
  height="4.093055555555556in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

> **Творческие способности ИИ**\
> Text2Image. Генерация изображений по текстовому описанию

+-----------------------+-----------------------+-----------------------+
| > Модель DALL-E 2     | > Модель RuDALL-E     | ![](verto             |
|                       |                       | pal_c0b099a1bf474e959 |
| ![](verto             | ![](verto             | 0819adae366c879/media |
| pal_c0b099a1bf474e959 | pal_c0b099a1bf474e959 | /image52.png){width=" |
| 0819adae366c879/media | 0819adae366c879/media | 1.9361111111111111in" |
| /image50.png){width=" | /image51.png){width=" | height="              |
| 1.9361100174978128in" | 1.9361100174978128in" | 1.948611111111111in"} |
| height="              | height="              |                       |
| 1.948611111111111in"} | 1.948611111111111in"} |                       |
+=======================+=======================+=======================+
+-----------------------+-----------------------+-----------------------+

> **Применение ML в жизни**\
> - Применение ИИ в бизнесе, науке и повседневной жизни - применение
> технологий машинного обучения (machine learning)\
> - Эти технологии подразумевают извлечение знаний из огромных массивов
> информации (наборов данных, или по-английски dataset --- датасетов).
>
> Принцип работы алгоритма машинного обучения: по большому количеству-\
> примеров вида вход - выход настраивают алгоритм, который сможет по
> входупредсказывать выход.

+-----------------------------------+-----------------------------------+
| \-                                | > Процесс настройки алгоритма     |
|                                   | > называется обучением            |
|                                   | > (learning).                     |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Автоматизация**\
> вид входных и выходных данных всегда один и тот же, однако четкого
> алгоритмаполучения результата не существует\
> - Отзывы. ИИ успешно сортирует отзывы о продукте, категоризирует их,
> собирает статистику и выделяет негативные отзывы, требующие срочного
> ответа.
>
> \- Модерация комментариев\
> - Скорость и внимание водителя\
> - Организация хранения документов и для их обработки.
>
> \- Чат-боты, заменяющие сотрудников контакт-центра, отвечающих на
> обращения клиентов в контакт-центр.
>
> **Прогнозирование**\
> Ответ неизвестен, но его можно предположить на основе исторических
> данных - задачи кредитного скоринга,\
> - прогнозирование оттока клиентов,\
> - прогнозирование страховых рисков,\
> - прогнозирования спроса на товары и услуги,
>
> **Пример.** Рестораны могут с высокой точностью предсказать количество
> заказов наследующий день/дни и оптимизировать закупки продуктов, а
> курьерские службы итакси --- выводить на линию оптимальное количество
> сотрудников.
>
> **Рекомендательные системы** - алгоритмы, прогнозирующие, какие\
> товары/фильмы/продукты будут интересны клиенту, и маркетинговые
> инструменты,позволяющие предсказать, на какой баннер клиент более
> вероятно кликнет.
>
> **Кейсы**\
> **Кредитный скоринг**\
> Уже сейчас при принятии решения для подавляющего количества кредитов\
> используется ИИ, а к концу 2022 года ИИ будет выдавать все кредиты в
> банке. Дляэтого алгоритм будет анализировать кредитную историю клиента
> и информацию о егодоходах и тратах.
>
> **Agro AI**\
> **Перед агробизнесом стоит ряд задач:**\
> - Как повысить урожайность хозяйств;\
> - Как купить или арендовать хорошее поле;\
> - Как увеличить посевную площадь;\
> - Как оценить спрос и предложение.
>
> **AI-оценщик поля** - проверка поля перед покупкой;\
> **AI-агроном** - прогноз урожайности и корректировка сельхозработ;
> **AI-аналитик** - ежемесячный аналитический отчет по регионам
> РФ;**Мониторинг границ поля** - определение фактических границ полей.
>
> **Борьба с мошенничеством**\
> **Робот-юрист**\
> **Чат-боты (DialoGPT)** - сценарии, нельзя оскорблять
> пользователяСнижение аварийности на транспорте с помощью компьютерного
> зрения![](vertopal_c0b099a1bf474e9590819adae366c879/media/image53.png){width="3.25in"
> height="2.016797900262467in"}
>
> **ИИ активно применяется в следующих сферах:**\
> ● промышленность: , , ;\
> ● торговля: , ;\
> ● медицина:\
> ,\
> ;\
> ● транспорт: ;\
> ● ,
>
> **Условия применения МО**\
> **Данные**\
> - Наличие данных\
> - Возможность доступа к ним
>
> **Ресурсы**\
> - Вычислительные мощности
>
> **Специалисты**\
> - Нужны ли дата-саентисты?
>
> \- Понимание предметной области
>
> **Метрики**\
> - Оценка качества моделей МО\
> - Достижение хороших показателей на метриках МО не приводит к прорыву
> в бизнесе
>
> **Методология управления проектами МО (CRISP-DM)**

+-----------------------------------+-----------------------------------+
|                                   | > Бизнес анализ (Business         |
|                                   | > Understanding)Анализ данных     |
|                                   | > (Data Understanding)Подготовка  |
|                                   | > данных (Data                    |
|                                   | > Preparation)Моделирование       |
|                                   | > (Modeling)\                     |
|                                   | > Оценка решения (Evaluation)\    |
|                                   | > Внедрение (Deployment)          |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image54.png){width="4.980555555555555in"
  height="2.7291666666666665in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

> **Машинное обучение** - это процесс автоматического построения
> некоторого алгоритмарешения задачи на основе данных\
> **Направления**\
> **●** **Обучение с учителем**\
> ○ Объекты\
> ○\
> Признаки ○ Ответы\
> ○ **Решить задачу:**\
> Подобрать такой алгоритм, который может **по признакам** для каждого
> объекта **предсказать ответ**

+-----------------+-----------------+-----------------+-----------------+
| **●**           | ○               | > **Класс       |                 |
|                 |                 | > задачи** - от |                 |
| **●**           |                 | > типа ответа   |                 |
+=================+=================+=================+=================+
|                 | ■               |                 | > Регрессия     |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Классификация |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Ранжирование  |
+-----------------+-----------------+-----------------+-----------------+
|                 | > **Обучение с  |                 |                 |
|                 | >               |                 |                 |
|                 | подкреплением** |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ○               | > Action        |                 |
|                 |                 | > →Reward       |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | > **Обучение    |                 |                 |
|                 | > без учителя** |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ○               | > Объекты       |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ○               | > Признаки      |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | **○**           | > **Решить      |                 |
|                 |                 | > задачу**      |                 |
+-----------------+-----------------+-----------------+-----------------+

> Подобрать алгоритм, который может **по признакам:**

+-----------------------+-----------------------+-----------------------+
| ○                     | ■                     | > Разделять объекты   |
+=======================+=======================+=======================+
|                       | ■                     | > Уменьшать           |
|                       |                       | > количество исходных |
|                       |                       | > признаков           |
+-----------------------+-----------------------+-----------------------+
|                       | ■                     | > Искать              |
|                       |                       | > закономерности      |
+-----------------------+-----------------------+-----------------------+
|                       | > **Класс задачи** -  |                       |
|                       | > от бизнес цели      |                       |
+-----------------------+-----------------------+-----------------------+
|                       | ■                     | > Кластеризация       |
+-----------------------+-----------------------+-----------------------+
|                       | ■                     | > Понижение           |
|                       |                       | > размерности         |
+-----------------------+-----------------------+-----------------------+
|                       | ■                     | > Ассоциации          |
+-----------------------+-----------------------+-----------------------+

> **Обучение:** Из множества доступных алгоритмов выбрать такой алгоритм
> решениязадачи, который минимизирует ошибку предсказания

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image55.png){width="3.948611111111111in"
  height="3.0319444444444446in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

> **Машинное обучение**

+-----------------+-----------------+-----------------+-----------------+
| **●**           | > **Обучение с  |                 |                 |
|                 | > учителем**    |                 |                 |
| **●**           |                 |                 |                 |
|                 |                 |                 |                 |
| **●**           |                 |                 |                 |
+=================+=================+=================+=================+
|                 | **○**           | > **Регрессия** |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | >               |
|                 |                 |                 | Прогнозирование |
|                 |                 |                 | > рынка         |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | >               |
|                 |                 |                 | Прогнозирование |
|                 |                 |                 | > популярности  |
|                 |                 |                 | > рекламы       |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | >               |
|                 |                 |                 | Прогнозирование |
|                 |                 |                 | > роста         |
|                 |                 |                 | > населения     |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Оценка        |
|                 |                 |                 | > пр            |
|                 |                 |                 | одолжительности |
|                 |                 |                 | > жизни         |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Прогноз       |
|                 |                 |                 | > погоды        |
+-----------------+-----------------+-----------------+-----------------+
|                 | **○**           | > **            |                 |
|                 |                 | Классификация** |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Идентификация |
|                 |                 |                 | > мошенничества |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Удержание     |
|                 |                 |                 | > клиентов      |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Классификация |
|                 |                 |                 | > изображений   |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Диагностика   |
+-----------------+-----------------+-----------------+-----------------+
|                 | > **Обучение    |                 |                 |
|                 | > без учителя** |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | **○**           | > **Уменьшение  |                 |
|                 |                 | > размерности** |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Обнаружение   |
|                 |                 |                 | > признаков     |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Обнаружение   |
|                 |                 |                 | > структуры     |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Визуализация  |
|                 |                 |                 | > больших       |
|                 |                 |                 | > данных        |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Сжатие с      |
|                 |                 |                 | > сохранением   |
|                 |                 |                 | > смысла        |
+-----------------+-----------------+-----------------+-----------------+
|                 | **○**           | > **            |                 |
|                 |                 | Кластеризация** |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Р             |
|                 |                 |                 | екомендательные |
|                 |                 |                 | > системы       |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Сегментация   |
|                 |                 |                 | > клиентов      |
+-----------------+-----------------+-----------------+-----------------+
|                 | ■               |                 | > Целевой       |
|                 |                 |                 | > маркетинг     |
+-----------------+-----------------+-----------------+-----------------+
|                 | > **Обучение с  |                 |                 |
|                 | >               |                 |                 |
|                 | подкреплением** |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ○               | > Управление    |                 |
|                 |                 | > роботом       |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ○               | > Решения       |                 |
|                 |                 | > реального     |                 |
|                 |                 | > времени       |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ○               | > Игровой ИИ    |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ○               | >               |                 |
|                 |                 | Алгоритмическая |                 |
|                 |                 | > торговля      |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | ○               | > Приобретение  |                 |
|                 |                 | > навыков       |                 |
+-----------------+-----------------+-----------------+-----------------+

> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image56.png){width="4.1875in"
> height="3.1347222222222224in"}
>
> **Machine Learning**

+-----------------------+-----------------------+-----------------------+
| **●**                 | > **Regression**      |                       |
|                       |                       |                       |
| **●**                 |                       |                       |
|                       |                       |                       |
| **●**                 |                       |                       |
|                       |                       |                       |
| **●**                 |                       |                       |
|                       |                       |                       |
| **●**                 |                       |                       |
|                       |                       |                       |
| **●**                 |                       |                       |
|                       |                       |                       |
| **●**                 |                       |                       |
+=======================+=======================+=======================+
|                       | ○                     | > Simple Linear       |
|                       |                       | > Regression          |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Multiple Linear     |
|                       |                       | > Regression          |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Polynomial          |
|                       |                       | > Regression          |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Support Vector      |
|                       |                       | > Regression (SVR)    |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Decision Tree       |
|                       |                       | > Regression          |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Random Forest       |
|                       |                       | > Regression          |
+-----------------------+-----------------------+-----------------------+
|                       | > **Classification**  |                       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Logistic Regression |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > K-Nearest Neighbors |
|                       |                       | > (K-NN)              |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Support Vector      |
|                       |                       | > Machine (SVM)       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Kernel SVM          |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Naive Bayes         |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Decision Tree       |
|                       |                       | > Classification      |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Random Forest       |
|                       |                       | > Classification      |
+-----------------------+-----------------------+-----------------------+
|                       | > **Clustering**      |                       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > K-Means Clustering  |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Hierarchical        |
|                       |                       | > Clustering          |
+-----------------------+-----------------------+-----------------------+
|                       | > **Association**     |                       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Apriori             |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Eclat               |
+-----------------------+-----------------------+-----------------------+
|                       | > **Reinforcement     |                       |
|                       | > Learning**          |                       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Upper Confidence    |
|                       |                       | > Bound (UCB)         |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Thompson Sampling   |
+-----------------------+-----------------------+-----------------------+
|                       | > **Dimensionality    |                       |
|                       | > Reduction**         |                       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Kernel PCA          |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Linear Discriminant |
|                       |                       | > Analysis (LDA)      |
+-----------------------+-----------------------+-----------------------+
|                       | > **Deep Learning**   |                       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Artificial Neural   |
|                       |                       | > Networks            |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Convolutional       |
|                       |                       | > Neural Networks     |
+-----------------------+-----------------------+-----------------------+

> **Типовой верхнеуровневый сценарий** разработки, валидации и внедрения
> модели![](vertopal_c0b099a1bf474e9590819adae366c879/media/image57.png){width="6.269444444444445in"
> height="2.4839588801399826in"}
>
> **Описание** задачи - что хотим сделать\
> **Подготовка** данных - какие признаки объектов доступны\
> **Предобработка** данных - подготовка признаков для решения
> задачи**Выбор** алгоритма - обучение и выбор лучшего алгоритма\
> **Оценка** алгоритма - вывод о качестве по метрикам
>
> **Валидация** модели - независимая, детальная проверка качества
> алгоритма**Внедрение** в пром - включение в промышленные бизнес
> процессы\
> **Мониторинг** качества - контроль качества работы решения в ПРОМ
>
> **Задача классификации**\
> Задача классификации в машинном обучении - это задача отнесения
> объекта к одномуиз заранее определенных классов на основании его
> формализованных признаков.
>
> Каждый из объектов в этой задаче представляется в виде вектора в
> N-мерномпространстве, каждое измерение в котором представляет собой
> описание одного изпризнаков объекта.
>
> Для обучения классификатора необходимо иметь набор объектов, для
> которыхзаранее определены классы.
>
> Это множество называется обучающей выборкой, её разметка производится
> вручную,с привлечением специалистов в исследуемой области.
>
> **Пример:**\
> У нас есть набор текстов, и у каждого текста есть оценка тональности.
>
> Алгоритм классификации может обучится на этих текстах, и в дальнейшем,
> обученныйалгоритм можно использовать для другого набора текстов.
>
> В этом случае, многомерное пространство признаков представляет собой
> матрицачастот слов в текстах.
>
> **Другой пример**, предположим есть таблица пациентов, с медицинскими
> показателями(виды болей, различные анализы) и диагноз, который был
> подтвержден. В этом случаеможно обучить алгоритм распознавать диагноз
> у вновь поступивших пациентов.
>
> **Типичная задача статистического обучения** - есть набор объектов с
> наблюдаемымисвойствами, и не наблюдаемыми свойствами.
>
> Нужно построить алгоритм, который бы позволял вычислить ненаблюдаемые
> свойствапри помощи наблюдаемых, при этом хотелось бы чтобы алгоритм
> ошибался не оченьчасто и не очень сильно.
>
> **Классификаторы основанные на таблице частот.**
>
> **1.** **ZeroR** (алгоритм строит таблицу частот и выбирает
> максимальную частоту). **2.** **OneR** (Алгоритм строит таблицу частот
> и строит одно правило для каждой класса. Выбирает правило, которое
> дает минимальную ошибку. Это правило применяется для всего датасета)\
> **Naive Bayesian 3.**
>
> **4.** **Decision Tree** (Алгоритм разбивает датасет на все меньшие
> куски данных, формируя тем самым дерево).
>
> **Классификаторы основанные на ковариационной матрице**\
> 1. Линейный дискриминационный анализ (Linear Discriminant Analysis) 2.
> Логистическая регрессия (Logistic Regression)
>
> **Классификатор основанный на функции сходства**\
> 1. Метод ближайших соседей (K Nearest Neighbors)
>
> **Другие**\
> 1. Нейронные сети.
>
> 2\. Метод опорных векторов (Support Vector Machine)

+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e       | > **Бинарная                      |
| 9590819adae366c879/media/image58. | > классификация:**разделение на   |
| png){width="3.3430555555555554in" | > два класса: ● Да или Нет\       |
| height="3.2083333333333335in"}    | > ● Болен или Здоров\             |
|                                   | > ● Дерево или Не дерево          |
|                                   | >                                 |
|                                   | > **Многоклассовая                |
|                                   | > классификация:** ● Из какого    |
|                                   | > сорта винограда сделано вино?   |
|                                   | >                                 |
|                                   | > ● На какую тему статья?         |
|                                   | >                                 |
|                                   | > ● Какая марка машины на         |
|                                   | > фотографии?                     |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Задача регрессии**\
> Задача регрессии состоит в том, чтобы на основании различных
> признаков\
> предсказать вещественный ответ, т.е. для каждого объекта нужно
> предсказать число.
>
> **Для задачи регрессии.**
>
> данные представлены в виде таблицы\
> - каждая строка - объект\
> - столбцы - признаки объектов (все объекты описываются одним и тем же
> набором признаков, но значения признаков у каждого объекта свои).
>
> столбец - с целевой переменной (англ. target), то есть той, что
> будем-\
> предсказывать
>
> ЗЫ В задаче классификации также имеется отдельный столбец с классами
> объектов.Этот столбец и будет целевой переменной для классификации
>
> предсказание спроса на товар - нужно предсказать, какое количество
> единиц товарапотребуется в торговой точке в определенный промежуток
> времени, например вконкретную неделю.
>
> предсказание стоимости квартиры (стоимость в рублях --- числовая
> величина).
>
> предсказание возраста человека по фотографии (возраст --- число).
>
> **Отличие задачи классификации от задачи регрессии выглядит
> незначительными в принципе действительно таковым является.**
>
> **Алгоритмы предсказания и обучения будут работать по-разному для этих
> двухзадач.**

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image59.png){width="5.448611111111111in"
  height="1.948611111111111in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

> **признаки:** площадь, число комнат, этаж и число лет с последнего
> ремонта,**целевая переменная** - стоимость квартиры.
>
> Компьютер видит данные как набор чисел, не зная, что за этими числами
> стоит.

+-----------------------------------------------------------------------+
|   ------------------------------------------------------------------  |
|                                                                       |
|   ------------------------------------------------------------------  |
|                                                                       |
| > ![](vertopal_c0b099a1bf                                             |
| 474e9590819adae366c879/media/image60.png){width="5.127777777777778in" |
| > height="1.8916655730533682in"}                                      |
| >                                                                     |
| > **Модель.** Стоимость квартиры = средней стоимости квартир в        |
| > выборке.                                                            |
+=======================================================================+
+-----------------------------------------------------------------------+

> Модель -- рабочая, но бесполезна\
> можно использовать в качестве базового решения, бейзлайна (англ.
> baseline): болеесложный алгоритм не должен делать предсказания хуже,
> чем базовое решение.

  --------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image61.png){width="4.0in"
  height="1.6458333333333333in"}
  --------------------------------------------------------------------------------

  --------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image62.png){width="3.9902777777777776in"
  height="1.8541666666666667in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Кластеризация**\
> **Кластеризация** - это разбиение элементов некоторого множества на
> группы на основеих схожести. Задача кластеризации состоит в разбиении
> объектов из X на несколькоподмножеств (кластеров), в которых объекты
> более схожи между собой, чем с\
> объектами из других кластеров.

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image63.png){width="5.563888888888889in"
  height="2.3430555555555554in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

> **Процедура кластеризации** - зависит от меры сходства или несходства.
>
> Такие меры выражаются виде функций расстояний, выраженных в виде той
> или инойфункции.

+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e       | > ![](vertopal_c0b099a1bf474e     |
| 9590819adae366c879/media/image64. | 9590819adae366c879/media/image65. |
| png){width="2.9583333333333335in" | png){width="2.5930555555555554in" |
| height="1.9055555555555554in"}    | > height="1.875in"}               |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Применение кластерного анализа**\
> 1. Статистика\
> 2. Распознавание образов\
> 3. Финансовая математика\
> Автоматическая классификация в различных областях науки (например, в4.
>
> археологии, биологии (кластеризация видов животных и растений))\
> 5. Маркетинг. Маркетологи выделяют группы с целью оптимизации
> рекламной деятельности, оптимизации логистической деятельности.
>
> 6\. Исследование свойств ДНК\
> Страхование (цель выделения групп населения и соотнесение групп с
> геогрф. 7.
>
> расположением, заработком, семейным статусом и другой..) 8. Городское
> планирование.
>
> 9\. Финансовое планирование города, района....
>
> 10\. Социологические исследования.
>
> **Результат кластерного анализа сильно зависит от алгоритма!**

  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image66.png){width="3.2597222222222224in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image67.png){width="2.602777777777778in"
  height="1.8541666666666667in"}                                                                  height="1.9583333333333333in"}
  ----------------------------------------------------------------------------------------------- ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

> Результаты кластерного анализа k-средних для семи кластеров (слева)
> ипринадлежность рассмотренных животных к реальным семействам (центр),
> ирезультат кластеризации с помощью тесселяции Вороного
>
> **Ранжирование**

+-----------------------------------------------------------------------+
| > **Рекомендательные системы**                                        |
+=======================================================================+
| > **Задача рекомендательной системы** - проинформировать пользователя |
| > о товаре,который ему может быть наиболее интересен в данный момент  |
| > времени. Клиентполучает информацию, а сервис зарабатывает на        |
| > предоставлении качественныхуслуг.                                   |
+-----------------------------------------------------------------------+
| > **Услуги** - это не обязательно прямые продажи предлагаемого        |
| > товара. Сервис такжеможет зарабатывать на комиссионных или просто   |
| > увеличивать лояльностьпользователей, которая потом выливается в     |
| > рекламные и иные доходы.                                            |
+-----------------------------------------------------------------------+
| > **Персонализация онлайн-маркетинга** -- очевидный тренд последнего  |
| > десятилетия.По оценкам McKinsey, 35% выручки Amazon или 75% Netflix |
| > приходится именно нарекомендованные товары и процент этот,          |
| > вероятно, будет расти.                                              |
+-----------------------------------------------------------------------+
| > **Рекомендательные системы** -- это про то, что предложить клиенту, |
| > чтобы сделатьего счастливым.                                        |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **Предмет рекомендации -- что рекомендуется.**                      |
| >                                                                     |
| > Здесь большое разнообразие - это могут быть товары (Amazon, Ozon),  |
| > статьи(Arxiv.org), новости (Surfingbird, Яндекс.Дзен), изображения  |
| > (500px), видео (YouTube, Netflix), люди (Linkedin, LonelyPlanet),   |
| > музыка (Last.fm, Pandora), плейлисты и прочее.В целом,              |
| > рекомендовать можно что угодно.                                     |
+=======================================================================+
| > **Цель рекомендации -- зачем рекомендуется.**                       |
| >                                                                     |
| > **Например:** покупка, информирование, обучение, заведение          |
| > контактов.                                                          |
+-----------------------------------------------------------------------+
| > **Контекст рекомендации - что пользователь в этот момент            |
| > делает.**Например: смотрит товары, слушает музыку, общается с       |
| > людьми.                                                             |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **Источник рекомендации -- кто рекомендует:**\                      |
| > - аудитория (средний рейтинг ресторана в TripAdvisor),\             |
| > - схожие по интересам пользователи,\                                |
| > - экспертное сообщество (бывает, когда речь о сложном товаре,       |
| > таком, как, например, вино).                                        |
+=======================================================================+
| > **Степень персонализации.**                                         |
| >                                                                     |
| > \- **Не персональные рекомендации** - когда вам рекомендуют то же   |
| > самое, что всем остальным. Они допускают таргетинг по региону или   |
| > времени, но не учитывают ваши личные предпочтения.                  |
| >                                                                     |
| > \- **Более продвинутый вариант** - когда рекомендации используют    |
| > данные из вашей текущей сессии. Вы посмотрели несколько товаров, и  |
| > внизу страницы вам предлагаются похожие.                            |
| >                                                                     |
| > \- **Персональные рекомендации** - используют всю доступную         |
| > информацию о клиенте, в том числе историю его покупок.              |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **Прозрачность.**                                                   |
| >                                                                     |
| > Люди больше доверяют рекомендации, если понимают, как именно она    |
| > былаполучена. Так меньше риск нарваться на «недобросовестные»       |
| > системы,\                                                           |
| > продвигающие проплаченный товар или ставящие более дорогие товары   |
| > выше врейтинге. Кроме того, хорошая рекомендательная система сама   |
| > должна уметьбороться с купленными отзывами и накрутками продавцов.  |
| >                                                                     |
| > Манипуляции кстати бывают и непреднамеренными. Например, когда      |
| > выходит новыйблокбастер, первым делом на него идут фанаты,          |
| > соответственно, первую парумесяцев рейтинг может быть сильно        |
| > завышен.                                                            |
+=======================================================================+
| > **Формат рекомендации.**                                            |
| >                                                                     |
| > Это может быть всплывающее окошко, появляющийся в определенном      |
| > разделесайта отсортированный список, лента внизу экрана или что-то  |
| > еще.                                                                |
+-----------------------------------------------------------------------+
| > **Алгоритмы.**                                                      |
| >                                                                     |
| > Несмотря на множество существующих алгоритмов, все они сводятся к   |
| > несколькимбазовым подходам, которые будут описаны далее. К наиболее |
| > классическимотносятся алгоритмы Summary-based (неперсональные),     |
| > Content-based (моделиоснованные на описании товара), Collaborative  |
| > Filtering (коллаборативная\                                         |
| > фильтрация), Matrix Factorization (методы основанные на матричном   |
| > разложении) инекоторые другие.                                      |
+-----------------------------------------------------------------------+

+-----------------------------------+-----------------------------------+
| > ![](vertopal                    | > Пользователи обычно             |
| _c0b099a1bf474e9590819adae366c879 | > оцениваютлишь небольшую часть   |
| /media/image68.png){width="3.3in" | > товаров, чтоесть в каталоге, и  |
| > height="2.2666655730533685in"}  | > задача\                         |
|                                   | > рекомендательной системы -\     |
|   ------------------------------  | > обобщить эту информацию и\      |
|                                   | > предсказать отношение клиента   |
|   ------------------------------  | > кдругим товарам, про которые    |
|                                   | > ничегоне известно. Другими      |
|                                   | > словами\                        |
|                                   | > нужно заполнить все             |
|                                   | > незаполненныеячейки.            |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Понижение размерности**
>
> Под уменьшением размерности (англ. dimensionality reduction) в
> машинном обученииподразумевается уменьшение числа признаков набора
> данных.
>
> Наличие в нем признаков избыточных, неинформативных или слабо
> информативныхможет понизить эффективность модели, а после такого
> преобразования она\
> упрощается, и соответственно уменьшается размер набора данных в памяти
> иускоряется работа алгоритмов ML на нем.
>
> Уменьшение размерности может быть осуществлено методами выбора
> признаков(англ. feature selection) или выделения признаков (англ.
> feature extraction).
>
> **Ассоциации**

+-----------------------------------+-----------------------------------+
| > **Поиск правил**                |                                   |
+===================================+===================================+
| > Правила связывания полезны при  |                                   |
| > поиске ассоциаций в большом     |                                   |
| > наборе данных иобнаружении      |                                   |
| > корреляций и зависимостей в     |                                   |
| > данных.                         |                                   |
| >                                 |                                   |
| > Обычно это применяется к        |                                   |
| > различным транзакционным данным |                                   |
| > из различныхотраслей, таких как |                                   |
| > розничная торговля, банковское  |                                   |
| > дело, медицина, страхование     |                                   |
| > ит.д.                           |                                   |
| >                                 |                                   |
| > Некоторые примеры алгоритмов    |                                   |
| > правил ассоциации включают      |                                   |
| > алгоритм Apriori, FP-Growth и   |                                   |
| > т.д.                            |                                   |
+-----------------------------------+-----------------------------------+
| > Правила связывания обычно       |                                   |
| > представляют собой набор        |                                   |
| > условных операторов,которые     |                                   |
| > помогают показать отношения     |                                   |
| > между элементами данных в       |                                   |
| > большихнаборах данных,          |                                   |
| > созданных в различных           |                                   |
| > бизнес-сценариях.               |                                   |
| >                                 |                                   |
| > Правило ассоциации широко       |                                   |
| > используется для обнаружения    |                                   |
| > корреляций втранзакционных      |                                   |
| > данных.                         |                                   |
| >                                 |                                   |
| > Для заданного набора транзакций |                                   |
| > правила связывания могут помочь |                                   |
| > найти правила,которые будут     |                                   |
| > предсказывать появление         |                                   |
| > элемента на основе вхождений    |                                   |
| > другихэлементов в транзакции.   |                                   |
| > Типичные термины, используемые  |                                   |
| > в алгоритме, -- этоподдержка,   |                                   |
| > уверенность и подъем (лифт).    |                                   |
| >                                 |                                   |
| > Поддержка определяет частоту    |                                   |
| > определенного набора элементов  |                                   |
| > данных в рамкахтранзакции как   |                                   |
| > отношение к общему количеству   |                                   |
| > транзакций.                     |                                   |
| >                                 |                                   |
| > Уверенность -- это количество   |                                   |
| > раз, когда условие оценивается  |                                   |
| > как истинное.                   |                                   |
| >                                 |                                   |
| > Лифт измеряет эффективность     |                                   |
| > правила с точки зрения его      |                                   |
| > предсказательной силы.          |                                   |
+-----------------------------------+-----------------------------------+
| > Правила ассоциации полезны при  |                                   |
| > анализе типичных данных,        |                                   |
| > связанных с розничнойторговлей, |                                   |
| > например данных, собранных с    |                                   |
| > помощью сканеров штрих-кода в\  |                                   |
| > супермаркетах, или данных,      |                                   |
| > генерируемых посредством        |                                   |
| > транзакций на                   |                                   |
| > веб-сайтеэлектронной торговли и |                                   |
| > т. д.                           |                                   |
| >                                 |                                   |
| > Эти данные обычно содержат      |                                   |
| > многочисленные записи           |                                   |
| > транзакций.                     |                                   |
| >                                 |                                   |
| > В конце концов, мы можем        |                                   |
| > добывать различные шаблоны,     |                                   |
| > такие как определенныегруппы    |                                   |
| > предметов, которые постоянно    |                                   |
| > покупаются вместе, предметы,    |                                   |
| > похожие напредметы, которые вы  |                                   |
| > просматриваете, и т. д.         |                                   |
| >                                 |                                   |
| > Это, в свою очередь, помогает в |                                   |
| > правильном размещении предметов |                                   |
| > на веб-сайтеили внутри          |                                   |
| > физического заведения.          |                                   |
+-----------------------------------+-----------------------------------+
| > ![](vertopal_c0b099a1bf474      | ![](vertopal_c0b099a1bf474        |
| e9590819adae366c879/media/image69 | e9590819adae366c879/media/image69 |
| .png){width="6.370833333333334in" | .png){width="6.370833333333334in" |
| > height="1.3111100174978128in"}  | height="1.3111100174978128in"}    |
+-----------------------------------+-----------------------------------+

+-----------------------------------------------------------------------+
| > **Направления ML**\                                                 |
| > ● Обучение с учителем\                                              |
| > ● Обучение с подкреплением\                                         |
| > ● Обучение без учителя                                              |
+=======================================================================+
+-----------------------------------------------------------------------+

+-----------------------+-----------------------+-----------------------+
| > **Обучение с        |                       |                       |
| > учителем**\         |                       |                       |
| > - Имеется множество |                       |                       |
| > объектов (ситуаций) |                       |                       |
| > и множество         |                       |                       |
| > возможных ответов   |                       |                       |
| > (откликов,          |                       |                       |
| > реакций).           |                       |                       |
| >                     |                       |                       |
| > \- Существует       |                       |                       |
| > некоторая           |                       |                       |
| > зависимость между   |                       |                       |
| > ответами и          |                       |                       |
| > объектами, но она   |                       |                       |
| > неизвестна.         |                       |                       |
| >                     |                       |                       |
| > Известна только     |                       |                       |
| > конечная            |                       |                       |
| > совокупность        |                       |                       |
| > прецедентов - пар   |                       |                       |
| > «объект, ответ»,-\  |                       |                       |
| > называемая          |                       |                       |
| > обучающей выборкой. |                       |                       |
| >                     |                       |                       |
| > \- На основе этих   |                       |                       |
| > данных требуется    |                       |                       |
| > восстановить        |                       |                       |
| > зависимость, то     |                       |                       |
| > есть построить      |                       |                       |
| > алгоритм, способный |                       |                       |
| > для любого объекта  |                       |                       |
| > выдать достаточно   |                       |                       |
| > точный ответ.       |                       |                       |
| >                     |                       |                       |
| > \- Для измерения    |                       |                       |
| > точности ответов    |                       |                       |
| > определенным        |                       |                       |
| > образом вводится    |                       |                       |
| > функционал          |                       |                       |
| > качества.           |                       |                       |
+=======================+=======================+=======================+
| > **Этап №1** -       |                       | ![](vert              |
| > обучение с          |                       | opal_c0b099a1bf474e95 |
| > учителем\           |                       | 90819adae366c879/medi |
| > ● **На входе:**     |                       | a/image70.png){width= |
| > данные -- выборка   |                       | "2.186111111111111in" |
| > прецедентов         |                       | height="1.125in"}     |
| > «объект→ответ»,     |                       |                       |
| > каждый объект\      |                       |                       |
| > описывается набором |                       |                       |
| > признаков\          |                       |                       |
| > ● **На выходе:**    |                       |                       |
| > модель,             |                       |                       |
| > предсказывающая     |                       |                       |
| > ответ по объекту    |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > **Этап №2** -       |                       |                       |
| > применение          |                       |                       |
| >                     |                       |                       |
| > ● На входе: данные  |                       |                       |
| > -- новый объект     |                       |                       |
| >                     |                       |                       |
| > ● На выходе:        |                       |                       |
| > предсказание ответа |                       |                       |
| > на новом объекте    |                       |                       |
+-----------------------+-----------------------+-----------------------+
| ![](verto             |                       |                       |
| pal_c0b099a1bf474e959 |                       |                       |
| 0819adae366c879/media |                       |                       |
| /image71.png){width=" |                       |                       |
| 2.9472222222222224in" |                       |                       |
| height="1             |                       |                       |
| .5930544619422573in"} |                       |                       |
+-----------------------+-----------------------+-----------------------+
| ![](verto             | > ![](verto           |                       |
| pal_c0b099a1bf474e959 | pal_c0b099a1bf474e959 |                       |
| 0819adae366c879/media | 0819adae366c879/media |                       |
| /image72.png){width=" | /image73.png){width=" |                       |
| 2.9680555555555554in" | 2.7194444444444446in" |                       |
| height="1             | > height="1           |                       |
| .2805544619422573in"} | .5833333333333333in"} |                       |
+-----------------------+-----------------------+-----------------------+

+-----------------------------------------------------------------------+
| > **Обучение с подкреплением**\                                       |
| > - (**Reinforcement Learning**, или RL) большую часть времени RL     |
| > работает с целями непосредственно искусственного интеллекта -       |
| > созданием агента, который сможет производить эффективные действия в |
| > заданной среде.                                                     |
| >                                                                     |
| > \- **Алгоритмы RL** используют вознаграждение как обратную связь    |
| > для выполненных действий и стараются его максимизировать.           |
| >                                                                     |
| > \- Популярность обучения с подкреплением стала расти после          |
| > известного матча по игре го между системой искусственного           |
| > интеллекта **AlphaGo**,\                                            |
| > разработанной британской компанией Google DeepMind, и азиатским\    |
| > чемпионом Ли Седолем.                                               |
| >                                                                     |
| > \- Система **AlphaGo** была создана с использованием алгоритмов RL. |
| >                                                                     |
| > Даже первая версия искусственного интеллекта представляла           |
| > серьезный-\                                                         |
| > вызов любому человеку.                                              |
| >                                                                     |
| > \- Следующая версия --- **AlphaZero** --- дошла до уровня           |
| > сложности, недостижимого для людей.                                 |
| >                                                                     |
| > \- Отличительная черта **AlphaZero** в том, что она научилась       |
| > играть сама с собой, а не использовать человеческие партии для      |
| > обучения.                                                           |
+=======================================================================+
| ![](vertopal_c0b099a1bf                                               |
| 474e9590819adae366c879/media/image74.png){width="6.115277777777778in" |
| height="3.0097222222222224in"}                                        |
+-----------------------------------------------------------------------+
| > **Разные действия приводят к разным выигрышам.** К примеру, при     |
| > поискесокровищ в лабиринте поворот налево может означать кучу       |
| > бриллиантов, а поворотнаправо - яму ядовитых змей.                  |
| >                                                                     |
| > **Агент получает выигрыш с задержкой во времени.** Это значит, что, |
| > повернувналево в лабиринте, мы не сразу поймем, что это правильный  |
| > выбор.                                                              |
| >                                                                     |
| > **Выигрыш зависит от текущего состояния системы.** Продолжая пример |
| > выше,поворот налево может быть правильным в текущей части           |
| > лабиринта, но необязательно в остальных.                            |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **Обучение без учителя**\                                           |
| > - В этом случае нет "учителя" и "обучающая выборка" состоит только  |
| > из объектов, т.е. Y отсутствует.                                    |
| >                                                                     |
| > \- **Задача кластеризации:** разбить объекты на группы (кластеры),  |
| > так, чтобы в одном кластере оказались близкие друг к другу объекты, |
| > а в разных\                                                         |
| > кластерах объекты были существенно различные.                       |
| >                                                                     |
| > \- Кластер можно охарактеризовать как группу объектов, имеющих      |
| > общие свойства.                                                     |
+=======================================================================+
| > ![](vertopal_c0b099a1bf4                                            |
| 74e9590819adae366c879/media/image75.png){width="3.2597222222222224in" |
| > height="1.9166666666666667in"}                                      |
+-----------------------------------------------------------------------+
| > ![](vertopal_c0b099a1bf                                             |
| 474e9590819adae366c879/media/image76.png){width="3.238888888888889in" |
| > height="1.625in"}                                                   |
+-----------------------------------------------------------------------+

> **Нейронные сети**\
> Мозг представляет собой огромную сеть, где каждым узлом является
> нервная клетка(нейрон)

+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e       | > Передача информации в мозгу,    |
| 9590819adae366c879/media/image77. | > как и нервнойсистеме в целом,   |
| png){width="2.5722222222222224in" | > осуществляется\                 |
| height="1.4055544619422573in"}    | > посредством нервных импульсов.  |
|                                   | > Они\                            |
|                                   | > распространяются в направлении  |
|                                   | > от телаклетки к концевому       |
|                                   | > отделу аксона, которыйможет     |
|                                   | > ветвиться, образуя множество\   |
|                                   | > окончаний, контактирующих с     |
|                                   | > другими\                        |
|                                   | > нейронами через узкую щель -    |
|                                   | > синап                           |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

+-----------------------------------+-----------------------------------+
| > \-\                             | > **Нейроны** работают не сами по |
| > -                               | > себе, а иерархически            |
|                                   | > объединяются.**Сначала** - в    |
|                                   | > локальные нейронные контуры     |
|                                   | > (или локальные сети), которые   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> состоят из нейронов, выполняющих одну функцию.
>
> \- **Локальные контуры** объединяются в отделы, которые выполняют
> совокупность схожих функций.
>
> **Искусственный нейрон**\
> **1.** **Клетка** - элементарный процессор, способный к простейшей
> обработке информации.
>
> **2.** **Нейрон** - элемент клеточной структуры мозга.
>
> **3.** **Нейрон** осуществляет прием и передачу информации в виде
> импульсов нервной активности.
>
> **4.** **Природа импульсов** -- электрохимическая.
>
> \- Данную функцию называют функцией активации или функцией
> срабатывания, передаточной функцией.
>
> \- Полученный результат посылается на единственный выход.
>
> \- Такие искусственные нейроны объединяют в **сети** - соединяют
> выходы одних нейронов с входами других.
>
> \- **Искусственный нейрон** - узел искусственной нейронной сети,
> являющийся упрощённой моделью естественного нейрона.
>
> \- Математически, искусственный нейрон обычно представляют как
> некоторую нелинейную функцию от единственного аргумента - линейной
> комбинации всех входных сигналов.
>
> **Искусственный нейрон** - это очень отдаленное подобие биологического
> нейрона.**Что такое искусственный нейрон?**
>
> Это простая функция на самом деле. У нее есть входы. Каждый вход
> умножается нанекие веса, дальше все суммируется, прогоняется через
> какую-то нелинейнуюфункцию, результат выдается на выход - все, это
> один нейрон.
>
> Если вы знакомы с логистической регрессией, под которой понимаем
> нелинейнуюфункцию SIGMOID, то один нейрон - это полный аналог
> логистической регрессии,простого линейного классификатора.

+-----------------------------------+-----------------------------------+
|   ----------------------------    | ![](vertopal_c0b099a1bf474        |
| --------------------------------- | e9590819adae366c879/media/image79 |
| --------------------------------- | .png){width="2.926388888888889in" |
|   ![](vertopal_c0b099a1bf474      | height="1.645832239720035in"}     |
| e9590819adae366c879/media/image78 |                                   |
| .png){width="2.948611111111111in" |                                   |
|   height="1.6041666666666667in"}  |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ----------------------------    |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Искусственная нейросеть**\
> **Искусственная нейросеть** - это способ собрать нейроны в сеть, чтобы
> она решалаопределенную задачу, например, задачу классификации.
>
> **Нейроны собираются по слоям.**
>
> Есть входной слой, куда подается входной сигнал, есть выходной слой,
> откудаснимается результат работы нейросети, и между ними есть скрытые
> слои. Их можетбыть 1, 2, 3, много.
>
> Если скрытых слоев больше, чем 1, нейросеть считается глубокой, если
> 1, тонеглубокой.

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image80.png){width="6.272222222222222in"
  height="2.386111111111111in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image81.png){width="6.272222222222222in"
  height="2.4055555555555554in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

> Лабораторная работа №1
>
> **Задание на разведочный анализ данных для датасета
> \`diamonds.csv\`:Датасет:** **Условие:**
>
> **Цели задания:**\
> 1. Понять основные статистические характеристики датасета. 2.
> Научиться визуализировать данные для анализа.
>
> 3\. Исследовать взаимосвязь между различными переменными.
>
> **Описание датасета:**\
> Датасет \`diamonds.csv\` содержит следующие столбцы:

+-----------------------------------+-----------------------------------+
| > \-\                             | > \`carat\`: вес алмаза в         |
| > -\                              | > каратах.                        |
| > -\                              | >                                 |
| > -\                              | > \`cut\`: качество огранки       |
| > -\                              | > алмаза (Fair, Good, Very Good,  |
| > -\                              | > Premium, Ideal). \`color\`:     |
| > -\                              | > цвет алмаза, от J (худший) до D |
| > -\                              | > (лучший).                       |
| > -\                              | >                                 |
| > -                               | > \`clarity\`: чистота алмаза (от |
|                                   | > I1 до IF).                      |
|                                   | >                                 |
|                                   | > \`depth\`: общая глубина в      |
|                                   | > процентах от вершины до         |
|                                   | > основания.                      |
|                                   | >                                 |
|                                   | > \`table\`: ширина верхней части |
|                                   | > алмаза относительно самой       |
|                                   | > широкой точки. \`price\`: цена  |
|                                   | > алмаза в долларах США.          |
|                                   | >                                 |
|                                   | > \`x\`: длина алмаза в мм.       |
|                                   | >                                 |
|                                   | > \`y\`: ширина алмаза в мм.      |
|                                   | >                                 |
|                                   | > \`z\`: глубина алмаза в мм.     |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Задачи:**\
> **0. Очистка датасета**
>
> **1. Исследование мер центральной тенденции:**\
> - Найдите среднее значение, медиану и моду для численных переменных.
>
> \- Опишите, что каждая из этих мер говорит о распределении данных.
>
> **2. Визуализация данных:**\
> - Создайте гистограммы для переменных \`carat\`, \`depth\`, и
> \`price\`.
>
> \- Постройте boxplot для цены в зависимости от качества огранки и
> цвета алмазов.
>
> \- Используйте scatter plot для изучения взаимосвязи между \`carat\` и
> \`price\`.
>
> **3. Исследование мер вариативности:**\
> - Рассчитайте стандартное отклонение и диапазон для переменных
> \`carat\`, \`depth\`, и \`price\`.
>
> \- Объясните значение этих мер в контексте данных.
>
> **4. Корреляционная матрица:**\
> - Создайте корреляционную матрицу для всех численных переменных.
>
> \- Используйте тепловую карту для визуализации корреляционной
> матрицы.- Обсудите, какие переменные наиболее сильно коррелируют и
> предположите почему.

+-----------------------------------------------------------------------+
| > **Подключение необходимых библиотек и датасета**                    |
+=======================================================================+
| > import csv\                                                         |
| > import os\                                                          |
| > import pandas as pd                                                 |
+-----------------------------------------------------------------------+
| > relative_path = \"diamonds.csv\"\                                   |
| > absolute_path = os.path.abspath(relative_path)                      |
| >                                                                     |
| > dataset = pd.read_csv(\"/Users/sam05/Data Analysis/diamonds.csv\",  |
| > sep = \',\') dataset.head()                                         |
+-----------------------------------------------------------------------+
| > **0. Очистка датасета**                                             |
+-----------------------------------------------------------------------+
| > dataset.drop_duplicates()\                                          |
| > dataset.head()                                                      |
+-----------------------------------------------------------------------+
| > ![](vertopal_c0b099a1bf                                             |
| 474e9590819adae366c879/media/image82.png){width="5.583333333333333in" |
| > height="1.7194444444444446in"}                                      |
+-----------------------------------------------------------------------+

+-----------------------+-----------------------+-----------------------+
| > **1. Исследование   |                       |                       |
| > мер центральной     |                       |                       |
| > тенденции:**        |                       |                       |
+=======================+=======================+=======================+
| > \- Найдите среднее  |                       |                       |
| > значение, медиану и |                       |                       |
| > моду для численных  |                       |                       |
| > переменных.         |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > avg =               |                       |                       |
| >                     |                       |                       |
| dataset\[\[\'carat\', |                       |                       |
| > \'depth\',          |                       |                       |
| > \'table\',          |                       |                       |
| > \'price\', \'x\',   |                       |                       |
| > \'y\',              |                       |                       |
| > \'z\'\]\].mean()    |                       |                       |
| > med =               |                       |                       |
| >                     |                       |                       |
| dataset\[\[\'carat\', |                       |                       |
| > \'depth\',          |                       |                       |
| > \'table\',          |                       |                       |
| > \'price\', \'x\',   |                       |                       |
| > \'y\',              |                       |                       |
| > \'z\'\]\].median()  |                       |                       |
| > mod =               |                       |                       |
| >                     |                       |                       |
| dataset\[\[\'carat\', |                       |                       |
| > \'depth\',          |                       |                       |
| > \'table\',          |                       |                       |
| > \'price\', \'x\',   |                       |                       |
| > \'y\',              |                       |                       |
| > \'z\'\]\].mode()    |                       |                       |
| > print(\"mean:\\n\", |                       |                       |
| > avg,                |                       |                       |
| >                     |                       |                       |
| \"\\n\\nmedian:\\n\", |                       |                       |
| > med,                |                       |                       |
| > \"\\n\\nmode:\\n\", |                       |                       |
| > mod)                |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > **mean:**           | > **median:**         | > **mode:**           |
| >                     | >                     |                       |
| > carat 0.797940      | > carat 0.70          | <table                |
| >                     | >                     | style="width:100%;">  |
| > depth 61.749405     | > depth 61.80         | <colgroup>            |
| >                     | >                     | <col                  |
| > table 57.457184     | > table 57.00         | style="width: 14%" /> |
| >                     | >                     | <col                  |
| > price 3932.799722   | > price 2401.00       | style="width: 14%" /> |
| >                     | >                     | <col                  |
| > x 5.731157          | > x 5.70              | style="width: 14%" /> |
| >                     | >                     | <col                  |
| > y 5.734526          | > y 5.71              | style="width: 14%" /> |
| >                     | >                     | <col                  |
| > z 3.538734          | > z 3.53              | style="width: 14%" /> |
| >                     | >                     | <col                  |
| > dtype: float64      | > dtype: float64      | style="width: 14%" /> |
|                       |                       | <col                  |
|                       |                       | style="width: 14%" /> |
|                       |                       | </colgroup>           |
|                       |                       | <thead>               |
|                       |                       | <tr class="header">   |
|                       |                       | <th>carat</th>        |
|                       |                       | <th                   |
|                       |                       | colspan="2">depth     |
|                       |                       | table</th>            |
|                       |                       | <th>price</th>        |
|                       |                       | <th><blockquote>      |
|                       |                       | <p>x</p>              |
|                       |                       | </blockquote></th>    |
|                       |                       | <th><blockquote>      |
|                       |                       | <p>y</p>              |
|                       |                       | </blockquote></th>    |
|                       |                       | <th>z</th>            |
|                       |                       | </tr>                 |
|                       |                       | </thead>              |
|                       |                       | <tbody>               |
|                       |                       | <tr class="odd">      |
|                       |                       | <td><blockquote>      |
|                       |                       | <p>0.3</p>            |
|                       |                       | </blockquote></td>    |
|                       |                       | <td>62.0</td>         |
|                       |                       | <td>56.0</td>         |
|                       |                       | <td><blockquote>      |
|                       |                       | <p>605</p>            |
|                       |                       | </blockquote></td>    |
|                       |                       | <td>4.37</td>         |
|                       |                       | <td>4.34</td>         |
|                       |                       | <td>2.7</td>          |
|                       |                       | </tr>                 |
|                       |                       | </tbody>              |
|                       |                       | </table>              |
+-----------------------+-----------------------+-----------------------+
| > \- Опишите, что     |                       |                       |
| > каждая из этих мер  |                       |                       |
| > говорит о           |                       |                       |
| > распределении       |                       |                       |
| > данных.             |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > **Среднее           |                       |                       |
| > значение** -        |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > **Медиана** -       |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > **Мода** -          |                       |                       |
+-----------------------+-----------------------+-----------------------+

+-----------------------+-----------------------+-----------------------+
| > **2. Визуализация   |                       |                       |
| > данных:**           |                       |                       |
+=======================+=======================+=======================+
| > Создайте            |                       |                       |
| > гистограммы для     |                       |                       |
| > переменных          |                       |                       |
| > \`carat\`,          |                       |                       |
| > \`depth\`, и        |                       |                       |
| > \`price\`.          |                       |                       |
+-----------------------+-----------------------+-----------------------+
| dataset.hi            |                       |                       |
| st(column=\'carat\')\ |                       |                       |
| dataset.hi            |                       |                       |
| st(column=\'depth\')\ |                       |                       |
| dataset.h             |                       |                       |
| ist(column=\'price\') |                       |                       |
+-----------------------+-----------------------+-----------------------+
| ![](verto             | ![](verto             | ![](verto             |
| pal_c0b099a1bf474e959 | pal_c0b099a1bf474e959 | pal_c0b099a1bf474e959 |
| 0819adae366c879/media | 0819adae366c879/media | 0819adae366c879/media |
| /image83.png){width=" | /image84.png){width=" | /image85.png){width=" |
| 1.9361100174978128in" | 1.9361100174978128in" | 1.9361111111111111in" |
| height="1             | height="1             | height="1             |
| .4680544619422573in"} | .4680544619422573in"} | .4680544619422573in"} |
+-----------------------+-----------------------+-----------------------+
| > Постройте boxplot   |                       |                       |
| > для цены в          |                       |                       |
| > зависимости от      |                       |                       |
| > качества огранки и  |                       |                       |
| > цвета алмазов.      |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > dataset.boxplot(    |                       |                       |
| column=\[\'price\'\], |                       |                       |
| > by=\[\'cut\',       |                       |                       |
| > \'color\'\])        |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > ![](verto           |                       |                       |
| pal_c0b099a1bf474e959 |                       |                       |
| 0819adae366c879/media |                       |                       |
| /image86.png){width=" |                       |                       |
| 3.1555555555555554in" |                       |                       |
| > height="2.3125in"}  |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > Используйте scatter |                       |                       |
| > plot для изучения   |                       |                       |
| > взаимосвязи между   |                       |                       |
| > \`carat\` и         |                       |                       |
| > \`price\`.          |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > sp =                |                       |                       |
| > dataset.plot        |                       |                       |
| .scatter(x=\'carat\', |                       |                       |
| > y=\'price\')        |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > ![](verto           |                       |                       |
| pal_c0b099a1bf474e959 |                       |                       |
| 0819adae366c879/media |                       |                       |
| /image87.png){width=" |                       |                       |
| 3.1666666666666665in" |                       |                       |
| > height="2.3125in"}  |                       |                       |
+-----------------------+-----------------------+-----------------------+

+-----------------------------------------------------------------------+
| > **3. Исследование мер вариативности:**                              |
+=======================================================================+
| > Рассчитайте стандартное отклонение и диапазон для                   |
| > переменных\`carat\`, \`depth\`, и \`price\`.                        |
+-----------------------------------------------------------------------+
| > dataset\[\[\'carat\',\'depth\',\'price\'\]\].std()                  |
+-----------------------------------------------------------------------+
| > carat 0.474011                                                      |
| >                                                                     |
| > depth 1.432621                                                      |
| >                                                                     |
| > price 3989.439738                                                   |
| >                                                                     |
| > dtype: float64                                                      |
+-----------------------------------------------------------------------+
| > Объясните значение этих мер в контексте данных.                     |
+-----------------------------------------------------------------------+
| > Карат -                                                             |
+-----------------------------------------------------------------------+

> (26.04.24) Семинар 4.1\
> jupyter notebook - bike

+-----------------------------------------------------------------------+
| > import csv\                                                         |
| > from google.colab import drive\                                     |
| > drive.mount(\'/content/gdrive\')                                    |
+=======================================================================+
| > Mounted at /content/gdrive                                          |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > import pandas as pd\                                                |
| > \# Создание DataFrame\                                              |
| > bikes =                                                             |
| > pd.read_csv(\"gdrive/MyDrive/Data_analysis/Практики/BikeData.csv\") |
| > bikes.head()                                                        |
+=======================================================================+
| ![](vertopal_c0b099a1bf                                               |
| 474e9590819adae366c879/media/image88.png){width="6.102777777777778in" |
| height="1.198611111111111in"}                                         |
+-----------------------------------------------------------------------+

> **Тема 1: Введение в инструменты + Тема 2: Введение в статистику**

+-----------------------------------------------------------------------+
| > **DataFrame.shape** - возвращает кортеж с количеством строк и       |
| > столбцов                                                            |
+=======================================================================+
| > bikes.shape                                                         |
+-----------------------------------------------------------------------+
| > (8760, 12)                                                          |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > bikes.info()                                                        |
+=======================================================================+
| > \<class \'pandas.core.frame.DataFrame\'\>\                          |
| > RangeIndex: 8760 entries, 0 to 8759\                                |
| > Data columns (total 12 columns):                                    |
|                                                                       |
| +---------------+---------------+---------------+---------------+     |
| | > \#          | > Column      | Non-Null      | > Dtype       |     |
| |               |               | Count         |               |     |
| +===============+===============+===============+===============+     |
| | > \-\--       | > \-\-\-      | > \-\-\-\-\-\ | > \-\-        |     |
| |               | \-\-\-\-\-\-- | -\-\-\-\-\-\- | \-\-\-\-\-\-- |     |
| |               |               | \-\-\-\-\-\-- |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 0           | > Date        | > 8760        | > object      |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 1           | > Hour        | > 8760        | > int64       |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 2           | > Temperature | > 8581        | > float64     |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 3           | > Humidity    | > 8760        | > int64       |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 4           | > Wind speed  | > 8760        | > float64     |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 5           | > Rainfall    | > 8760        | > float64     |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 6           | > Snowfall    | > 8760        | > float64     |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 7           | > Seasons     | > 8760        | > object      |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 8           | > Holiday     | > 8760        | > object      |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 9           | Functioning   | > 8760        | > object      |     |
| |               | Day           | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | 10            | > Partner 1   | > 8760        | > int64       |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
| | > 11          | > Partner 2   | > 8760        | > int64       |     |
| |               |               | > non-null    |               |     |
| +---------------+---------------+---------------+---------------+     |
|                                                                       |
| > dtypes: float64(4), int64(4), object(4)\                            |
| > memory usage: 821.4+ KB                                             |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > bikes.columns                                                       |
+=======================================================================+
| > Index(\[\'Date\', \'Hour\', \'Temperature\', \'Humidity\', \'Wind   |
| > speed\', \'Rainfall\', \'Snowfall\', \'Seasons\', \'Holiday\',      |
| > \'Functioning Day\', \'Partner 1\', \'Partner 2\'\],\               |
| > dtype=\'object\')                                                   |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > bikes.describe()                                                    |
+=======================================================================+
| > ![](vertopal_c0b099a1bf                                             |
| 474e9590819adae366c879/media/image89.png){width="5.863888888888889in" |
| > height="2.0416666666666665in"}                                      |
+-----------------------------------------------------------------------+

> Лабораторная работа №2
>
> **Описание датасета**\
> ● **country**: The country that the wine is from\
> ● **description**: A few sentences from a sommelier describing the
> wine\'s taste, smell, look, feel, etc.
>
> ● **designation**: The vineyard within the winery where the grapes
> that made the wine are from\
> ● **points**: The number of points WineEnthusiast rated the wine on a
> scale of 1-100 (though they say they only post reviews for wines that
> score \>=80)\
> ● **price**: The cost for a bottle of the wine\
> ● **province**: The province or state that the wine is from\
> ● **region_1**: The wine growing area in a province or state (ie
> Napa)\
> ● **region_2**: Sometimes there are more specific regions specified
> within a wine growing area (ie Rutherford inside the Napa Valley), but
> this value can sometimes be blank●\
> **variety**: The type of grapes used to make the wine (ie Pinot Noir)
> **winery**: The winery that made the wine●
>
> **Задачи**\
> **1.** **Типы данных и создание новых переменных**\
> - Определите и классифицируйте типы данных каждого столбца в наборе
> данных.
>
> \- Какие из них категориальные?
>
> \- Какие числовые?
>
> \- Создайте новую переменную цена_за_балл, разделив цену на оценку,
> чтобы анализировать соотношение цены и качества вин.
>
> **2.** **Генеральная совокупность и выборка, частотные таблицы и**\
> **распределения**\
> - Сформируйте частотную таблицу для переменной \'страна\', чтобы
> увидеть количество отзывов по каждой стране.
>
> \- Выберите случайную выборку из 100 строк и сравните среднюю цену с
> ценой по всему набору данных.
>
> \- Хорошо ли выборка представляет собой всю совокупность?
>
> **3.** **Описательные статистики**\
> - Рассчитайте описательные статистики для числовых переменных
> (среднее, медиана, мода, размах, дисперсия и стандартное отклонение).
>
> \- Обсудите, какая мера центральной тенденции лучше всего описывает
> переменные оценки и цена и почему.

+-----------------------------------+-----------------------------------+
| > **4.**\                         | > **Z-оценка и выбросы**\         |
| > -\                              | > Рассчитайте Z-баллы для         |
| > -\                              | > переменной цена, чтобы          |
| > -\                              | > определить выбросы.Какой порог  |
| > -                               | > вы бы использовали и почему?    |
|                                   | >                                 |
|                                   | > Как выбросы влияют на набор     |
|                                   | > данных?                         |
|                                   | >                                 |
|                                   | > Следует ли их удалять или       |
|                                   | > оставить для анализа?           |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

+-----------------------------------+-----------------------------------+
| > **5.**\                         | > **Корреляция**\                 |
| > -\                              | > Вычислите матрицу корреляции    |
| > -                               | > для числовых переменных.Какие   |
| >                                 | > пары показывают наивысшую       |
| > **6.**\                         | > корреляцию?                     |
| > -                               | >                                 |
|                                   | > **Введение в визуализацию       |
|                                   | > данных**\                       |
|                                   | > Создайте гистограмму для        |
|                                   | > переменной оценки и диаграмму   |
|                                   | > размаха для                     |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> переменной цена.
>
> **7.** **Продвинутая визуализация данных**\
> - Постройте диаграмму рассеяния, чтобы визуализировать взаимосвязь
> между ценой и оценками.
>
> \- Используйте цветовую кодировку, чтобы различать страны.
>
> **8.** **Введение в тестирование гипотез, непараметрические
> критерии**- Проведите тест Манна-Уитни для сравнения распределения
> оценок между винами из США и Франции.

+-----------------------------------+-----------------------------------+
| > \-\                             | > Что можно сделать вывод из      |
| > **9.**\                         | > результатов?                    |
| > -\                              | >                                 |
| > -                               | > **Параметрические критерии для  |
|                                   | > тестирования гипотез**\         |
|                                   | > Выполните t-тест для сравнения  |
|                                   | > средней цены вин из Калифорнии  |
|                                   | > и Орегона.Существенно ли они    |
|                                   | > различаются?                    |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **10. Линейная регрессия**\
> - Постройте модель линейной регрессии для прогнозирования цены на
> основе оценок.
>
> \- Каково значение R² и как оно интерпретируется?
>
> **11. Логистическая регрессия**\
> - Используя логистическую регрессию, предскажите, является ли вино из
> США на основе его оценок и цены.
>
> \- Обсудите точность модели.
>
> **12. Задача классификации**\
> - Постройте классификатор дерева решений, чтобы различать красные и
> белые вина, используя подходящие характеристики из набора данных.
>
> **Датасет:**\
> **Условие:**
>
> **Подключение библиотек и датасета**

+-----------------------------------------------------------------------+
| > **import** csv\                                                     |
| > **import** os\                                                      |
| > **import** numpy **as** np\                                         |
| > **import** pandas **as** pd\                                        |
| > **import** seaborn **as** sns\                                      |
| > **import** statsmodels.api **as** sm\                               |
| > **import** matplotlib.pyplot **as** plt                             |
| >                                                                     |
| > **from** scipy **import** stats                                     |
| >                                                                     |
| > relative_path = \"winemag-data_first150k.csv\"\                     |
| > absolute_path = os.path.abspath(relative_path)                      |
| >                                                                     |
| > wine_dataset_original = pd.read_csv(absolute_path, sep = \',\')     |
| >                                                                     |
| > wine_dataset = wine_dataset_original.dropna(subset=\[\'price\'\])   |
| > wine_dataset.head()                                                 |
+=======================================================================+
| ![](vertopal_c0b099a1bf                                               |
| 474e9590819adae366c879/media/image90.png){width="6.113888888888889in" |
| height="1.5513877952755906in"}                                        |
+-----------------------------------------------------------------------+

+-----------------------+-----------------------+-----------------------+
| > **1. Типы данных и  |                       |                       |
| > создание новых      |                       |                       |
| > переменных:**       |                       |                       |
+=======================+=======================+=======================+
| > \- Определите и     |                       |                       |
| > классифицируйте     |                       |                       |
| > типы данных каждого |                       |                       |
| > столбца в наборе    |                       |                       |
| > данных.             |                       |                       |
| >                     |                       |                       |
| > \- Какие из них     |                       |                       |
| > категориальные?     |                       |                       |
| >                     |                       |                       |
| > \- Какие числовые?  |                       |                       |
| >                     |                       |                       |
| > Создайте новую      |                       |                       |
| > переменную          |                       |                       |
| > цена_за_балл,       |                       |                       |
| > разделив цену на    |                       |                       |
| > оценку, чтобы-\     |                       |                       |
| > анализировать       |                       |                       |
| > соотношение цены и  |                       |                       |
| > качества вин.       |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > **\# Типы данных**\ |                       |                       |
| > pr                  |                       |                       |
| int(wine_dataset.dtyp |                       |                       |
| es\[1:\].to_string()) |                       |                       |
| >                     |                       |                       |
| > **\# Категориальные |                       |                       |
| > переменные**\       |                       |                       |
| > categorical_vars =  |                       |                       |
| > wine_dataset.sel    |                       |                       |
| ect_dtypes(include=\[ |                       |                       |
| \'object\'\]).columns |                       |                       |
| > prin                |                       |                       |
| t(\"\\nКатегориальные |                       |                       |
| > переменные:\")\     |                       |                       |
| > for cat in          |                       |                       |
| > categorical_vars:\  |                       |                       |
| > print(cat)          |                       |                       |
| >                     |                       |                       |
| > **\# Числовые       |                       |                       |
| > переменные**\       |                       |                       |
| > numeric_vars =      |                       |                       |
| > wine_da             |                       |                       |
| taset.select_dtypes(i |                       |                       |
| nclude=\[\'float64\', |                       |                       |
| >                     |                       |                       |
|  \'int64\'\]).columns |                       |                       |
| > print(\"\\nЧисловые |                       |                       |
| > переменные:\")\     |                       |                       |
| > for num in          |                       |                       |
| >                     |                       |                       |
|  numeric_vars\[1:\]:\ |                       |                       |
| > print(num)          |                       |                       |
| >                     |                       |                       |
| > **\# Новая          |                       |                       |
| > переменная          |                       |                       |
| > price_per_point**\  |                       |                       |
| > w                   |                       |                       |
| ine_dataset.insert(11 |                       |                       |
| ,\'price_per_point\', |                       |                       |
| > wine                |                       |                       |
| _dataset\[\'price\'\] |                       |                       |
| > /                   |                       |                       |
| > wine_d              |                       |                       |
| ataset\[\'points\'\], |                       |                       |
| > False)              |                       |                       |
| > wine_dataset.head() |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > country object      | > **Категориальные    | > **Числовые          |
| >                     | > переменные:**       | > переменные:**       |
| > description object  | > country\            | > points\             |
| >                     | > description\        | > price               |
| > designation object  | > designation\        |                       |
| >                     | > province\           |                       |
| > points int64        | > region_1\           |                       |
| >                     | > region_2\           |                       |
| > price float64       | > variety\            |                       |
| >                     | > winery              |                       |
| > province object     |                       |                       |
| >                     |                       |                       |
| > region_1 object     |                       |                       |
| >                     |                       |                       |
| > region_2 object     |                       |                       |
| >                     |                       |                       |
| > variety object      |                       |                       |
| >                     |                       |                       |
| > winery object       |                       |                       |
+-----------------------+-----------------------+-----------------------+
| ![](vert              |                       |                       |
| opal_c0b099a1bf474e95 |                       |                       |
| 90819adae366c879/medi |                       |                       |
| a/image91.png){width= |                       |                       |
| "6.102777777777778in" |                       |                       |
| height="1             |                       |                       |
| .9472222222222222in"} |                       |                       |
+-----------------------+-----------------------+-----------------------+

+-----------------------------------+-----------------------------------+
| **2. Генеральная совокупность и   |                                   |
| выборка, частотные таблицы и      |                                   |
| распределения:**                  |                                   |
+===================================+===================================+
| > \- Сформируйте частотную        |                                   |
| > таблицу для переменной          |                                   |
| > \'страна\', чтобы увидеть       |                                   |
| > количество отзывов по каждой    |                                   |
| > стране.                         |                                   |
| >                                 |                                   |
| > \- Выберите случайную выборку   |                                   |
| > из 100 строк и сравните среднюю |                                   |
| > цену с ценой по всему набору    |                                   |
| > данных.                         |                                   |
| >                                 |                                   |
| > \- Хорошо ли выборка            |                                   |
| > представляет собой всю          |                                   |
| > совокупность?                   |                                   |
+-----------------------------------+-----------------------------------+
| > **\# Частотная таблица для      |                                   |
| > переменной \'country\'**\       |                                   |
| > country_counts =                |                                   |
| > wine_dataset\[\'count           |                                   |
| ry\'\].value_counts().to_string() |                                   |
| > print(country_counts)           |                                   |
| >                                 |                                   |
| > **\# Случайная выборка из 100   |                                   |
| > строк**\                        |                                   |
| > sample =                        |                                   |
| > wine_dataset.sample(n=100,      |                                   |
| > random_state=42)                |                                   |
| > sample_mean_price =             |                                   |
| > sample\[\'price\'\].mean()\     |                                   |
| > overall_mean_price =            |                                   |
| >                                 |                                   |
|  wine_dataset\[\'price\'\].mean() |                                   |
| >                                 |                                   |
| > print(f\"\\nСредняя цена в      |                                   |
| > выборке:                        |                                   |
| > {sample_mean_price:.2f}\")\     |                                   |
| > print(f\"Средняя цена в наборе  |                                   |
| > данных:                         |                                   |
| > {overall_mean_price:.2f}\")     |                                   |
| > print(f\"Отношение средней цены |                                   |
| > в выборке к средней цене в      |                                   |
| > наборе:                         |                                   |
| > {sample_mean                    |                                   |
| _price/overall_mean_price:.2f}\") |                                   |
+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e       | > **Средняя цена в выборке:**     |
| 9590819adae366c879/media/image92. | > 30.38\                          |
| png){width="1.8013877952755906in" | > **Средняя цена в наборе         |
| height="5.458333333333333in"}     | > данных:** 33.13\                |
|                                   | > **Отношение средней цены в      |
|                                   | > выборке к средней цене          |
|                                   | > внаборе:** 0.92                 |
+-----------------------------------+-----------------------------------+
|                                   | > 30.38/33.13 \* 100% = 92%       |
|                                   | >                                 |
|                                   | > Несмотря на близость            |
|                                   | > результатов, стоит заметить,    |
|                                   | > чтовыборка 100 из 150 000       |
|                                   | > слишком маленькая, чтобы        |
|                                   | > бытьрепрезентативной, из-за     |
|                                   | > возможного отсутствия           |
|                                   | > точностипри выборе другой сотни |
|                                   | > строк                           |
+-----------------------------------+-----------------------------------+

+-----------------------+-----------------------+-----------------------+
| > **3. Описательные   |                       |                       |
| > статистики:**       |                       |                       |
+=======================+=======================+=======================+
| > \- Рассчитайте      |                       |                       |
| > описательные        |                       |                       |
| > статистики для      |                       |                       |
| > числовых переменных |                       |                       |
| > (среднее, медиана,  |                       |                       |
| > мода, размах,       |                       |                       |
| > дисперсия и         |                       |                       |
| > стандартное         |                       |                       |
| > отклонение).        |                       |                       |
| >                     |                       |                       |
| > \- Обсудите, какая  |                       |                       |
| > мера центральной    |                       |                       |
| > тенденции лучше     |                       |                       |
| > всего описывает     |                       |                       |
| > переменные оценки и |                       |                       |
| > цена и почему.      |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > **\# Описательные   |                       |                       |
| > статистики для      |                       |                       |
| > числовых            |                       |                       |
| > переменных**\       |                       |                       |
| > numeric_vars =      |                       |                       |
| > wine_da             |                       |                       |
| taset.select_dtypes(i |                       |                       |
| nclude=\[\'float64\', |                       |                       |
| > \'int               |                       |                       |
| 64\'\]).columns\[1:\] |                       |                       |
| >                     |                       |                       |
| > means =             |                       |                       |
| > wine_dataset\[n     |                       |                       |
| umeric_vars\].mean()\ |                       |                       |
| > medians =           |                       |                       |
| > wine_dataset\[num   |                       |                       |
| eric_vars\].median()\ |                       |                       |
| > modes =             |                       |                       |
| > wine                |                       |                       |
| _dataset\[numeric_var |                       |                       |
| s\].mode().iloc\[0\]\ |                       |                       |
| > ranges =            |                       |                       |
| > wine_dataset\[n     |                       |                       |
| umeric_vars\].max() - |                       |                       |
| > wine_dataset\       |                       |                       |
| [numeric_vars\].min() |                       |                       |
| > variances =         |                       |                       |
| > wine_dataset\[      |                       |                       |
| numeric_vars\].var()\ |                       |                       |
| > std_devs =          |                       |                       |
| > wine_dataset\       |                       |                       |
| [numeric_vars\].std() |                       |                       |
| >                     |                       |                       |
| > print(\"\\nСреднее  |                       |                       |
| > значение:\")\       |                       |                       |
| > pri                 |                       |                       |
| nt(means.to_string()) |                       |                       |
| >                     |                       |                       |
| > pr                  |                       |                       |
| int(\"\\nМедиана:\")\ |                       |                       |
| > print               |                       |                       |
| (medians.to_string()) |                       |                       |
| >                     |                       |                       |
| >                     |                       |                       |
|  print(\"\\nМода:\")\ |                       |                       |
| > pri                 |                       |                       |
| nt(modes.to_string()) |                       |                       |
| >                     |                       |                       |
| > p                   |                       |                       |
| rint(\"\\nРазмах:\")\ |                       |                       |
| > prin                |                       |                       |
| t(ranges.to_string()) |                       |                       |
| >                     |                       |                       |
| > prin                |                       |                       |
| t(\"\\nДисперсия:\")\ |                       |                       |
| > print(v             |                       |                       |
| ariances.to_string()) |                       |                       |
| >                     |                       |                       |
| > p                   |                       |                       |
| rint(\"\\nСтандартное |                       |                       |
| > отклонение:\")\     |                       |                       |
| > print(              |                       |                       |
| std_devs.to_string()) |                       |                       |
+-----------------------+-----------------------+-----------------------+
| > **Среднее           | > **Мода:**           | > **Дисперсия:**      |
| > значение:**\        | >                     | >                     |
| > points 87.787919    | > points 87.000000    | > points 10.379224    |
| > price 33.131482     | >                     | >                     |
| > price_per_point     | > price 20.000000     | > price 1319.326636   |
| > 0.371145            | >                     | >                     |
|                       | > price_per_point     | > price_per_point     |
|                       | > 0.229885            | > 0.148330            |
+-----------------------+-----------------------+-----------------------+
| > **Медиана:**        | > **Размах:**         | > **Стандартное       |
| >                     | >                     | > отклонение:**       |
| > points 88.000000    | > points 20.000000    | >                     |
| >                     | >                     | > points 3.221680     |
| > price 24.000000     | > price 2296.000000   | >                     |
| >                     | >                     | > price 36.322536     |
| > price_per_point     | > price_per_point     | >                     |
| > 0.275862            | > 23.185812           | > price_per_point     |
|                       |                       | > 0.385137            |
+-----------------------+-----------------------+-----------------------+
| > **points**: размах  |                       |                       |
| > данной переменной - |                       |                       |
| > 20 и судя по тому,  |                       |                       |
| > что минимальное     |                       |                       |
| > значениеуказано как |                       |                       |
| > 80, а в целом       |                       |                       |
| > результат оценки    |                       |                       |
| > находится в         |                       |                       |
| > промежутке от 1 до  |                       |                       |
| > 100                 |                       |                       |
| >                     |                       |                       |
|  логичнопредположить, |                       |                       |
| > что рассматриваются |                       |                       |
| > только значения от  |                       |                       |
| > 80 до 100, причем   |                       |                       |
| > толькоцелые.        |                       |                       |
| > Среднее значение,   |                       |                       |
| > медиана и мода      |                       |                       |
| > близки друг к другу |                       |                       |
| > и могут быть\       |                       |                       |
| > рассмотрены как     |                       |                       |
| > подходящие меры     |                       |                       |
| > центральной         |                       |                       |
| > тенденции, однако   |                       |                       |
| > больше              |                       |                       |
| > всегоподходят       |                       |                       |
| > медиана и мода,     |                       |                       |
| > т.к. в оценке       |                       |                       |
| > используются именно |                       |                       |
| > целые значения      |                       |                       |
| >                     |                       |                       |
| > **price**: размах   |                       |                       |
| > этой переменной     |                       |                       |
| > гораздо больше, чем |                       |                       |
| > у прошлой и можно   |                       |                       |
| > заметить,           |                       |                       |
| > чтостандартное      |                       |                       |
| > отклонение          |                       |                       |
| > значительное,       |                       |                       |
| > поэтому в качестве  |                       |                       |
| > подходящей          |                       |                       |
| > мерыцентральной     |                       |                       |
| > тенденции стоит     |                       |                       |
| > рассмотреть медиану |                       |                       |
+-----------------------+-----------------------+-----------------------+

+-----------------------------------------------------------------------+
| > **4. Z-оценка и выбросы:**                                          |
+=======================================================================+
| > \- Рассчитайте Z-баллы для переменной цена, чтобы определить        |
| > выбросы.                                                            |
| >                                                                     |
| > \- Какой порог вы бы использовали и почему?                         |
| >                                                                     |
| > \- Как выбросы влияют на набор данных?                              |
| >                                                                     |
| > \- Следует ли их удалять или оставить для анализа?                  |
+-----------------------------------------------------------------------+
| > **\# Вычисление Z-оценок для переменной \"price\"**\                |
| > z_scores = (wine_dataset\[\'price\'\] -                             |
| > wine_dataset\[\'price\'\].mean()) / wine_dataset\[\'price\'\].std() |
| >                                                                     |
| > **\# Определение выбросов с использованием порога в 2.5 стандартных |
| > отклонений**outliers = (z_scores \< -2.5) \| (z_scores \> 2.5)      |
| >                                                                     |
| > **\# Вывод количества выбросов**\                                   |
| > print(f\"Количество выбросов: {outliers.sum()}\")                   |
| >                                                                     |
| > **\# Удаление выбросов**\                                           |
| > wine_dataset_cleaned = wine_dataset.loc\[\~outliers\]               |
+-----------------------------------------------------------------------+
| > **Количество выбросов:** 2475                                       |
+-----------------------------------------------------------------------+
| > **Влияние выбросов на набор данных:** Выбросы могут существенно     |
| > повлиять наразличные статистические характеристики набора данных,   |
| > такие как:\                                                         |
| > ● **Среднее значение** - может быть сильно смещено в сторону        |
| > выбросов ● **Дисперсия и стандартное отклонение** - могут быть      |
| > завышены из-за влияния выбросов\                                    |
| > ●\                                                                  |
| > **Корреляции между переменными** - могут быть                       |
| > искаженыСледовательно, выбросы могут серьезно исказить результаты   |
| > последующего анализаданных.                                         |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **5. Корреляция:**                                                  |
+=======================================================================+
| > \- Вычислите матрицу корреляции для числовых переменных.            |
| >                                                                     |
| > \- Какие пары показывают наивысшую корреляцию?                      |
+-----------------------------------------------------------------------+
| > **\# Матрица корреляции для числовых переменных**corr_matrix =      |
| > wine_dataset_cleaned\[numeric_vars\].corr() print(corr_matrix)      |
| >                                                                     |
| > **\# Матрица-маска для того, чтобы оставить только один треугольник |
| > (в данном случаенижний), т.к. главная диагональ не содержит важной  |
| > информации а относительнодиагонали значения симметричны**\          |
| > mask_matrix = np.triu(wine_dataset_cleaned\[numeric_vars\].corr())\ |
| > plt.figure(figsize=(10, 8))\                                        |
| > plt.title(\'Корреляционная матрица\')\                              |
| > sns.heatmap(corr_matrix, annot=True, cmap=\"YlGnBu\",               |
| > mask=mask_matrix)\                                                  |
| > plt.show()                                                          |
+-----------------------------------------------------------------------+
| +---------------+---------------+---------------+---------------+     |
| | > **points**  | > **points**  | > **price**   | > **pric      |     |
| |               |               |               | e_per_point** |     |
| +===============+===============+===============+===============+     |
| |               | 1.000000      | 0.554296      | > 0.515991    |     |
| +---------------+---------------+---------------+---------------+     |
| | > **price**   | 0.554296      | 1.000000      | > 0.998336    |     |
| +---------------+---------------+---------------+---------------+     |
| | > **pric      | 0.515991      | 0.998336      | > 1.000000    |     |
| | e_per_point** |               |               |               |     |
| +---------------+---------------+---------------+---------------+     |
+-----------------------------------------------------------------------+
| > ![](vertopal_c0b099a1bf                                             |
| 474e9590819adae366c879/media/image93.png){width="5.144444444444445in" |
| > height="4.5625in"}                                                  |
+-----------------------------------------------------------------------+
| > ● price & points - 0.55 наблюдается умеренная положительная         |
| > корреляция                                                          |
| >                                                                     |
| > ● price & price_per_point - 0.99 наблюдается очень сильная          |
| > положительная корреляция                                            |
| >                                                                     |
| > ● points & price_per_point - 0.52 наблюдается умеренная             |
| > положительная корреляция                                            |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **6. Введение в визуализацию данных:**                              |
+=======================================================================+
| > \- Создайте гистограмму для переменной оценки и диаграмму размаха   |
| > для                                                                 |
| >                                                                     |
| > переменной цена.                                                    |
+-----------------------------------------------------------------------+
| > **\# Гистограмма для переменной points**\                           |
| > plt.figure(figsize=(8, 6))\                                         |
| > plt.title(\'Гистограмма для points\')\                              |
| > sns.histplot(data=wine_dataset_cleaned, x=\"points\", bins=20)      |
| > plt.xticks(range(80,101))\                                          |
| > plt.show()                                                          |
| >                                                                     |
| > **\# Диаграмма размаха для переменной price**                       |
| > plt.figure(figsize=(8, 6))\                                         |
| > plt.title(\'Диаграмма размаха для переменной price\')               |
| > sns.boxplot(y=\'price\', data=wine_dataset_cleaned) plt.show()      |
+-----------------------------------------------------------------------+
| > ![](vertopal_c0b099a1bf4                                            |
| 74e9590819adae366c879/media/image94.png){width="3.6555555555555554in" |
| > height="2.7916666666666665in"}                                      |
| >                                                                     |
| > ![](vertopal_c0b099a1bf4                                            |
| 74e9590819adae366c879/media/image95.png){width="3.6555555555555554in" |
| > height="2.676388888888889in"}                                       |
+-----------------------------------------------------------------------+
| > По гистограмме переменной points видно, что результаты являются     |
| > примеромнормального распределения                                   |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **7. Продвинутая визуализация данных:**                             |
+=======================================================================+
| > \- Постройте диаграмму рассеяния, чтобы визуализировать взаимосвязь |
| > между                                                               |
| >                                                                     |
| > ценой и оценками.                                                   |
| >                                                                     |
| > \- Используйте цветовую кодировку, чтобы различать страны.          |
+-----------------------------------------------------------------------+
| ![](vertopal_c0b099a1bf                                               |
| 474e9590819adae366c879/media/image96.png){width="6.083332239720035in" |
| height="6.083333333333333in"}                                         |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **8. Введение в тестирование гипотез, непараметрические критерии:** |
+=======================================================================+
| > \- Проведите тест Манна-Уитни для сравнения распределения оценок    |
| > между                                                               |
| >                                                                     |
| > винами из США и Франции.                                            |
| >                                                                     |
| > \- Что можно сделать вывод из результатов?                          |
+-----------------------------------------------------------------------+
| > **\# Выборка вин из США и Франции**\                                |
| > usa_wines =                                                         |
| > wine_dataset_cleaned\[wine_dataset_cleaned\[\'country\'\] ==        |
| > \'US\'\] france_wines =                                             |
| > wine_dataset_cleaned\[wine_dataset_cleaned\[\'country\'\] ==        |
| > \'France\'\]                                                        |
| >                                                                     |
| > **\# Тест Манна-Уитни**\                                            |
| > stat, p_value = stats.mannwhitneyu(usa_wines\[\'points\'\],         |
| > france_wines\[\'points\'\]) print(f\"Статистика теста Манна-Уитни:  |
| > {stat:.2f}\")\                                                      |
| > print(f\"Значение p: {p_value:.4f}\")                               |
+-----------------------------------------------------------------------+
| > **Статистика теста Манна-Уитни:** 386633317.00**Значение p:**       |
| > 0.0000                                                              |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **9. Параметрические критерии для тестирования гипотез:**           |
+=======================================================================+
| > \- Выполните t-тест для сравнения средней цены вин из Калифорнии и  |
| >                                                                     |
| > Орегона.                                                            |
| >                                                                     |
| > \- Существенно ли они различаются?                                  |
+-----------------------------------------------------------------------+
| > **\# Выборка вин из Калифорнии и Орегона**\                         |
| > california_wines =                                                  |
| > wine_dataset_cleaned\[wine_dataset_cleaned\[\'province\'\] ==       |
| > \'California\'\].dropna(subset=\[\'price\'\])\                      |
| > oregon_wines =                                                      |
| > wine_dataset_cleaned\[wine_dataset_cleaned\[\'province\'\] ==       |
| > \'Oregon\'\].dropna(subset=\[\'price\'\])                           |
| >                                                                     |
| > **\# Т-тест**\                                                      |
| > stat, p_value = stats.ttest_ind(california_wines\[\'price\'\],      |
| > oregon_wines\[\'price\'\]) print(f\"Статистика t-теста:             |
| > {stat:.2f}\")\                                                      |
| > print(f\"Значение p: {p_value:.4f}\")                               |
+-----------------------------------------------------------------------+
| > **Статистика t-теста:** -1.17\                                      |
| > **Значение p:** 0.2417                                              |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **10. Линейная регрессия:**                                         |
+=======================================================================+
| > \- Постройте модель линейной регрессии для прогнозирования цены на  |
| > основе                                                              |
| >                                                                     |
| > оценок.                                                             |
| >                                                                     |
| > \- Каково значение R² и как оно интерпретируется?                   |
+-----------------------------------------------------------------------+
| > from sklearn.linear_model import LinearRegression                   |
| >                                                                     |
| > **\# Разделение на входные данные (X) и целевую переменную (y)** X  |
| > = wine_dataset_cleaned\[\[\'points\'\]\]\                           |
| > y = wine_dataset_cleaned\[\'price\'\]                               |
| >                                                                     |
| > **\# Создание и обучение модели линейной регрессии**model =         |
| > LinearRegression()\                                                 |
| > model.fit(X, y)                                                     |
| >                                                                     |
| > **\# Оценка модели**\                                               |
| > r_squared = model.score(X, y)\                                      |
| > print(f\"Коэффициент детерминации (R²): {r_squared:.2f}\")          |
+-----------------------------------------------------------------------+
| > Коэффициент детерминации (R²): 0.31                                 |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **11. Логистическая регрессия:**                                    |
+=======================================================================+
| > \- Используя логистическую регрессию, предскажите, является ли вино |
| > из США                                                              |
| >                                                                     |
| > на основе его оценок и цены.                                        |
| >                                                                     |
| > \- Обсудите точность модели.                                        |
+-----------------------------------------------------------------------+
| > from sklearn.linear_model import LogisticRegression                 |
| >                                                                     |
| > **\# Разделение на входные данные (X) и целевую переменную (y)** X  |
| > = wine_dataset_cleaned\[\[\'points\', \'price\'\]\]\                |
| > y = (wine_dataset_cleaned\[\'country\'\] == \'US\').astype(int)     |
| >                                                                     |
| > **\# Создание и обучение модели логистической регрессии**model =    |
| > LogisticRegression()\                                               |
| > model.fit(X, y)                                                     |
| >                                                                     |
| > **\# Оценка модели**\                                               |
| > accuracy = model.score(X, y)\                                       |
| > print(f\"Точность модели: {accuracy:.2f}\")                         |
+-----------------------------------------------------------------------+
| > **Точность модели:** 0.55                                           |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > **12. Задача классификации:**                                       |
+=======================================================================+
| > \- Постройте классификатор дерева решений, чтобы различать красные  |
| > и                                                                   |
|                                                                       |
| белые вина, используя подходящие характеристики из набора данных.     |
+-----------------------------------------------------------------------+
| > from sklearn.tree import DecisionTreeClassifier from                |
| > sklearn.model_selection import train_test_split from                |
| > sklearn.metrics import accuracy_score                               |
| >                                                                     |
| > **\# Разделение на входные данные (X) и целевую переменную (y)** X  |
| > = wine_dataset_cleaned\[\[\'points\', \'price\'\]\]\                |
| > y =                                                                 |
| > (w                                                                  |
| ine_dataset_cleaned\[\'variety\'\].str.contains(\'Red\')).astype(int) |
| >                                                                     |
| > **\# Разделение на обучающую и тестовую выборки**\                  |
| > X_train, X_test, y_train, y_test = train_test_split(X, y,           |
| > test_size=0.2, random_state=42)                                     |
| >                                                                     |
| > **\# Создание и обучение классификатора дерева решений**model =     |
| > DecisionTreeClassifier()\                                           |
| > model.fit(X_train, y_train)                                         |
| >                                                                     |
| > **\# Оценка модели**\                                               |
| > y_pred = model.predict(X_test)\                                     |
| > accuracy = accuracy_score(y_test, y_pred)\                          |
| > print(f\"Точность классификатора дерева решений: {accuracy:.2f}\")  |
+-----------------------------------------------------------------------+
| > **Точность классификатора дерева решений:** 0.88                    |
+-----------------------------------------------------------------------+

> (17.05.24) Семинар 4.2
>
> (21.05.24) Лекция 4.3

+-----------------------------------+-----------------------------------+
| > **Анализ данных**\              | > ![](vertopal_c0b099a1bf474e     |
| > ● Исследуйте данные ● Проверьте | 9590819adae366c879/media/image97. |
| > качество ● Найдите выбросы      | png){width="2.5194433508311462in" |
| >                                 | > height="2.5208333333333335in"}  |
| > Начинается с первоначального    |                                   |
| > сбора\                          |                                   |
| > данных и переходит к            |                                   |
| > действиям,\                     |                                   |
| > направленным на ознакомление с  |                                   |
| > данными,выявление проблем с     |                                   |
| > качеством данных,обнаружение    |                                   |
| > первых сведений о данных        |                                   |
| > илиобнаружение интересных       |                                   |
| > подмножеств дляформирования     |                                   |
| > гипотез относительно\           |                                   |
| > скрытой информации.             |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Анализ Данных**\
> **●Собрать исходные данные**\
> ○ получить в рамках проекта данные, перечисленные в ресурсах проекта ○
> включает загрузку данных, если это необходимо для понимания данных ○
> возможно, приводит к этапам подготовки начальных данных\
> ○ при получении нескольких источников данных интеграция является
> дополнительной проблемой либо здесь, либо на более позднем этапе
> подготовки данных
>
> **●Описать данные**\
> **○** исследовать «грубые» или «поверхностные» свойства полученных
> данных **○** отчет о результатах
>
> **Сбор Данных**\
> 1. Перечислите нужные данные и укажите, сколько их необходимо.
>
> 2\. Найдите и документируйте места, где можно получить данные.
>
> 3\. Выясните объем пространства, которое займут данные.
>
> Ознакомьтесь с правовыми обязательствами и при необходимости
> получите4.
>
> разрешение.
>
> 5\. Получите права доступа.
>
> 6\. Создайте рабочее пространство (с хранилищем достаточного объема).
>
> 7\. Получите данные.
>
> 8\. Представьте данные в формате, который позволяет легко
> манипулировать данными (не изменяя сами данные).
>
> 9\. Удостоверьтесь в том, что конфиденциальная информация удалена или
> защищена (например, анонимизирована).
>
> 10\. Выясните размер и тип данных (временной ряд, выборка,
> географические данные и т.д.).
>
> 11\. Произведите выборку испытательного набора, отложите его в сторону
> и никогда не смотрите на него
>
> **Анализ данных**\
> **Исследуйте данные**\
> **●** **решает вопросы интеллектуального анализа данных, которые
> можно** **решить с помощью запросов, визуализации и отчетов,
> включая:**

+-----------------------+-----------------------+-----------------------+
| **●**                 | ○                     | > распределение       |
|                       |                       | > ключевых атрибутов, |
+=======================+=======================+=======================+
|                       | ○                     | > результаты простых  |
|                       |                       | > агрегаций           |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > отношения между     |
|                       |                       | > парами или          |
|                       |                       | > небольшим           |
|                       |                       | > количеством         |
|                       |                       | > атрибутов           |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > свойства значимых   |
|                       |                       | > субпопуляций,       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > простой             |
|                       |                       | > статистический      |
|                       |                       | > анализ              |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > может напрямую      |
|                       |                       | > касаться целей      |
|                       |                       | > интеллектуального   |
|                       |                       | > анализа данных      |
+-----------------------+-----------------------+-----------------------+
|                       | > **может напрямую    |                       |
|                       | > касаться целей      |                       |
|                       | > интеллектуального   |                       |
|                       | > анализа данных**    |                       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > может               |
|                       |                       | > способствовать или  |
|                       |                       | > улучшать описание   |
|                       |                       | > данных и отчеты о   |
+-----------------------+-----------------------+-----------------------+

> качестве\
> ○ может использоваться для преобразования и другой необходимой
> подготовки данных\
> **●** **Проверить качество данных**\
> ○ изучить качество данных, ответив на такие вопросы, как: «Полны ли
> данные?», Есть ли в данных пропущенные значения?»
>
> **Описание данных**\
> 1. Создайте копию данных для исследования (при необходимости производя
> выборку, чтобы получить поддающийся управлению размер).
>
> 2\. Создайте тетрадь Jupyter для сохранения записи об исследовании
> данных.
>
> 3\. Изучите каждый атрибут и его характеристики:\
> - имя;\
> - тип (категориальный, целочисленный/с плавающей точкой,\
> ограниченный/неограниченный, текстовый, структурированный и т.д.);

+-----------------------+-----------------------+-----------------------+
| > 4.\                 | \-                    | > процент             |
| > 5.\                 |                       | > отсутствующих       |
| > 6.\                 |                       | > значений;           |
| > 7.                  |                       |                       |
+=======================+=======================+=======================+
|                       | \-                    | > возможная польза    |
|                       |                       | > для задачи;         |
+-----------------------+-----------------------+-----------------------+
|                       | \-                    | > тип распределения   |
|                       |                       | > (гауссово,          |
|                       |                       | > равномерное,        |
|                       |                       | > логарифмическое и   |
|                       |                       | > т.д.).              |
+-----------------------+-----------------------+-----------------------+
|                       | > Визуализируйте      |                       |
|                       | > данные.             |                       |
|                       | >                     |                       |
|                       | > Исследуйте          |                       |
|                       | > взаимосвязи между   |                       |
|                       | > атрибутами.         |                       |
|                       | >                     |                       |
|                       | > Идентифицируйте     |                       |
|                       | > дополнительные      |                       |
|                       | > данные, которые     |                       |
|                       | > могут быть          |                       |
|                       | > по                  |                       |
|                       | лезнымиДокументируйте |                       |
|                       | > все, что вы узнали  |                       |
+-----------------------+-----------------------+-----------------------+

> **Подготовка данных (Data preparation)**

  ----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image98.png){width="5.480555555555555in"
  height="2.875in"}
  ----------------------------------------------------------------------------------------------

  ----------------------------------------------------------------------------------------------

  ----------------------------------- -----------------------------------

  ----------------------------------- -----------------------------------

> **Работа с пропущенными значениями**\
> **Типы пропусков**\
> - **Полностью случайные пропуски** (missing completely at random,
> MCAR) предполагают, что вероятность появления пропуска никак не
> связана с\
> данными. Такие пропуски возникают, например, если измерительный прибор
> неисправен и случайным образом не записал часть наблюдений, или если
> один из образцов крови, изучаемых в лаборатории, оказался поврежден и
> по этой причине его характеристики выпали из исследования.
>
> \- **Случайные пропуски** (missing at random, MAR) - вероятность
> появления пропуска зависит от некоторой известной нам переменной.
> Например,\
> отсутствие ответа на определенный вопрос анкеты может зависеть от
> возраста респондента. Молодые охотнее отвечают на вопрос, люди более
> пожилого возраста скорее избегают ответа.
>
> \- **Неслучайные пропуски** (missing not at random, MNAR) -
> вероятность\
> появления пропуска зависит, в том числе, от фактора, о котором мы
> ничего не знаем. Например, у весов может быть верхний предел измерения
> и любой образец выше этого предела автоматически не записывается. В
> опросах общественного мнения MNAR возникает, когда люди с более
> активной\
> жизненной позицией (переменная, которую мы не измеряем) чаще дают
> ответы на вопросы интервьюера.
>
> **Выявление пропусков**

+-----------------------------------+-----------------------------------+
|   ----------------------------    |   -----------------------------   |
| --------------------------------- | --------------------------------- |
| --------------------------------- | --------------------------------- |
|   ![](vertopal_c0b099a1bf474      |   ![](vertopal_c0b099a1bf474e     |
| e9590819adae366c879/media/image99 | 9590819adae366c879/media/image100 |
| .png){width="2.698611111111111in" | .png){width="2.738888888888889in" |
|   height="2.0625in"}              |   height="1.5833333333333333in"}  |
|   ----------------------------    |   -----------------------------   |
| --------------------------------- | --------------------------------- |
| --------------------------------- | --------------------------------- |
|                                   |                                   |
|   ----------------------------    |   -----------------------------   |
| --------------------------------- | --------------------------------- |
| --------------------------------- | --------------------------------- |
+===================================+===================================+
|   ------------------------------  |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|   ![](vertopal_c0b099a1bf474e9    |                                   |
| 590819adae366c879/media/image101. |                                   |
| png){width="3.2291666666666665in" |                                   |
|   height="1.9694444444444446in"}  |                                   |
|   ------------------------------  |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
|                                   |                                   |
|   ------------------------------  |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+-----------------------------------+-----------------------------------+

> **Что собственно делаем?**
>
> **Удаление строк** (deleting rows или listwise deletion, также
> называется анализом полныхнаблюдений, complete case analysis), в
> которых есть пропуски - наиболее очевидныйподход к работе с
> пропущенными значениями. Рассмотрим этот способ на практике.

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image102.png){width="4.656944444444444in"
  height="1.3444433508311462in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Удаляем все и идем спать**\
> **Удаление столбцов** (column deletion) несложно выполнить с помощью
> метода .drop().Например, удалим столбец Cabin, в котором более 77
> процентов пропусков.

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image103.png){width="4.605555555555555in"
  height="1.5513877952755906in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Или заполняем пропуски**\
> **Заполнение константой**\
> **Количественные данные.** Самый простой способ работы с пропусками в\
> количественных данных - заполнить пропуски константой. Например, нулем
> (подходитдля алгоритмов, чувствительных к масштабу признаков).

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image104.png){width="4.656944444444444in"
  height="1.0722222222222222in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Категориальные данные.** Для категориальных признаков в некоторых
> случаях можнопровести дополнительное исследование. В частности, в
> датасете «Титаник» есть двапассажира с неизвестным портом посадки.
> Заполнить модельным.

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image105.png){width="4.666666666666667in"
  height="1.4791666666666667in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Заполнение средним арифметическим или медианой**

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image106.png){width="4.990277777777778in"
  height="1.6972222222222222in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

+-----------------------------------+-----------------------------------+
| > ![](vertopal_c0b099a1bf474e9    | ![](vertopal_c0b099a1bf474e       |
| 590819adae366c879/media/image107. | 9590819adae366c879/media/image108 |
| png){width="2.7805555555555554in" | .png){width="2.613888888888889in" |
| > height="1.7402777777777778in"}  | height="1.6666666666666667in"}    |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Заполнение внутригрупповым значением**

  ------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image109.png){width="3.6569444444444446in"
  height="2.1569444444444446in"}
  ------------------------------------------------------------------------------------------------

  ------------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image110.png){width="5.261111111111111in"
  height="0.6875in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

  ------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image111.png){width="2.9069444444444446in"
  height="1.8222211286089238in"}
  ------------------------------------------------------------------------------------------------

  ------------------------------------------------------------------------------------------------

> **Метрики**\
> **Самые часто используемые метрики**

+-----------------------------------+-----------------------------------+
| > ●\                              | > **Classification Metrics**      |
| > ●\                              | > (accuracy, precision, recall,   |
| > ●\                              | > F1-score, ROC, AUC, ...)        |
| > ●\                              | > **Regression Metrics** (MSE,    |
| > ●\                              | > MAE)\                           |
| > ●\                              | > **Ranking Metrics** (MRR, DCG,  |
| > ●                               | > NDCG)\                          |
|                                   | > **Statistical Metrics**         |
|                                   | > (Correlation)\                  |
|                                   | > **Computer Vision Metrics**     |
|                                   | > (PSNR, SSIM, IoU)\              |
|                                   | > **NLP Metrics** (Perplexity,    |
|                                   | > BLEU score)\                    |
|                                   | > **Deep Learning Related         |
|                                   | > Metrics** (Inception score,     |
|                                   | > Frechet Inception distance)     |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Classification Metrics**\
> **Confusion Matrix**\
> Не метрика, но знать надо!

+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e       |                                   |
| 9590819adae366c879/media/image112 |                                   |
| .png){width="6.083332239720035in" |                                   |
| height="2.531943350831146in"}     |                                   |
+===================================+===================================+
| ![](vertopal_c0b099a1bf474e9      | ![](vertopal_c0b099a1bf474e9      |
| 590819adae366c879/media/image113. | 590819adae366c879/media/image114. |
| png){width="2.5611100174978128in" | png){width="3.2819444444444446in" |
| height="3.0527777777777776in"}    | height="2.083332239720035in"}     |
|                                   |                                   |
|                                   | > Чувствительность и              |
|                                   | > Специфичность                   |
+-----------------------------------+-----------------------------------+

+-----------------------------------------------------------------------+
| > ![](vertopal_c0b099a1bf47                                           |
| 4e9590819adae366c879/media/image115.png){width="5.8069444444444445in" |
| > height="1.7444444444444445in"}                                      |
|                                                                       |
|   ------------------------------------------------------------------  |
|                                                                       |
|   ------------------------------------------------------------------  |
+=======================================================================+
+-----------------------------------------------------------------------+

> 1100 изображений (1000 не-котов, и 100 котов) - P = 100, N = 1000

+-----------------------------------+-----------------------------------+
| > **1.** 𝑇𝑃𝑅 = 𝑇𝑃𝑃                | > **2.** 𝐹𝑁𝑅 = 𝐹𝑁𝑃                |
| >                                 | >                                 |
| > True positive rate (TPR),       | > False negative rate (FNR), miss |
| > recall, sensitivity             | > rate                            |
| >                                 |                                   |
| > (SEN), probability of           |                                   |
| > detection, hit rate, power      |                                   |
+===================================+===================================+
| > **3.** 𝑇𝑁𝑅 = 𝑇𝑁𝑁                | > **4.** 𝐹𝑃𝑅 = 𝐹𝑃𝑁                |
| >                                 | >                                 |
| > True negative rate (TNR),       | > False positive rate (FPR),      |
| > specificity (SPC),              | > probability of                  |
| >                                 | >                                 |
| > selectivity                     | > false alarm, fall-out           |
+-----------------------------------+-----------------------------------+

> **Accuracy (Точность ?)**\
> доля объектов, названных классификатором правильно (True Positive +
> True Negative)

  -----------------------------------------------------------------------
  𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦 =                          𝑇𝑜𝑡𝑎𝑙 𝑛𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛𝑠 𝑚𝑎𝑑𝑒 =
                                      𝑇𝑃 + 𝑇𝑁
  ----------------------------------- -----------------------------------

  -----------------------------------------------------------------------

> Не используется на несбалансированных датасетах. Почему?
>
> **Precision (Точность ?)**\
> доля объектов, названных классификатором положительными и при
> этомдействительно являющимися положительными

+-----------------------+-----------------------+-----------------------+
|                       | > 𝑁𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑇𝑟𝑢𝑒      | 𝑇𝑃                    |
|                       | > 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒            |                       |
|                       | > 𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛𝑠         |                       |
+=======================+=======================+=======================+
| 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 =           | 𝑇𝑜𝑡𝑎𝑙 𝑛𝑢𝑚𝑏𝑒𝑟 𝑜𝑓       | 𝑇𝑃 + 𝐹𝑃               |
|                       | 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒 𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛𝑠  |                       |
|                       | 𝑚𝑎𝑑𝑒 =                |                       |
+-----------------------+-----------------------+-----------------------+

> Precision_Cat = ? = 90 / (90 + 60) = 90 / 150 = 0.6\
> Precision_Non_Cat = ? = 940 / (940 + 10) = 940 / 950 = 0.99
>
> **Recall (Полнота)**\
> какую долю объектов положительного класса из всех объектов
> положительного классанашел алгоритм.

  -----------------------------------------------------------------------
  𝑁𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑇𝑟𝑢𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒                         𝑇𝑃
  𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛𝑠                                     
  ----------------------- ----------------------- -----------------------
  𝑅𝑒𝑐𝑎𝑙𝑙 = 𝑇𝑜𝑡𝑎𝑙 𝑛𝑢𝑚𝑏𝑒𝑟   =                       𝑇𝑃 + 𝐹𝑁
  𝑜𝑓 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒 𝑜𝑏𝑗𝑒𝑐𝑡𝑠                             

  -----------------------------------------------------------------------

> Recall \_Cat = 90 / (90 + 10) = 90 / 100 = 0.9\
> Recall \_Non_Cat = 940 / (940 + 60) = 940 / 1000 = 0.94
>
> **Recall** - способность алгоритма обнаруживать данный класс
> вообще**Precision** - способность отличать этот класс от других
> классов.
>
> **F-Beta Score (F - Мера)**

+-----------------+-----------------+-----------------+-----------------+
| 𝐹β = (1 + β2) · |                 |                 | 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 ·     |
|                 |                 |                 | 𝑅𝑒𝑐𝑎𝑙𝑙          |
+=================+=================+=================+=================+
|                 |                 |                 | β2 · 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛  |
|                 |                 |                 | · 𝑅𝑒𝑐𝑎𝑙𝑙        |
+-----------------+-----------------+-----------------+-----------------+
|                 | 2               | > 1             |                 |
+-----------------+-----------------+-----------------+-----------------+
| 𝐹1=             | 1               |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | 𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 +     | > 𝑟𝑒𝑐𝑎𝑙𝑙        |                 |
+-----------------+-----------------+-----------------+-----------------+

> β принимает значения в диапазоне
>
> \- 0 \< β \< 1 если приоритет отдается точности,
>
> \- β \> 1 приоритет отдается полноте.
>
> \- При β=1 сбалансированная F-мера (также ее называют F1).
>
> **F-Мера**

+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e9      | ![](vertopal_c0b099a1bf474e       |
| 590819adae366c879/media/image116. | 9590819adae366c879/media/image117 |
| png){width="2.9472222222222224in" | .png){width="2.958332239720035in" |
| height="2.0833333333333335in"}    | height="1.7805544619422573in"}    |
+===================================+===================================+
| > ![](vertopal_c0b099a1bf474e     |                                   |
| 9590819adae366c879/media/image118 |                                   |
| .png){width="5.905555555555556in" |                                   |
| > height="4.072221128608924in"}   |                                   |
+-----------------------------------+-----------------------------------+

> **ROC-кривая**\
> взаимосвязь между чувствительностью модели (TPR) и её специфичностью
> (FPR)
>
> **Порог Отсечения**

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image119.png){width="2.198611111111111in"
  height="1.5319433508311462in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Построение ROC Кривой**\
> Вектор вероятности принадлежности к классу\
> \[0.45, 0.6, 0.7, 0.3\]\
> cut-off= 0.5: predicted-labels= \[0,1,1,0\] (default threshold)\
> cut-off= 0.2: predicted-labels= \[1,1,1,1\]\
> cut-off= 0.8: predicted-labels= \[0,0,0,0\]

  ------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image120.png){width="2.1777777777777776in"
  height="1.4583333333333333in"}
  ------------------------------------------------------------------------------------------------

  ------------------------------------------------------------------------------------------------

> **ROC-кривая получается следующим образом:**\
> ● Для каждого значения порога отсечения, которое меняется от 0 до 1 с
> шагом d​(например, 0,01) рассчитываются значения чувствительности Se и\
> специфичности Sp.
>
> ● Строится график зависимости:\
> - по оси Y откладывается чувствительность Se,\
> - по оси X FPR=100−Sp - доля ложно положительных случаев.
>
> **Какая модель лучше?**

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image121.png){width="2.063888888888889in"
  height="1.7597222222222222in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **AUC**

+-----------------------------------+-----------------------------------+
| > area under the curve (AUC)\     |   ------------------------------  |
| > **AUC** - это вероятность того, | --------------------------------- |
| > что модель ранжируетслучайный   | --------------------------------- |
| > положительный пример выше,      |   ![](vertopal_c0b099a1bf474e9    |
| > чемслучайный отрицательный      | 590819adae366c879/media/image122. |
| > пример\                         | png){width="2.0722222222222224in" |
| > Площадь под ROC кривой\         |   height="1.7708333333333333in"}  |
| > Пределы значения AUC?           |   ------------------------------  |
| >                                 | --------------------------------- |
| > Зависит ли AUC от CUT-OFF?      | --------------------------------- |
|                                   |                                   |
|                                   |   ------------------------------  |
|                                   | --------------------------------- |
|                                   | --------------------------------- |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **AUC ROC**\
> Чем больше показатель AUC, тем лучшей прогностической силой обладает
> модель. ● показатель AUC предназначен скорее для сравнительного
> анализа нескольких моделей;\
> ● AUC не содержит никакой информации о чувствительности и
> специфичности модели.

+-----------------------------------+-----------------------------------+
| > **Интервал AUC**                | > **Качество модели**             |
+===================================+===================================+
| > 0,9-1,0                         | > Отличное                        |
+-----------------------------------+-----------------------------------+
| > 0,8-0,9                         | > Очень хорошее                   |
+-----------------------------------+-----------------------------------+
| > 0,7-0,8                         | > Хорошее                         |
+-----------------------------------+-----------------------------------+
| > 0,6-0,7                         | > Среднее                         |
+-----------------------------------+-----------------------------------+
| > 0,5-0,6                         | > Неудовлетворительное            |
+-----------------------------------+-----------------------------------+

> **Критерии выбора порога отсечения**\
> **1.** **Требование минимальной величины чувствительности
> (специфичности)** **модели.**
>
> Например, нужно обеспечить чувствительность теста не менее 80%. В
> этомслучае оптимальным порогом будет максимальная специфичность\
> (чувствительность), которая достигается при 80% (или значение, близкое
> к нему«справа» из-за дискретности ряда) чувствительности
> (специфичности).
>
> **2.** **Требование максимальной суммарной чувствительности и**
> **специфичности модели**
>
> 𝐶𝑢𝑡𝑡_𝑜𝑓𝑓𝑜= 𝑚𝑎𝑥𝑘(𝑆𝑒𝑘+ 𝑆𝑝𝑘)
>
> **3.** **Требование баланса между чувствительностью и специфичностью**
>
> 𝐶𝑢𝑡𝑡_𝑜𝑓𝑓𝑜= 𝑚𝑖𝑛𝑘\|𝑆𝑒𝑘+ 𝑆𝑝𝑘\|
>
> **Баланс чувствительности и
> специфичности**![](vertopal_c0b099a1bf474e9590819adae366c879/media/image124.png){width="4.368055555555555in"
> height="3.07757874015748in"}

  ------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image123.png){width="3.6055555555555556in"
  height="2.5625in"}
  ------------------------------------------------------------------------------------------------

  ------------------------------------------------------------------------------------------------

> **Многоклассовая Классификация**\
> **Матрица неточностей**\
> **macro-averaging**

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> Матрица неточностей (26 классов, результирующая точность - 0.8,
> результирующая полнота - 0.91)
>
> **Столбец** - экспертное решение\
> **Строка** - классификатор

+-----------------------+-----------------------+-----------------------+
| 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛𝑐=           |                       | 𝐴𝑐,𝑐                  |
+=======================+=======================+=======================+
|                       |                       | > 𝑛\                  |
|                       |                       | > ∑𝐴𝑐,𝑖𝑖=1            |
+-----------------------+-----------------------+-----------------------+
|                       | +------------------+  |                       |
|                       | | > 𝐴𝑐,𝑐           |  |                       |
|                       | +==================+  |                       |
|                       | +------------------+  |                       |
+-----------------------+-----------------------+-----------------------+
| 𝑅𝑒𝑐𝑎𝑙𝑙𝑐=              | > 𝑛\                  |                       |
|                       | > ∑𝐴𝑖,𝑐\              |                       |
|                       | > 𝑖=1                 |                       |
+-----------------------+-----------------------+-----------------------+

> **Regression Metrics**\
> **Mean Absolute Error** - Средняя Абсолютная Ошибка (MAE, mean
> absolute
> deviation)![](vertopal_c0b099a1bf474e9590819adae366c879/media/image125.png){width="3.1805555555555554in"
> height="0.5833333333333334in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image126.png){width="6.269444444444445in"
> height="0.9085378390201225in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image127.png){width="0.18055555555555555in"
> height="0.125in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image128.png){width="0.125in"
> height="0.16666666666666666in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image129.png){width="5.555555555555555e-2in"
> height="0.1111111111111111in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image130.png){width="1.1527777777777777in"
> height="0.2638888888888889in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image131.png){width="0.1388888888888889in"
> height="2.7777777777777776e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image132.png){width="0.1527777777777778in"
> height="4.1666666666666664e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image133.png){width="0.1388888888888889in"
> height="2.7777777777777776e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image134.png){width="0.1527777777777778in"
> height="8.333333333333333e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image135.png){width="0.1388888888888889in"
> height="8.333333333333333e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image136.png){width="0.375in"
> height="0.125in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image137.png){width="0.25in"
> height="0.16666666666666666in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image138.png){width="0.2222222222222222in"
> height="0.1388888888888889in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image139.png){width="0.2361111111111111in"
> height="0.2222222222222222in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image140.png){width="4.1666666666666664e-2in"
> height="0.2222222222222222in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image141.png){width="0.3472222222222222in"
> height="0.2222222222222222in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image142.png){width="0.2916666666666667in"
> height="0.2222222222222222in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image143.png){width="0.2361111111111111in"
> height="0.2222222222222222in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image144.png){width="0.2222222222222222in"
> height="0.2222222222222222in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image145.png){width="0.2361111111111111in"
> height="0.2638888888888889in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image146.png){width="0.2777777777777778in"
> height="0.4027777777777778in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image147.png){width="5.555555555555555e-2in"
> height="0.1111111111111111in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image148.png){width="0.9027777777777778in"
> height="0.2638888888888889in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image149.png){width="0.1527777777777778in"
> height="4.1666666666666664e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image150.png){width="0.18055555555555555in"
> height="0.18055555555555555in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image151.png){width="8.333333333333333e-2in"
> height="0.16666666666666666in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image152.png){width="0.2222222222222222in"
> height="0.20833333333333334in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image153.png){width="0.1111111111111111in"
> height="9.722222222222222e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image154.png){width="0.125in"
> height="9.722222222222222e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image155.png){width="0.2361111111111111in"
> height="0.18055555555555555in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image156.png){width="0.18055555555555555in"
> height="0.25in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image157.png){width="9.722222222222222e-2in"
> height="0.6388888888888888in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image158.png){width="9.722222222222222e-2in"
> height="0.6388888888888888in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image159.png){width="3.1569444444444446in"
> height="1.4911832895888013in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image160.png){width="0.1388888888888889in"
> height="0.2638888888888889in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image161.png){width="8.333333333333333e-2in"
> height="8.333333333333333e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image162.png){width="0.2777777777777778in"
> height="0.18055555555555555in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image163.png){width="0.1527777777777778in"
> height="0.18055555555555555in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image164.png){width="0.2361111111111111in"
> height="0.1527777777777778in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image165.png){width="0.16666666666666666in"
> height="5.555555555555555e-2in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image166.png){width="0.2777777777777778in"
> height="0.2222222222222222in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image167.png){width="0.3055555555555556in"
> height="0.3055555555555556in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image168.png){width="0.4166666666666667in"
> height="0.3472222222222222in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image169.png){width="0.1527777777777778in"
> height="0.125in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image170.png){width="0.4444444444444444in"
> height="0.2222222222222222in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image171.png){width="0.125in"
> height="0.2222222222222222in"}

+-----------------------------------+-----------------------------------+
| 𝑀𝐴𝐸=                              | > 𝑁\                              |
|                                   | > 1                               |
|                                   | >                                 |
|                                   | > 𝑁𝑖=1∑\|𝑦𝑖−ŷ𝑖\|                  |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> Насколько прогнозы были далеки от реальных значений.Направление
> ошибки? Мы переоценили или недооценили?
>
> **Mean Squared Error** - Средняя квадратичная ошибка (MSE)

+-----------------------------------+-----------------------------------+
| 𝑀𝑆𝐸=                              | > 𝑁\                              |
|                                   | > 1 2                             |
|                                   | >                                 |
|                                   | > 𝑁𝑖=1∑(𝑦𝑖−ŷ𝑖)                    |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> Какие недостатки MSE? Достоинства MSE?
>
> **Logistic Loss** - логистические потери

  -----------------------------------------------------------------------
  𝑙\
  𝑙𝑜𝑔𝑙𝑜𝑠𝑠=−1𝑙𝑖=1∑(𝑦𝑖· 𝑙𝑜𝑔(ŷ𝑖) + (1 −𝑦𝑖) · 𝑙𝑜𝑔(1 −ŷ𝑖))
  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> ŷ - это ответ алгоритма на i-ом объекте, y - истинная метка класса на
> i-ом объекте, аl - размер выборки
>
> **Что такое logloss?**
>
> Мы хотим получить **линейную логарифмическую функцию потерь** (т. e.
> Веса w),которая аппроксимирует целевое значение с точностью до ошибки:

+-----------------------------------------------------------------------+
|   ------------------------------------------------------------------  |
|   𝑦= 𝑤τ𝑥+ ε                                                           |
|   ------------------------------------------------------------------  |
|                                                                       |
|   ------------------------------------------------------------------  |
+=======================================================================+
| ε \~ 𝑛𝑜𝑟𝑚(0, σ2)                                                      |
+-----------------------------------------------------------------------+

> **Плотность распределения:**

+-----------------------+-----------------------+-----------------------+
| 𝑝(𝑦\|𝑥, 𝑤) =          | > 2 1⎡τ𝑥)             | > ⎤\                  |
|                       | >                     | > ⎥\                  |
|                       | > 2πσ 2𝑒𝑥𝑝−(𝑦−𝑤 ⎣ 2σ  | > ⎦                   |
|                       | > 2                   |                       |
+=======================+=======================+=======================+
+-----------------------+-----------------------+-----------------------+

> **Функция правдоподобия и оценка ее максимума:**

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> **Минимизация MSE**\
> метод стохастического градиента **(SGD)** для минимизации MSE:\
> нам нужно взять производную функции ошибки для конкретного объекта и
> записатьформулу коррекции веса в виде \"шага к антиградиенту\":

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image172.png){width="1.948611111111111in"
  height="1.2291666666666667in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Общий случай**

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image173.png){width="4.886111111111111in"
  height="1.2708333333333333in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Настройка логистической регрессии методом SGD**

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image174.png){width="2.761111111111111in"
  height="1.8222211286089238in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **МО**\
> **Общая схема машинного обучения**\
> **Пример задачи:**\
> Вы хотите купить себе дом\
> - Имеется несколько вариантов\
> - Хотим оценить стоимость каждого дома
>
> **Обозначения**\
> ● x - **объект**, **sample** - для чего хотим делать предсказания
> Конкретный дом
>
> ● y - ответ, **целевая переменная**, **target** - что предсказываем
> Стоимость дома

+-----------------------------------+-----------------------------------+
| ●                                 | > **Задача:** дом →стоимость      |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Обучающая выборка**\
> ● Мы ничего не понимаем в недвижимости\
> ● Зато имеем много объектов с известными ответами

+-----------------------------------+-----------------------------------+
|                                   |   ------------------------------  |
|                                   |   𝑝 𝑋= (𝑥𝑖 , 𝑦𝑖 )𝑖                |
|                                   |   ------------------------------  |
|                                   |                                   |
|                                   |   ------------------------------  |
+===================================+===================================+
| ●                                 | P - размер обучающей выборки      |
+-----------------------------------+-----------------------------------+

> **В нашем случае:** набор домов, проданных в том же городе за
> последние 2 года
>
> **Признаки**

+-----------------------------------+-----------------------------------+
| > ●\                              | > **Объекты** - абстрактные       |
| > ●\                              | > сущности\                       |
| > ●\                              | > Компьютеры работают только с    |
| > ●\                              | > числами\                        |
| > ●                               | > Признаки, факторы, features -   |
|                                   | > числовые характеристики         |
|                                   | > объектовd - количество          |
|                                   | > признаков\                      |
|                                   | > x = (x(, ... , xd) -            |
|                                   | > признаковое описание            |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Какие признаки могут быть использованы в нашем примере?**

+-----------------------+-----------------------+-----------------------+
| **●**                 | > **Информация о      |                       |
|                       | > самом доме:**       |                       |
| **●**                 |                       |                       |
+=======================+=======================+=======================+
|                       | ○                     | > Площадь             |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Год постройки       |
+-----------------------+-----------------------+-----------------------+
|                       | > **Информация о      |                       |
|                       | > рай                 |                       |
|                       | оне/местоположении:** |                       |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Удаленность от      |
|                       |                       | > центра              |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Рейтинг             |
|                       |                       | > безопасности района |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Уровень             |
|                       |                       | > экологичности       |
|                       |                       | > района              |
+-----------------------+-----------------------+-----------------------+

> **Алгоритм**\
> ● **a(x)** - алгоритм, модель - функция, предсказывающая ответ для
> любого объекта ● **Линейная модель:** a(x) = w0 + w1x1 + ... + wdxd\
> **●** **Например:**\
> a(x) = 1 000 000 + 100 000 \* (площадь) - 100 000 \* (расстояние до
> метро)
>
> **Функция потерь**\
> ● Не все алгоритмы полезны\
> ● a(x) = 0 - не принесет никакой выгоды\
> ● **Функция потерь** (или функционал качества) - мера корректности
> ответа алгоритма\
> ● Предсказали стоимость 15 млн, на самом деле 17 млн - хорошо или
> плохо?
>
> ● Функция потерь (или функционал качества) - мера корректности ответа
> алгоритма

+-----------------------------------+-----------------------------------+
| ●                                 | Среднеквадратичная ошибка (Mean   |
|                                   | Squared Error, MSE):              |
+===================================+===================================+
|                                   |   ------------------------------  |
|                                   |   𝑙\                              |
|                                   |   2 𝑀𝑆𝐸=1 𝑙𝑖=1∑(𝑎(𝑥𝑖) −𝑦𝑖)        |
|                                   |   ------------------------------  |
|                                   |                                   |
|                                   |   ------------------------------  |
+-----------------------------------+-----------------------------------+
|                                   |                                   |
+-----------------------------------+-----------------------------------+
| > ●\                              | Чем меньше, тем лучше\            |
| > ●\                              | Должна соответствовать            |
| > ●                               | бизнес-требованиям\               |
|                                   | Одна из самых важных составляющих |
|                                   | анализа данных                    |
+-----------------------------------+-----------------------------------+

> **Обучение алгоритма**
>
> ● Есть обучающая выборка и функция потерь
>
> ● Семейство алгоритмов P
>
> ● Из чего выбираем алгоритм
>
> ● **Пример:** все линейные модели
>
> 𝐴= {𝑤0 + 𝑤1𝑥1 + \... + 𝑤𝑑𝑥𝑑 \| 𝑤0, 𝑤1,\..., 𝑤𝑑 ϵ ℝ}
>
> ● **Обучение:** поиск оптимального алгоритма с точки зрения значения
> функции
>
> потерь на обучающей выборке
>
> ● В результате получаем алгоритм, который может делать предсказания
> для
>
> новых объектов.
>
> **А вдруг модель просто запомнит примеры?**

+-----------------------+-----------------------+-----------------------+
| > ●\                  | > Мы хотим, чтобы она |                       |
| > ●                   | > нашла зависимости в |                       |
| >                     | > виде формулыА может |                       |
| > ●\                  | > просто запомнить:   |                       |
| > **●**               |                       |                       |
+=======================+=======================+=======================+
|                       | ○                     | > Дом именно с такими |
|                       |                       | > характеристиками    |
|                       |                       | > стоит столько-то    |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Не работает на      |
|                       |                       | > немного других      |
|                       |                       | > домах               |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Это эффект          |
|                       |                       | > **переобучения**    |
+-----------------------+-----------------------+-----------------------+
|                       | > Как проверить?      |                       |
|                       | >                     |                       |
|                       | > **Надо проверять на |                       |
|                       | > домах, которые она  |                       |
|                       | > не видела!**        |                       |
+-----------------------+-----------------------+-----------------------+

> **Обобщающая способность алгоритма**
>
> ● Перед обучением от данных отделяется **отложенная** выборка:
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image175.png){width="3.3430555555555554in"
> height="0.36388779527559056in"}
>
> Обучение Валидация
>
> ● **Слишком большое обучение** - тестовая выборка нерепрезентативна
>
> ● **Слишком большой тест** - модель не сможет обучиться
>
> ● **Обычно:** 70/30, 80/20
>
> **Схема работы машинного обучения**

+-----------------------------------+-----------------------------------+
| > **Обучение**\                   | ![](vertopal_c0b099a1bf474e9      |
| > Прецеденты →Извлечение\         | 590819adae366c879/media/image176. |
| > признаков →Обучение             | png){width="3.4583333333333335in" |
| > алгоритма→Валидация алгоритма   | height="1.9069444444444446in"}    |
| > →a(x)**Тест**\                  |                                   |
| > Новый объект →a(x) →\           |                                   |
| > Предсказание                    |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Виды и примеры задач**
>
> **Регрессия**
>
> ● **Вещественные ответы:** 𝕐= ℝ
>
> ● (вещественные числа - числа с любой дробной частью)
>
> ● **Примеры:** предсказание зарплат, стоимости недвижимости, объема
>
> нефтедобычи...
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image177.png){width="3.2402777777777776in"
> height="2.009721128608924in"}
>
> **Классификация**
>
> ● Конечное число ответов: 𝕐\<∞
>
> ● Бинарная классификация: 𝕐= {−1, +1}
>
> ● Многоклассовая классификация: 𝕐= {1, 2, ... , 𝐾}
>
> ● Примеры: кредитный скоринг, предсказание оттока, категоризация
> писем,
>
> определение объекта на фото

+-----------------------------------+-----------------------------------+
| > ![](vertopal_c0b099a1bf474e9    | > ![](vertopal_c0b099a1bf474e     |
| 590819adae366c879/media/image178. | 9590819adae366c879/media/image179 |
| png){width="3.1861100174978128in" | .png){width="2.061111111111111in" |
| > height="1.7916666666666667in"}  | > height="1.7291666666666667in"}  |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Кластеризация**

+-----------------------------------+-----------------------------------+
| > ●\                              | > 𝕐- отсутствует\                 |
| > ●\                              | > Нужно найти группы похожих      |
| > ●\                              | > объектов\                       |
| > ●\                              | > Сколько таких групп?            |
| > ●                               | >                                 |
|                                   | > Как измерить качество?          |
|                                   | >                                 |
|                                   | > **Пример:** сегментация         |
|                                   | > пользователей мобильного        |
|                                   | > оператора                       |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Ранжирование**

+-----------------------+-----------------------+-----------------------+
| > ●\                  | > Нужно не            |                       |
| > ●                   | > предсказать         |                       |
|                       | > величину, а         |                       |
|                       | > правильно           |                       |
|                       | > упорядочить         |                       |
|                       | > объектыПримеры:     |                       |
+=======================+=======================+=======================+
|                       | ○                     | > Ранжирование        |
|                       |                       | > поисковой выдачи    |
+-----------------------+-----------------------+-----------------------+
|                       | ○                     | > Ранжирование        |
|                       |                       | > товаров в           |
|                       |                       | > рекомендательной    |
|                       |                       | > системе             |
+-----------------------+-----------------------+-----------------------+

> **Рекомендательные системы**\
> ● Полки рекомендаций на Amazon генерируют 35% от всех покупок\
> ● Рекомендации на основе машинного обучения и анализа больших объемов
> данных
>
> **Обнаружение аномалий**

+-----------------------------------+-----------------------------------+
| > **Задача** - найти объекты,     | ![](vertopal_c0b099a1bf474e9      |
| > которые являются\               | 590819adae366c879/media/image180. |
| > нестандартными, выбиваются из   | png){width="2.3430555555555554in" |
| > общего\                         | height="1.5097211286089238in"}    |
| > распределения\                  |                                   |
| > **Примеры:**\                   |                                   |
| > ● Обнаружение мошеннических     |                                   |
| > транзакций ● Раннее обнаружение |                                   |
| > поломок в системах самолёта или |                                   |
| > автомобиля                      |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Линейные методы для регрессии и классификации**\
> **Основные виды моделей**

+-----------------------+-----------------------+-----------------------+
| > **Линейные модели** | > **Решающие деревья  | > **Нейронные сети**  |
|                       | > и ихкомбинации**    |                       |
| ![](vertop            |                       | ![](vertop            |
| al_c0b099a1bf474e9590 | ![](verto             | al_c0b099a1bf474e9590 |
| 819adae366c879/media/ | pal_c0b099a1bf474e959 | 819adae366c879/media/ |
| image181.png){width=" | 0819adae366c879/media | image183.png){width=" |
| 1.8222211286089238in" | /image182.png){width= | 1.8958333333333333in" |
| height="1             | "2.009721128608924in" | height="0             |
| .4069444444444446in"} | height="1             | .9277777777777778in"} |
|                       | .3333333333333333in"} |                       |
+=======================+=======================+=======================+
+-----------------------+-----------------------+-----------------------+

> **Линейная модель для регрессии**

+-----------------------+-----------------------+-----------------------+
| +--------+--------+   | > ![](verto           | ![](vertop            |
| | >      | >      |   | pal_c0b099a1bf474e959 | al_c0b099a1bf474e9590 |
| |  **x** |  **y** |   | 0819adae366c879/media | 819adae366c879/media/ |
| +========+========+   | /image184.png){width= | image185.png){width=" |
| | > 1    | > 2    |   | "2.448611111111111in" | 2.4166666666666665in" |
| +--------+--------+   | > height="1           | height="1             |
| | > 3    | > 5    |   | .9277777777777778in"} | .9069444444444446in"} |
| +--------+--------+   |                       |                       |
| | > -1   | > -2   |   |                       |                       |
| +--------+--------+   |                       |                       |
| | > 5    | > ?    |   |                       |                       |
| +--------+--------+   |                       |                       |
+=======================+=======================+=======================+
+-----------------------+-----------------------+-----------------------+

> **Метод наименьших квадратов**\
> **Дано:**\
> 1. Набор экспериментальных точек (y1,x1), (y2,x2), ... ,(yn,xn) 2.
> Линейная модель y = a + bx\
> Найти коэффициенты a и b

+-----------------------------------+-----------------------------------+
| > **Переопределенная система      | > **Необходимость в               |
| > уравнений**                     | > приближенныхметодах**\          |
|                                   | > Метод наименьших квадратов      |
|   ------------------------------  | > (МНК)Минимизация суммы          |
| --------------------------------- | > квадратов\                      |
| --------------------------------- | > отклонений RSS (Resudiual Sum   |
|   ![](vertopal_c0b099a1bf474e9    | > of Squares)                     |
| 590819adae366c879/media/image186. |                                   |
| png){width="1.3333333333333333in" |   ------------------------------  |
|   height="0.6777777777777778in"}  | --------------------------------- |
|   ------------------------------  | --------------------------------- |
| --------------------------------- |   ![](vertopal_c0b099a1bf474e9    |
| --------------------------------- | 590819adae366c879/media/image187. |
|                                   | png){width="2.2083333333333335in" |
|   ------------------------------  |   height="0.4375in"}              |
| --------------------------------- |   ------------------------------  |
| --------------------------------- | --------------------------------- |
|                                   | --------------------------------- |
| > В общем случае решения не имеет |                                   |
| > (т.к.экспериментальные точки    |   ------------------------------  |
| > обычно неложатся в точности на  | --------------------------------- |
| > одну прямую)                    | --------------------------------- |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Линейная регрессия: коэффициенты**

+-----------------+-----------------+-----------------+-----------------+
| > *             |                 | > **Результат   |                 |
| *Минимизируемая |                 | > расчёта**     |                 |
| > функция**     |                 | >               |                 |
| >               |                 | > ![](          |                 |
| > ![](          |                 | vertopal_c0b099 |                 |
| vertopal_c0b099 |                 | a1bf474e9590819 |                 |
| a1bf474e9590819 |                 | adae366c879/med |                 |
| adae366c879/med |                 | ia/image189.png |                 |
| ia/image188.png |                 | ){width="1.4166 |                 |
| ){width="2.6861 |                 | 666666666667in" |                 |
| 100174978128in" |                 | >               |                 |
| >               |                 | height="0.58333 |                 |
| height="0.52083 |                 | 33333333334in"} |                 |
| 33333333334in"} |                 |                 |                 |
+=================+=================+=================+=================+
| > **Поиск       |                 |                 |                 |
| > стационарных  |                 |                 |                 |
| > точек для     |                 |                 |                 |
| > RSS**         |                 |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
| > ![](          |                 | > ![](          |                 |
| vertopal_c0b099 |                 | vertopal_c0b099 |                 |
| a1bf474e9590819 |                 | a1bf474e9590819 |                 |
| adae366c879/med |                 | adae366c879/med |                 |
| ia/image190.png |                 | ia/image191.png |                 |
| ){width="2.4583 |                 | ){width="2.0305 |                 |
| 333333333335in" |                 | 544619422573in" |                 |
| >               |                 | > he            |                 |
| height="0.72916 |                 | ight="0.625in"} |                 |
| 66666666666in"} |                 |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
| > ![](          | > ![]           |                 | > ![](          |
| vertopal_c0b099 | (vertopal_c0b09 |                 | vertopal_c0b099 |
| a1bf474e9590819 | 9a1bf474e959081 |                 | a1bf474e9590819 |
| adae366c879/med | 9adae366c879/me |                 | adae366c879/med |
| ia/image192.png | dia/image193.pn |                 | ia/image194.png |
| ){width="1.6347 | g){width="1.823 |                 | ){width="1.8222 |
| 222222222222in" | 611111111111in" |                 | 211286089238in" |
| >               | > hei           |                 | > hei           |
| height="0.39583 | ght="0.3125in"} |                 | ght="0.3125in"} |
| 33333333333in"} |                 |                 |                 |
+-----------------+-----------------+-----------------+-----------------+

> **Линейная регрессия: коэффициенты r и R2**

+-----------------------------------+-----------------------------------+
| > ![](vertopal_c0b099a1bf474e9    | > **Коэффициент корреляции        |
| 590819adae366c879/media/image195. | > Пирсона ry,ŷ**                  |
| png){width="2.7805555555555554in" |                                   |
| > height="0.7819433508311461in"}  | ![](vertopal_c0b099a1bf474e       |
|                                   | 9590819adae366c879/media/image196 |
|                                   | .png){width="2.977777777777778in" |
|                                   | height="0.30277777777777776in"}   |
|                                   |                                   |
|                                   | ![](vertopal_c0b099a1bf474e       |
|                                   | 9590819adae366c879/media/image197 |
|                                   | .png){width="1.113888888888889in" |
|                                   | height="0.20833333333333334in"}   |
+===================================+===================================+
| > **Связь между R2и ry,ŷ**        |                                   |
|                                   |                                   |
| ![](vertopal_c0b099a1bf474e       |                                   |
| 9590819adae366c879/media/image198 |                                   |
| .png){width="6.102777777777778in" |                                   |
| height="0.4583333333333333in"}    |                                   |
|                                   |                                   |
| ![](vertopal_c0b099a1bf474e       |                                   |
| 9590819adae366c879/media/image199 |                                   |
| .png){width="6.102777777777778in" |                                   |
| height="0.6666666666666666in"}    |                                   |
+-----------------------------------+-----------------------------------+

> Предположим, что у нас есть данные о ценах на автомобили (в тысячах
> долларов) взависимости от их пробега (в тысячах километров):

+-----------------------------------+-----------------------------------+
| > **Пробег (X)**                  | > **Цена (Y)**                    |
+===================================+===================================+
| > 10                              | > 15                              |
+-----------------------------------+-----------------------------------+
| > 20                              | > 10                              |
+-----------------------------------+-----------------------------------+
| > 30                              | > 7                               |
+-----------------------------------+-----------------------------------+
| > 40                              | > 5                               |
+-----------------------------------+-----------------------------------+
| > 50                              | > 3                               |
+-----------------------------------+-----------------------------------+

> **1. Вычисляем средние значения (Mx и My):**

+-----------------------+-----------------------+-----------------------+
| 𝑀𝑥=10 + 20 + 30 +     |                       | > = 30                |
| 40 + 50               |                       |                       |
+=======================+=======================+=======================+
| 𝑀𝑦=15 + 10 + 7 + 5 +  | > = 8                 |                       |
| 3                     |                       |                       |
+-----------------------+-----------------------+-----------------------+

> **2. Найдем отклонения, квадраты отклонений и произведение
> отклонений:**

+---------+---------+---------+---------+---------+---------+---------+
| > **X** | > **Y** | > **X - | > **Y - | >       | >       | >       |
|         |         | > Mx**  | > My**  |  **(X - |  **(Y - |  **(X - |
|         |         |         |         | >       | >       | >       |
|         |         |         |         |  Mx)2** |  My)2** | Mx)(Y - |
|         |         |         |         |         |         | > My)** |
+=========+=========+=========+=========+=========+=========+=========+
| > 10    | > 15    | > -20   | > 7     | > 400   | > 49    | > -140  |
+---------+---------+---------+---------+---------+---------+---------+
| > 20    | > 10    | > -10   | > 2     | > 100   | > 4     | > -20   |
+---------+---------+---------+---------+---------+---------+---------+
| > 30    | > 7     | > 0     | > -1    | > 0     | > 1     | > 0     |
+---------+---------+---------+---------+---------+---------+---------+
| > 40    | > 5     | > 10    | > -3    | > 100   | > 9     | > -30   |
+---------+---------+---------+---------+---------+---------+---------+
| > 50    | > 3     | > 20    | > -5    | > 400   | > 25    | > -100  |
+---------+---------+---------+---------+---------+---------+---------+

> **3. Вычисляем суммы квадратов отклонений и произведений отклонений:**
> SP = -140 - 20 + 0 - 30 - 100 = -290\
> SSx = 400 + 100 + 0 + 100 + 400 = 1000
>
> **4. Находим коэффициенты уравнения регрессии (a и b):**

+-----------------------------------+-----------------------------------+
| 𝑎=                                | > 𝑆𝑆𝑥= −290 1000=−0. 29           |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> 𝑏= 𝑀𝑦−𝑎× 𝑀𝑥= 8 −(−0. 29 × 30) = 16. 7
>
> **Уравнение регрессии**\
> Теперь у нас есть уравнение линейной регрессии, описывающее
> зависимость ценыавтомобиля от его пробега:\
> Цена = -0.29 x Пробег + 16.7
>
> **Пример прогноза**\
> Для автомобиля с пробегом 25 тысяч километров прогнозируемая цена
> будет: Цена = -0.29 x 25 + 16.7 = 9.55 тыс. долл.
>
> **MSE**\
> **Среднеквадратичная ошибка (Mean Squared Error)** применяется в
> случаях, когдатребуется подчеркнуть большие ошибки и выбрать модель,
> которая дает меньшеименно больших ошибок. Большие значения ошибок
> становятся заметнее за счетквадратичной зависимости.
>
> **MSE рассчитывается по формуле:**

+-----------------------------------+-----------------------------------+
| +--------------+--------------+   | > где n - количество наблюдений   |
| | 𝑀𝑆𝐸=         | > 𝑁\         |   | > по которым строится модель      |
| |              | > 1 2        |   | > иколичество прогнозов, yi -     |
| |              |              |   | > фактические значение            |
| |              | 𝑁𝑖=1∑(𝑦𝑖−ŷ𝑖) |   | > **зависимойпеременной** для     |
| +==============+==============+   | > i-го наблюдения, ŷi - значение  |
| +--------------+--------------+   | > зависимойпеременной,            |
|                                   | > предсказанное моделью           |
|                                   | >                                 |
|                                   | > Таким образом, можно сделать    |
|                                   | > вывод, что MSE настроена        |
|                                   | > наотражение влияния именно      |
|                                   | > больших ошибок на качество      |
|                                   | > модели.                         |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Линейная модель для регрессии**

+-----------------------------------+-----------------------------------+
| +--------------+--------------+   | ![](vertopal_c0b099a1bf474e9      |
| | > **x**      | > **y**      |   | 590819adae366c879/media/image200. |
| +==============+==============+   | png){width="2.2805544619422573in" |
| | > 1          | > 2          |   | height="1.7819444444444446in"}    |
| +--------------+--------------+   |                                   |
| | > 3          | > 5          |   |                                   |
| +--------------+--------------+   |                                   |
| | > -1         | > -2         |   |                                   |
| +--------------+--------------+   |                                   |
| | > 5          | > ?          |   |                                   |
| +--------------+--------------+   |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Идея процедуры обучения**

+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e9      | > **MSE при фиксированном**       |
| 590819adae366c879/media/image201. | > 𝒂**:**                          |
| png){width="2.5416666666666665in" |                                   |
| height="1.625in"}                 | ![](vertopal_c0b099a1bf474e9      |
|                                   | 590819adae366c879/media/image202. |
|                                   | png){width="3.2916666666666665in" |
|                                   | height="1.0944444444444446in"}    |
+===================================+===================================+
| > ![](vertopal_c0b099a1bf474e     |                                   |
| 9590819adae366c879/media/image203 |                                   |
| .png){width="2.488888888888889in" |                                   |
| > height="1.5944433508311462in"}  |                                   |
+-----------------------------------+-----------------------------------+

> **Положим на параболу мячик в точке В**

+-----------------+-----------------+-----------------+-----------------+
| ![](            |                 | > **Производная |                 |
| vertopal_c0b099 |                 | > покажет       |                 |
| a1bf474e9590819 |                 | > скоростьКуда  |                 |
| adae366c879/med |                 | > покатится?**\ |                 |
| ia/image204.png |                 | > f(A) \> f(C)  |                 |
| ){width="2.8111 |                 | > 🡪вправо\      |                 |
| 100174978128in" |                 | > f(A) \< f(C)  |                 |
| height="1.72916 |                 | > 🡪влево        |                 |
| 66666666667in"} |                 |                 |                 |
+=================+=================+=================+=================+
| ![]             | ![](            |                 | ![](            |
| (vertopal_c0b09 | vertopal_c0b099 |                 | vertopal_c0b099 |
| 9a1bf474e959081 | a1bf474e9590819 |                 | a1bf474e9590819 |
| 9adae366c879/me | adae366c879/med |                 | adae366c879/med |
| dia/image205.pn | ia/image206.png |                 | ia/image207.png |
| g){width="1.894 | ){width="1.9361 |                 | ){width="1.9777 |
| 443350831146in" | 100174978128in" |                 | 777777777779in" |
| height="1.28194 | height="1.30277 |                 | height="1.33333 |
| 44444444446in"} | 77777777778in"} |                 | 33333333333in"} |
+-----------------+-----------------+-----------------+-----------------+
| > MSE при       |                 | ![](            |                 |
| > фиксированном |                 | vertopal_c0b099 |                 |
| > 𝒂:            |                 | a1bf474e9590819 |                 |
|                 |                 | adae366c879/med |                 |
|                 |                 | ia/image208.png |                 |
|                 |                 | ){width="3.0416 |                 |
|                 |                 | 666666666665in" |                 |
|                 |                 | height="1.01111 |                 |
|                 |                 | 00174978127in"} |                 |
+-----------------+-----------------+-----------------+-----------------+

> **Обучение линейной
> регрессии**![](vertopal_c0b099a1bf474e9590819adae366c879/media/image210.png){width="1.7222222222222223in"
> height="0.6186253280839895in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image211.png){width="8.198610017497813in"
> height="8.183067585301837in"}

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image209.png){width="3.761111111111111in"
  height="1.7180555555555554in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

+-----------------------------------+-----------------------------------+
| > ● Градиент - вектор частных     |                                   |
| > производных                     |                                   |
| >                                 |                                   |
| > ● Вектор градиента указывает в  |                                   |
| > направлении\                    |                                   |
| > наискорейшего возрастания       |                                   |
| > функции\                        |                                   |
| > ● Градиентный спуск -           |                                   |
| > итерационных метод\             |                                   |
| > минимизации функции, в котором  |                                   |
| > на каждом шаге мы идем в        |                                   |
| > направлении антиградиента       |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Линейная регрессия**

+-----------------------------------+-----------------------------------+
| > **Среднеквадратичная ошибка и   | > **Подсчет градиента:**          |
| > задача обучения:**              |                                   |
|                                   |   ------------------------------  |
|   ------------------------------  |                                   |
|                                   |   ------------------------------  |
|   ------------------------------  |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Градиентный спуск**\
> 1. Начальное приближение: w0\
> 2. Повторять до сходимости:

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> 3\. Останавливаемся, если выполнено условие сходимости:

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> **Демо: линейная регрессия**

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> **Обучение линейной регрессии**\
> ● Задача линейной регрессии выпукла и имеет единственное решение,
> поэтому нет проблем с локальными оптимумами при градиентном спуске\
> ● Это решение можно найти аналитически (приравняв градиент к нулю), но
> для его подсчета нужно обращать
> матрицы:![](vertopal_c0b099a1bf474e9590819adae366c879/media/image216.png){width="9.543055555555556in"
> height="6.080924103237096in"}
>
> **Линейная модель для классификации**

+-----------------------+-----------------------+-----------------------+
| <table>               |                       |                       |
| <colgroup>            |                       |                       |
| <col                  |                       |                       |
| style="width: 33%" /> |                       |                       |
| <col                  |                       |                       |
| style="width: 33%" /> |                       |                       |
| <col                  |                       |                       |
| style="width: 33%" /> |                       |                       |
| </colgroup>           |                       |                       |
| <thead>               |                       |                       |
| <tr class="header">   |                       |                       |
| <th><blockquote>      |                       |                       |
| <p><s                 |                       |                       |
| trong>x1</strong></p> |                       |                       |
| </blockquote></th>    |                       |                       |
| <th><blockquote>      |                       |                       |
| <p><s                 |                       |                       |
| trong>x2</strong></p> |                       |                       |
| </blockquote></th>    |                       |                       |
| <th><blockquote>      |                       |                       |
| <p><                  |                       |                       |
| strong>y</strong></p> |                       |                       |
| </blockquote></th>    |                       |                       |
| </tr>                 |                       |                       |
| </thead>              |                       |                       |
| <tbody>               |                       |                       |
| <tr class="odd">      |                       |                       |
| <td>180</td>          |                       |                       |
| <td><blockquote>      |                       |                       |
| <p>5</p>              |                       |                       |
| </blockquote></td>    |                       |                       |
| <td>М</td>            |                       |                       |
| </tr>                 |                       |                       |
| <tr class="even">     |                       |                       |
| <td>170</td>          |                       |                       |
| <td>20</td>           |                       |                       |
| <td>Ж</td>            |                       |                       |
| </tr>                 |                       |                       |
| <tr class="odd">      |                       |                       |
| <td>160</td>          |                       |                       |
| <td><blockquote>      |                       |                       |
| <p>5</p>              |                       |                       |
| </blockquote></td>    |                       |                       |
| <td>М</td>            |                       |                       |
| </tr>                 |                       |                       |
| <tr class="even">     |                       |                       |
| <td>190</td>          |                       |                       |
| <td>30</td>           |                       |                       |
| <td><blockquote>      |                       |                       |
| <p>?</p>              |                       |                       |
| </blockquote></td>    |                       |                       |
| </tr>                 |                       |                       |
| </tbody>              |                       |                       |
| </table>              |                       |                       |
+=======================+=======================+=======================+
|                       | ![](vertop            | ![](verto             |
|                       | al_c0b099a1bf474e9590 | pal_c0b099a1bf474e959 |
|                       | 819adae366c879/media/ | 0819adae366c879/media |
|                       | image212.png){width=" | /image213.png){width= |
|                       | 2.3444444444444446in" | "2.311111111111111in" |
|                       | height="1.75in"}      | height="1             |
|                       |                       | .7194444444444446in"} |
+-----------------------+-----------------------+-----------------------+

> **Уверенность в предсказании**

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image214.png){width="2.9777766841644793in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image215.png){width="2.977777777777778in"
  height="2.0416666666666665in"}                                                                   height="2.0305544619422573in"}
  ------------------------------------------------------------------------------------------------ -----------------------------------------------------------------------------------------------

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

> **Логистическая регрессия**

+-----------------------------------+-----------------------------------+
| > Линейная модель классификации,  | ![](vertopal_c0b099a1bf474e       |
| > которая выдаетвероятность       | 9590819adae366c879/media/image217 |
| > класса\                         | .png){width="2.261111111111111in" |
| > В случае одного признака:\      | height="1.7708333333333333in"}    |
| > Логистическая функция 𝜎(𝑥)      |                                   |
| > взамен знака\                   |                                   |
| > возвращает уверенность:\        |                                   |
| > Дальше от прямой - больше       |                                   |
| > вероятность класса              |                                   |
| >                                 |                                   |
| > (Непонятная формула)            |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Уверенность в предсказании**

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image214.png){width="2.9777766841644793in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image218.png){width="2.977777777777778in"
  height="2.0416666666666665in"}                                                                   height="1.4055544619422573in"}
  ------------------------------------------------------------------------------------------------ -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image219.png){width="2.9777766841644793in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image220.png){width="2.977777777777778in"
  height="2.0in"}                                                                                  height="1.4069433508311462in"}

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

> **Демо: логистическая
> регрессия**![](vertopal_c0b099a1bf474e9590819adae366c879/media/image223.png){width="6.272222222222222in"
> height="4.434830489938758in"}

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> **Пример**\
> Предсказание зарплаты по описанию вакансии:

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image221.png){width="3.397222222222222in"
  height="1.1666666666666667in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Пример - извлечение признаков**\
> ● Преобразовываем в «мешок слов» или «мешок n-грамм» ● Нормируем
> признаки - TF-IDF
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image222.png){width="5.125in"
> height="1.4263877952755906in"}
>
> **Пример - веса модели**
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image224.png){width="4.115277777777778in"
> height="3.761111111111111in"}
>
> **Пример - предсказания**

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image225.png){width="5.906944444444444in"
  height="1.9375in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Линейные модели**\
> **Линейная модель** в общем виде суммирует значения всех признаков с
> некоторымивесами\
> **Веса при признаках** - параметры, которые необходимо настраивать в
> процессеобучения
>
> **Плюсы:**\
> ● Линейные модели способны обучаться на сверхбольших выборках\
> ● Могут работать на данных с большим количеством признаков (например,
> на текстах)\
> ● Хорошо интерпретируются
>
> **Минусы:**

+-----------------------------------+-----------------------------------+
| ●                                 | > Могут восстанавливать лишь      |
|                                   | > линейные закономерности         |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Бинарная классификация**\
> Задачей **бинарной классификации** является определение принадлежности
> некоегообъекта к одному из двух возможных классов.
>
> **Например:**\
> ● является ли сообщение электронной почты «нормальным» или
> представляет собой спам;\
> ● здоров или болен пациент;\
> ● является ли заемщик банка надежным или ненадежным;\
> ● качественная или бракованная деталь.
>
> **Наиболее известными методами бинарной классификации являются:**

+-----------------------------------+-----------------------------------+
| > ●\                              | > логистическая регрессия         |
| > ●\                              | > (Logistic Regression);\         |
| > ●\                              | > «наивный» байесовский           |
| > ●                               | > классификатор (Naive Bayes      |
|                                   | > Classifier);метод опорных       |
|                                   | > векторов (Support Vector        |
|                                   | > Machine, SVM);\                 |
|                                   | > нейронная сеть (Neural Network) |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Логистическая регрессия**\
> Логистическая регрессия (линейный классификатор) - один из методов
> бинарнойклассификации данных.
>
> **Алгоритм применения логистической регрессии:**

+-----------------------------------+-----------------------------------+
| > 1.\                             | > Подготовка обучающей выборки -- |
| > 2.\                             | > кодирование классов             |
| > 3.\                             | > числами.Задание функций штрафа. |
| > 4.\                             | >                                 |
| > 5.                              | > Задание целевой функции.        |
|                                   | >                                 |
| 1\.                               | > Задание начальных значений      |
|                                   | > коэффициентам функции.          |
|                                   | >                                 |
|                                   | > Численное решение:              |
|                                   | >                                 |
|                                   | > Если точка находится над прямой |
|                                   | > и относим ее к классу +1, то    |
|                                   | > значение                        |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> линейной функции z будет положительным от 0 до + ∞. Значит можем
> считать,что вероятность, находится в пределах (0.5,1\]. Чем больше
> значение функции,тем выше вероятность.
>
> 2\. Если точка находится под прямой и относим ее к классу -1 или 0, то
> значение функции будет отрицательным от - ∞до 0. Тогда будем читать,
> что вероятность находится в пределах \[0,0.5) .
>
> Точка находится на прямой, на границе между двумя классами. В таком
> случае3.
>
> значение функции z будет равно 0 и вероятность погашения кредита
>
> Задача модели логистической регрессии как раз и состоит в том, чтобы
> определитьпараметры , при которых значение функции потерь Logistic
> Loss будет стремиться кминимальному.

+-----------------------------------+-----------------------------------+
| > **Функция логистического        | ![](vertopal_c0b099a1bf474e9      |
| > отклика** (сигмоид-функция      | 590819adae366c879/media/image226. |
| > илиобратный-логит               | png){width="1.3638877952755906in" |
| > преобразования) соответствует   | height="0.5111100174978128in"}    |
| > вероятностинаступления события  |                                   |
| > (для определения вероятности\   |                                   |
| > принадлежности объекта к классу |                                   |
| > +1):                            |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Функция логистической ошибки**

+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e9      | > ![](vertopal_c0b099a1bf474e     |
| 590819adae366c879/media/image227. | 9590819adae366c879/media/image228 |
| png){width="2.9777766841644793in" | .png){width="2.073611111111111in" |
| height="0.46249890638670166in"}   | > height="0.46805555555555556in"} |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

+-----------------------------------+-----------------------------------+
| > **Задача модели логистической   | > ![](vertopal_c0                 |
| > регрессии** состоит в том,чтобы | b099a1bf474e9590819adae366c879/me |
| > определить параметры θ, при     | dia/image229.png){width="1.625in" |
| > которых значениефункции потерь  | > height="0.40694335083114613in"} |
| > будет стремиться к              |                                   |
| > минимальному.                   |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Пример логистической регрессии**\
> В результате численного решения будут определены параметры функции
> линейногоразделения. Визуальная проверка показывает корректность
> разделения двух классов

+-----------------------------------+-----------------------------------+
| > ![](vertopal_c0b099a1bf474e9    | > ![](vertopal_c0b099a1bf474e9    |
| 590819adae366c879/media/image230. | 590819adae366c879/media/image231. |
| png){width="3.6555555555555554in" | png){width="0.9583333333333334in" |
| > height="1.8861100174978127in"}  | > height="1.1569444444444446in"}  |
+===================================+===================================+
| > ![](vertopal_c0b099a1bf474e9    | > ![](vertopal_c0b099a1bf474e9    |
| 590819adae366c879/media/image232. | 590819adae366c879/media/image233. |
| png){width="3.5097222222222224in" | png){width="0.8958333333333334in" |
| > height="1.0305544619422573in"}  | > height="1.0833333333333333in"}  |
+-----------------------------------+-----------------------------------+

> **Оценка качества классификации**

+-----------------------------------+-----------------------------------+
| > При бинарной классификации      | ![](vertopal_c0b099a1bf474e9      |
| > возможны\                       | 590819adae366c879/media/image234. |
| > четыре сочетания реального      | png){width="2.5722222222222224in" |
| > класса каждогоиз объектов       | height="0.9375in"}                |
| > выборки данных и                |                                   |
| > предположенияалгоритма о классе |                                   |
| > объекта.                        |                                   |
+===================================+===================================+
| > Реальные алгоритмы допускают    | ![](vertopal_c0b099a1bf474e       |
| > ошибкиклассификации двух        | 9590819adae366c879/media/image235 |
| > видов:\                         | .png){width="2.561111111111111in" |
| > ошибки I рода и ошибки II рода. | height="1.1347222222222222in"}    |
+-----------------------------------+-----------------------------------+

+-----------------------------------+-----------------------------------+
| \-                                | > **Истинный Позитив (TP):** Это  |
|                                   | > относится к случаям, в которых  |
|                                   | > мы                              |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> предсказывали «ДА и наш прогноз был на самом деле ПРАВДА (Например, у
> пациента на самом деле диабет, и вы предсказали, что это правда)\
> - **Правда отрицательный (TN):** это относится к случаям, в которых
> мы\
> предсказывали «НЕТ и наш прогноз был на самом деле ПРАВДА\
> (Например, у пациента нет диабета, и вы предсказали то же самое.)\
> - **Ложно положительный (FP):** это относится к случаям, в которых мы\
> предсказывали «ДА», но наш прогноз оказался ЛОЖНЫЙ (У пациента не было
> диабета, но наша модель предсказала, что он / она диабетик)\
> - **Ложный Отрицательный (FN):** это относится к случаям, в которых мы
> предсказывали «НЕТ но наш прогноз оказался ЛОЖНЫЙ
>
> **F-критерия для оценки качества классификации**\
> **Этапы расчета F-критерия:**

+-----------------------------------+-----------------------------------+
| > 1\. Подсчет количества каждого  | +---------+---------+---------+   |
| >                                 | | ![]     | ![]     | > ![]   |   |
| > сочетания случаев.              | | (vertop | (vertop | (vertop |   |
| >                                 | | al_c0b0 | al_c0b0 | al_c0b0 |   |
| > 2\. Расчет точности (precision) | | 99a1bf4 | 99a1bf4 | 99a1bf4 |   |
| >                                 | | 74e9590 | 74e9590 | 74e9590 |   |
| > 3\. Расчет чувствительности     | | 819adae | 819adae | 819adae |   |
| > (recall)                        | | 366c879 | 366c879 | 366c879 |   |
| >                                 | | /media/ | /media/ | /media/ |   |
| > 4\. Расчет F-критерия           | | image23 | image23 | image23 |   |
|                                   | | 6.png){ | 7.png){ | 8.png){ |   |
|                                   | | width=" | width=" | width=" |   |
|                                   | | 0.98888 | 0.92777 | 0.86388 |   |
|                                   | | 7795275 | 7777777 | 7795275 |   |
|                                   | | 5906in" | 7778in" | 5906in" |   |
|                                   | | he      | he      | > hei   |   |
|                                   | | ight="0 | ight="0 | ght="0. |   |
|                                   | | .520833 | .520833 | 4902766 |   |
|                                   | | 3333333 | 3333333 | 8416447 |   |
|                                   | | 334in"} | 334in"} | 945in"} |   |
|                                   | +=========+=========+=========+   |
|                                   | +---------+---------+---------+   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Пример расчета F-критерия**\
> Предположим, что в электронный почтовый ящик пришло 10 сообщений,
> часть изкоторых является нормальными, а часть - спамом
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image239.png){width="5.791666666666667in"
> height="2.4694444444444446in"}
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image240.png){width="5.636111111111111in"
> height="2.8125in"}
>
> **Недообучение. Переобучение**
>
> Переобучение/Недообучение. Overtraining/Undertraining

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image241.png){width="5.313888888888889in"
  height="4.104166666666667in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Обучение и переобучение**

  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image242.png){width="1.9361100174978128in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image243.png){width="1.9361100174978128in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image244.png){width="1.9361111111111111in"
  height="1.2916666666666667in"}                                                                   height="1.323611111111111in"}                                                                    height="1.2819444444444446in"}
  ------------------------------------------------------------------------------------------------ ------------------------------------------------------------------------------------------------ ------------------------------------------------------------------------------------------------

  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

> **Как избежать недообучения?**
>
> 1\. Использовать более сложную модель
>
> 2\. Перемешивать данные после вычисления каждой эпохи (deep learning)
>
> 3\. Добавить новые features
>
> **Как избежать переобучения?**

+-----------------------------------+-----------------------------------+
| > 1.\                             | > Найти больше данных для train\  |
| > 2.\                             | > Если новых данных нет, то       |
| > 3.\                             | > аугментировать (augmentation)   |
| > 4.\                             | > то, что естьРанняя остановка    |
| > 5.\                             | > (early stopping)\               |
| > 6.                              | > Добавить регуляризацию (L1, L2  |
|                                   | > ) для весов\                    |
|                                   | > Dropout - выбросить часть узлов |
|                                   | > из нейронки\                    |
|                                   | > Dropconnect - обнулить          |
|                                   | > некоторые веса                  |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> jupyter notebook - regression\
> **Ссылка:**

+-----------------------------------------------------------------------+
| > \# for data\                                                        |
| > import pandas as pd\                                                |
| > import numpy as np\                                                 |
| > \## for plotting\                                                   |
| > import matplotlib.pyplot as plt\                                    |
| > import seaborn as sns                                               |
| >                                                                     |
| > \## for machine learning\                                           |
| > from sklearn import preprocessing, model_selection from             |
| > google.colab import drive\                                          |
| > drive.mount(\'/content/gdrive\')                                    |
+=======================================================================+
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > \'\'\'\                                                             |
| > Читаем данные из файла, и сразу смотрим заголовки столбцов          |
| > (название фич) и первые 5строк.                                     |
| >                                                                     |
| > \'\'\'                                                              |
| >                                                                     |
| > dtf =                                                               |
| > pd.read_c                                                           |
| sv(\'gdrive/MyDrive/Data_analysis/ПИ/Лекции/Регрессия/penguins.csv\') |
| > dtf.head()                                                          |
+=======================================================================+
| ![](vertopal_c0b099a1bf4                                              |
| 74e9590819adae366c879/media/image245.png){width="6.113888888888889in" |
| height="1.4166666666666667in"}                                        |
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > def utils_recognize_type(dtf, col, max_cat=20):\                    |
| > if (dtf\[col\].dtype == \"O\") \| (dtf\[col\].nunique() \<          |
| > max_cat): return \"cat\"\                                           |
| > else:\                                                              |
| > return \"num\"                                                      |
+=======================================================================+
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > \'\'\'\                                                             |
| > Функция подготовки датасета для дальнейшего скармливания            |
| > моделям\'\'\'                                                       |
| >                                                                     |
| > def prep(df):\                                                      |
| > \'\'\'\                                                             |
| > заменяем категориальные данные на числовыенормируем данные          |
| >                                                                     |
| > :param df: входной датасет\                                         |
| > :return: возвращает новый датасет, полностью готовый для            |
| > обучения\'\'\'\                                                     |
| > df.loc\[df.species == \'Adelie\', \'species_ind\'\] = 0\            |
| > df.loc\[df.species == \'Chinstrap\', \'species_ind\'\] = 1\         |
| > df.loc\[df.species == \'Gentoo\', \'species_ind\'\] = 2\            |
| > df.loc\[df.island == \'Biscoe\', \'island_ind\'\] = 0\              |
| > df.loc\[df.island == \'Dream\', \'island_ind\'\] = 1\               |
| > df.loc\[df.island == \'Torgersen\', \'island_ind\'\] = 2            |
| >                                                                     |
| > df.loc\[df.sex == \'MALE\', \'sex_g\'\] = 0\                        |
| > df.loc\[df.sex == \'FEMALE\', \'sex_g\'\] = 1                       |
| >                                                                     |
| > df.drop(\'Unnamed: 0\', axis=1, inplace=True)\                      |
| > emdf = df.dropna(axis=0, how=\'any\', inplace=False)                |
| >                                                                     |
| > \# нормируем значения\                                              |
| > Y = \'species_ind\'                                                 |
| >                                                                     |
| > n_df = emdf\                                                        |
| > lbs = \[\]                                                          |
| >                                                                     |
| > for v in dtf.columns:\                                              |
| > if utils_recognize_type(dtf, v) == \'cat\':\                        |
| > lbs.append(v)                                                       |
| >                                                                     |
| > n_df.drop(columns = lbs, inplace=True)                              |
| >                                                                     |
| > scaler = preprocessing.MinMaxScaler(feature_range=(0,1)) X =        |
| > scaler.fit_transform(n_df)                                          |
| >                                                                     |
| > train_emdf_scaled = pd.DataFrame(X,                                 |
| > columns=n_df.columns,index=n_df.index )                             |
| >                                                                     |
| > return train_emdf_scaled                                            |
+=======================================================================+
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| > \'\'\'\                                                             |
| > Получаем чистенький датасет\                                        |
| > \'\'\'\                                                             |
| > scaled_dtf = prep(dtf)\                                             |
| > \'\'\'\                                                             |
| > смотрим, что в нем.                                                 |
| >                                                                     |
| > Все категориальные столбцы были удалены, даже те, которые           |
| > превратили в числовые.Если числовые категориальные столбцы нужны,   |
| > то нужно изменить логику в функцииutils_recognize_type\             |
| > \'\'\'\                                                             |
| > scaled_dtf.head()                                                   |
+=======================================================================+
| > ![](vertopal_c0b099a1bf4                                            |
| 74e9590819adae366c879/media/image246.png){width="4.166666666666667in" |
| > height="1.4791655730533684in"}                                      |
+-----------------------------------------------------------------------+

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> (28.05.24) Лекция 4.4
>
> **Кодирование категориальных переменных**\
> Большинство алгоритмов машинного обучения работает с числовыми
> данными, чтоделает необходимым преобразование категориальных
> переменных в числовые: ● **One-Hot Encoding:** каждая категория
> преобразуется в новый столбец, где 1 означает наличие категории и 0 -
> её отсутствие. Для избежания проблемы мультиколлинеарности
> (переопределения) одна из колонок обычно удаляется.
>
> **Label Encoding:** каждой категории присваивается уникальное число.
> Этот●\
> метод подходит, когда категориальные признаки имеют порядок, но
> можетввести искажение в модели, когда такого порядка нет.
>
> **Нормализация и стандартизация данных**\
> Для улучшения производительности многих алгоритмов машинного обучения\
> требуется масштабирование данных:\
> ● **Нормализация (Min-Max Scaling):** преобразование данных таким
> образом, что их значения оказываются в диапазоне от 0 до 1.
>
> ● **Стандартизация (Z-score Scaling):** преобразование данных с целью
> получения среднего значения равного 0 и стандартного отклонения
> равного 1.
>
> **T-test**\
> T-тест является статистическим методом, используемым для оценки
> различий междусредними значениями двух групп, что помогает определить,
> статистически значимы лиразличия между этими группами. P-значение
> (p-value) - это мера, которая помогаетинтерпретировать результаты
> статистических тестов, включая t-тест. Вместе онииграют ключевую роль
> в проверке статистических гипотез.
>
> **T-тест: Основные аспекты**\
> T-тесты бывают трех основных типов:\
> 1. Одновыборочный t-тест проверяет, отличается ли среднее значение
> одной выборки от известного стандартного значения.
>
> 2\. Независимый (двухвыборочный) t-тест сравнивает средние значения
> двух различных групп.
>
> 3\. Зависимый t-тест (или парный t-тест) сравнивает средние значения
> двух связанных групп, например, измерения до и после эксперимента на
> тех же участниках.
>
> **Пример использования:**\
> Рассмотрим две группы студентов, которым были предложены разные
> методыобучения, и мы хотим определить, есть ли статистически значимые
> различия в ихоценках.
>
> **P-значение: Определение и интерпретация**\
> P-значение - это вероятность получить результат теста, равный или
> более\
> экстремальный, чем тот, который фактически наблюдался, при условии,
> что нулеваягипотеза верна. Нулевая гипотеза обычно утверждает, что
> между группами нетразличий или эффекта.
>
> ● **Маленькое p-значение** (обычно меньше 0.05) указывает на то, что\
> наблюдаемые данные маловероятны при справедливости нулевой гипотезы, и
> поэтому мы отвергаем нулевую гипотезу, предполагая, что различия\
> статистически значимы.
>
> ● **Большое p-значение** говорит о том, что данные согласуются с
> нулевой гипотезой, или что у нас недостаточно доказательств для её
> отклонения.

+-----------------------------------+-----------------------------------+
| > **Пример:**\                    | ![](vertopal_c0b099a1bf474e       |
| > Предположим, что p-значение в   | 9590819adae366c879/media/image247 |
| > тесте различиясредних оценок    | .png){width="2.249998906386702in" |
| > двух групп студентов            | height="1.9694444444444446in"}    |
| > составляет0.03. Это означает,   |                                   |
| > что если бы между группамине    |                                   |
| > было различий (нулевая гипотеза |                                   |
| > верна),вероятность получить     |                                   |
| > такие или более                 |                                   |
| > значимыеразличия составляла бы  |                                   |
| > 3%. Поскольку это\              |                                   |
| > значение меньше стандартного    |                                   |
| > порога в 5%, мыможем сказать,   |                                   |
| > что различия между              |                                   |
| > группамистатистически значимы.  |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Еще регрессии**\
> **R2**\
> Истинный коэффициент детерминации модели зависимости случайной
> величины y отфакторов x определяется следующим образом:

+-----------------------------------+-----------------------------------+
|   -                               |                                   |
| --------------------------------- | --------------------------------- |
|   𝑅2 = 1             2\           |   где        2 𝐷\[𝑦\] = \-        |
|   −𝐷\[𝑦\|𝑥\]𝐷\[𝑦\]   = 1 −σ2σ𝑦    |              σ𝑦         дисперсия |
|   -                               |                         случайной |
| ----------------- --------------- |                                   |
|                                   |                       величины y, |
|   -                               |                         а         |
| --------------------------------- |                                   |
|                                   | ---------- ---------- ----------- |
|                                   |                                   |
|                                   |                                   |
|                                   | --------------------------------- |
|                                   |                                   |
|                                   | > D\[y\|x\] = σ2- условная (по    |
|                                   | > факторам x) дисперсиязависимой  |
|                                   | > переменной (дисперсия ошибки    |
|                                   | > модели)                         |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

+-----------------------------------------------------------------------+
|   --------------------------                                          |
| --------------------------------------------------------------------- |
|   ![](vertopal_c0b099a1bf4                                            |
| 74e9590819adae366c879/media/image248.png){width="4.365277777777778in" |
|   height="1.863888888888889in"}                                       |
|   --------------------------                                          |
| --------------------------------------------------------------------- |
|                                                                       |
|   --------------------------                                          |
| --------------------------------------------------------------------- |
+=======================================================================+
+-----------------------------------------------------------------------+

> **Классификация**\
> **Логистическая регрессия**\
> **Логистическая регрессия** - это статистическая модель, используемая
> дляпрогнозирования вероятности возникновения события путём подгонки
> данных клогистической кривой. Она широко используется для бинарной
> классификации.

+-----------------------------------+-----------------------------------+
| > **Как работает логистическая    | ![](vertopal_c0b099a1bf474e9      |
| > регрессия:**                    | 590819adae366c879/media/image250. |
| >                                 | png){width="1.5930544619422573in" |
| > ![](vertopal_c0b099a1bf474e9    | height="1.511111111111111in"}     |
| 590819adae366c879/media/image249. |                                   |
| png){width="3.7916666666666665in" |                                   |
| > height="1.2805544619422573in"}  |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

+-----------------------------------+-----------------------------------+
| ![](vertopal_c0b099a1bf474e       | ![](vertopal_c0b099a1bf474e       |
| 9590819adae366c879/media/image251 | 9590819adae366c879/media/image252 |
| .png){width="2.551388888888889in" | .png){width="3.301388888888889in" |
| height="1.5930555555555554in"}    | height="0.9680555555555556in"}    |
+===================================+===================================+
| > ![](vertopal_c0b099a1bf474e     |                                   |
| 9590819adae366c879/media/image253 |                                   |
| .png){width="5.655555555555556in" |                                   |
| > height="4.520833333333333in"}   |                                   |
+-----------------------------------+-----------------------------------+

> **Переход к
> вероятности**![](vertopal_c0b099a1bf474e9590819adae366c879/media/image256.png){width="4.062498906386701in"
> height="1.392729658792651in"}

+-----------------------------------+-----------------------------------+
| > **(wnxn + wn-1xn-1 + ... +      |                                   |
| > w1x1 + w0) \> 0**\              |                                   |
| > то объект относится к классу I\ |                                   |
| > **σ(wnxn + wn-1xn-1 + ... +     |                                   |
| > w1x1 + w0)**\                   |                                   |
| > вероятность принадлежности      |                                   |
| > объекта к классу I**σ** -       |                                   |
| > сигмоид                         |                                   |
|                                   |                                   |
| <table>                           |                                   |
| <colgroup>                        |                                   |
| <col style="width: 20%" />        |                                   |
| <col style="width: 20%" />        |                                   |
| <col style="width: 20%" />        |                                   |
| <col style="width: 20%" />        |                                   |
| <col style="width: 20%" />        |                                   |
| </colgroup>                       |                                   |
| <thead>                           |                                   |
| <tr class="header">               |                                   |
| <th></th>                         |                                   |
| <th><blockquote>                  |                                   |
| <p>𝑧<br />                        |                                   |
| 𝑒</p>                             |                                   |
| </blockquote></th>                |                                   |
| <th></th>                         |                                   |
| <th></th>                         |                                   |
| <th>1</th>                        |                                   |
| </tr>                             |                                   |
| </thead>                          |                                   |
| <tbody>                           |                                   |
| <tr class="odd">                  |                                   |
| <td>σ(𝑧) =</td>                   |                                   |
| <td><blockquote>                  |                                   |
| <p>𝑧1+𝑒</p>                       |                                   |
| </blockquote></td>                |                                   |
| <td><blockquote>                  |                                   |
| <p>или</p>                        |                                   |
| </blockquote></td>                |                                   |
| <td>σ(𝑧) =</td>                   |                                   |
| <td><blockquote>                  |                                   |
| <p>−𝑧1+𝑒</p>                      |                                   |
| </blockquote></td>                |                                   |
| </tr>                             |                                   |
| </tbody>                          |                                   |
| </table>                          |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Что минимизируем?**

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image254.png){width="5.177777777777778in"
  height="1.0625in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image255.png){width="6.147222222222222in"
  height="1.9277777777777778in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Регуляризация функции потерь**\
> Если веса слишком большие или разных порядков\
> ● L2 регуляризация\
> ● L1 регуляризация
>
> **L1 регуляризация**

  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image257.png){width="3.8222222222222224in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image258.png){width="2.0527777777777776in"
  height="2.738888888888889in"}                                                                    height="0.8333333333333334in"}
  ------------------------------------------------------------------------------------------------ ------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image259.png){width="6.102777777777778in"    
  height="3.969443350831146in"}                                                                    

  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

> **L2 регуляризация**

+-----------------------------------------------------------------------+
| ![](vertopal_c0b099a1bf4                                              |
| 74e9590819adae366c879/media/image260.png){width="6.061111111111111in" |
| height="3.375in"}                                                     |
+=======================================================================+
| ![](vertopal_c0b099a1bf4                                              |
| 74e9590819adae366c879/media/image261.png){width="6.041665573053368in" |
| height="1.9069433508311462in"}                                        |
+-----------------------------------------------------------------------+
| > Эта штрафная функция является суммой квадратов весов модели,        |
| > умноженных нагиперпараметр регуляризации. Это означает, что L2      |
| > регуляризация штрафуетбольшие значения весов, заставляя их          |
| > приближаться к нулю, но в отличие от L1регуляризации не зануляет их |
| > полностью. Вместо этого L2 регуляризация штрафуетбольшие значения   |
| > весов более гладко и непрерывно, что позволяет более                |
| > уверенноуправлять компромиссом между точностью и сложностью модели. |
|                                                                       |
| ![](vertopal_c0b099a1bf4                                              |
| 74e9590819adae366c879/media/image262.png){width="6.102777777777778in" |
| height="2.0527766841644794in"}                                        |
+-----------------------------------------------------------------------+

> **Метод k-ближайших соседей (k-NN)**\
> **Метод k-ближайших соседей** - это непараметрический алгоритм,
> который использует\'k\' наиболее близких обучающих примеров в
> пространстве признаков для\
> прогнозирования новых данных.
>
> **Как работает k-NN:**\
> ● Выбор числа k: Количество соседей для рассмотрения.
>
> ● Вычисление расстояния: Обычно используется евклидово расстояние.●
> Голосование для классификации / Среднее для регрессии: Используется
> для определения класса или предсказания значения.
>
> **Оценка качества моделей**\
> Для оценки моделей используются различные метрики:\
> ● **Классификация:** Точность (Accuracy), Полнота (Recall), Точность
> (Precision), F1-мера, ROC-AUC.
>
> ● **Регрессия:** Среднеквадратичная ошибка (MSE), Средняя абсолютная
> ошибка (MAE).
>
> **Наивные Байесовские алгоритмы**\
> Почему "наивные" ?
>
> Такие же наивные как и ты, когда надеешься подготовится к экзамену за
> 1 ночь
>
> **Как работает наш мозг**\
> Вы видите, что в траве лежит что-то зеленое и круглое.\
> Ваш мозг сразу подсказывает вам, что это.
>
> Что он подсказал?
>
> **Теорема Байеса**
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image263.png){width="2.676388888888889in"
> height="0.6874989063867016in"}
>
> \- P(A\|B) - вероятность наступления события А, при условии, что
> событие В уже случилось;\
> - P(B\|A) -- вероятность наступления события В, при условии, что
> событие А уже случилось. Сейчас это выглядит как какой-то замкнутый
> круг, но мы скоро поймем, почему формула работает;

+-----------------------------------+-----------------------------------+
| > \-\                             | > P(A) -- априорная (безусловная) |
| > -                               | > вероятность наступления события |
|                                   | > А; P(B) -- априорная            |
|                                   | > (безусловная) вероятность       |
|                                   | > наступления события В.          |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Немного теории вероятности**

+-----------------------------------+-----------------------------------+
| > **Вероятность события** -       | ![](vertopal_c0b099a1bf474e       |
| > отношение числа благоприятных   | 9590819adae366c879/media/image264 |
| > исходов кчислу всех возможных   | .png){width="0.958332239720035in" |
| > исходов То есть вероятность     | height="0.5833333333333334in"}    |
| > события\                        |                                   |
| > показывает, какую часть         |                                   |
| > благоприятные исходы составляют |                                   |
| > от всехвозможных исходов.       |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> Если мы вычисляем вероятность события A в предположении, что событие B
> ужепроизошло (то есть условную вероятность), то в этом случае для нас
> множествоисходов, благоприятствующих событию B окажется множеством
> всех возможныхисходов, а благоприятными исходами будут те исходы,
> которые при этом ещеблагоприятствуют событию A.
>
> То есть нам нужно найти, какую часть число исходов, благоприятствующих
> событиям исоставляет от числа исходов, благоприятствующих событию.

+-----------------------------------+-----------------------------------+
| > \- Пусть для некоторого         | ![](vertopal_c0b099a1bf474e       |
| > эксперимента красный круг       | 9590819adae366c879/media/image265 |
| > обозначает множество всех       | .png){width="2.238888888888889in" |
| > возможных исходов.              | height="2.0930544619422573in"}    |
| >                                 |                                   |
| > \- Зеленый круг обозначает      |                                   |
| > множество\                      |                                   |
| > исходов, благоприятствующих     |                                   |
| > событию A Синий круг обозначает |                                   |
| > множество исходов,-\            |                                   |
| > благоприятствующих событию B\   |                                   |
| > - Область, лежащая в            |                                   |
| > пересечении этих\               |                                   |
| > кругов, обозначает множество    |                                   |
| > исходов,\                       |                                   |
| > благоприятствующих обоим        |                                   |
| > событиям А и В, обозначим его   |                                   |
| > AB                              |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image266.png){width="6.272222222222222in"
  height="1.625in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

  ------------------------------------------------------------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image267.png){width="1.1666666666666667in"                                       
  height="0.3958333333333333in"}                                                                                                       
  ------------------------------------------------------------------------------------------------ ----------------- ----------------- -----------------

  ------------------------------------------------------------------------------------------------------------------------------------------------------

> **Пример 1**

+-----------------------------------------------------------------------+
| > **Пример 1:** На фабрике керамической посуды 10% произведённых      |
| > тарелок имеютдефект. При контроле качества продукции выявляется 80% |
| > дефектных тарелок.Остальные тарелки поступают в продажу. Найдите    |
| > вероятность того, что случайновыбранная при покупке тарелка не      |
| > имеет дефектов.                                                     |
+=======================================================================+
| > **Дерево вероятностей**\                                            |
| > **Красные линии** - то, что поступило в продажу                     |
+-----------------------------------------------------------------------+
| ![](vertopal_c0b099a1bf4                                              |
| 74e9590819adae366c879/media/image268.png){width="6.083332239720035in" |
| height="2.9694444444444446in"}                                        |
+-----------------------------------------------------------------------+
| > Красными веточками обозначены тарелки, которые поступили в продажу. |
| >                                                                     |
| > Это тарелки без дефектов (они составляют 0,9 от всех тарелок) и     |
| > тарелки с\                                                          |
| > дефектами, которые пропустила система контроля. Их 0.1\*0.2 = 0.02  |
| > от всех тарелок.                                                    |
| >                                                                     |
| > Таким образом, вероятность того, что тарелка поступила в продажу    |
| > равна:\                                                             |
| > 0.9 + 0.02 = 0.92\                                                  |
| > При этом вероятность того, что тарелка не имеет дефектов равна 0.9\ |
| > Следовательно, вероятность того, что случайно выбранная при покупке |
| > тарелка неимеет дефектов равна:\                                    |
| > 0.9/0.92 = 0.98                                                     |
+-----------------------------------------------------------------------+

> **k-ближайших соседей**\
> **Алгоритм строится следующим образом:**\
> 1. сначала вычисляется расстояние между тестовым и всеми обучающими
> образцами;\
> 2. далее из них выбирается k-ближайших образцов (соседей), где число k
> задаётся заранее;\
> 3. итоговым прогнозом среди выбранных k-ближайших образцов будет мода
> в случае классификации и среднее арифметическое в случае
> регрессии;![](vertopal_c0b099a1bf474e9590819adae366c879/media/image269.png){width="6.781944444444444in"
> height="9.54713145231846in"}

+-----------------------------------+-----------------------------------+
| 4\.                               | > предыдущие шаги повторяются для |
|                                   | > всех тестовых образцов.         |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Существует множество метрик для вычисления расстояния между
> объектами,среди которых наиболее популярными являются следующие:**\
> ● Евклидово расстояние - это наиболее простая и общепринятая метрика,
> которая определяется как длина отрезка между двумя объектами a и b в
> пространстве с n признаками и вычисляется по формуле:

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

+-----------------------------------+-----------------------------------+
| ●                                 | > Манхэттенское расстояние -      |
|                                   | > метрика, которая определяется   |
|                                   | > как сумма модулей               |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> разностей координат двух точек в пространстве между двумя объектами
> **a** и **b** с**n** признаками и вычисляется по формуле:

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

+-----------------------------------+-----------------------------------+
| ●                                 | > Косинусное расстояние -         |
|                                   | > метрика, которая определяется   |
|                                   | > как угол между двумя            |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> векторами **a** и **b** в пространстве с **n** признаками и
> вычисляется по формуле:

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

> **Решающие деревья** - это модель, которая использует древовидную
> структуру дляпринятия решений. Каждый узел в дереве представляет
> признак (или атрибут), каждыйветвь - решение (или правило), а каждый
> лист - исход (решение или
> класс).![](vertopal_c0b099a1bf474e9590819adae366c879/media/image270.png){width="3.8847222222222224in"
> height="3.6770133420822395in"}![](vertopal_c0b099a1bf474e9590819adae366c879/media/image271.png){width="3.3125in"
> height="2.13286854768154in"}
>
> **Как работают решающие деревья:**\
> ● Выбор признака: на каждом шаге выбирается признак, который наилучшим
> образом разделяет набор данных на основе некоторого критерия\
> информативности (например, индекс Джини или энтропия).
>
> ● Разделение: данные разделяются на подмножества, которые содержат
> возможные значения выбранного признака.

+-----------------------------------+-----------------------------------+
| ●                                 | > Рекурсия: процесс повторяется   |
|                                   | > для каждого производного        |
|                                   | > подмножества.                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Случайные леса (Random Forests)**\
> **Случайный лес** - это ансамблевый метод машинного обучения, который
> строитмножество решающих деревьев при обучении и выводит моду классов\
> (классификация) или среднее предсказание (регрессия) отдельных
> деревьев.
>
> **Преимущества случайных лесов:**\
> ● Устойчивость к переобучению: благодаря ансамблевой природе и
> использованию множества деревьев модели меньше подвержены переобучению
> по сравнению с одиночными решающими деревьями.
>
> ● Высокая точность: случайные леса часто демонстрируют высокую
> точность предсказаний на широком спектре данных.
>
> По сравнению с другими методами машинного обучения, теоретическая
> частьалгоритма Random Forest проста. У нас нет большого объема теории,
> необходиматолько формула **итогового классификатора a(x)**:

+-----------------------------------+-----------------------------------+
|                                   | > **Где**                         |
|                                   | >                                 |
|                                   | > ● N - количество деревьев       |
|                                   | >                                 |
|                                   | > ● i - счетчик для деревьев      |
|                                   | >                                 |
|                                   | > ● b - решающее дерево           |
|                                   | >                                 |
|                                   | > ● x - сгенерированная нами на   |
|                                   | > основе данных выборка           |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> jupyter notebook - classification_ed\
> **Ссылка:**
>
> (31.05.24) Семинар 4.3
>
> Лабораторная работа №3
>
> **Описание датасета**\
> Датасет состоит из двух файлов: \`TrainData3.csv\` и
> \`TestData3.csv\`, содержащихтренировочные и тестовые данные
> соответственно. Каждый файл включает в себяанонимизированные
> характеристики клиентов некоторой компании и целевуюпеременную,
> указывающую, покинет ли клиент компанию.
>
> \- TrainData3.csv: Тренировочный набор данных, содержащий 1000
> записей.
>
> TestData3.csv: Тестовый набор данных, содержащий 300 записей.-
>
> Каждый файл включает 15 столбцов, из которых 14 - это
> анонимизированные признакиклиентов, а 15-й столбец - целевая
> переменная.
>
> 1\. feature_0 до feature_13: Анонимизированные числовые признаки
> клиентов. Значения этих признаков варьируются от 0 до 100.
>
> 2\. target: Целевая переменная (0 или 1). Показывает, покинет ли
> клиент компанию: \`1\`: Клиент покинет компанию-\
> - \`0\`: Клиент останется в компании
>
> **Задача оттока клиентов**\
> **Часть 1: Работа с пропусками**\
> **Задание 1**\
> Проверьте, есть ли в тренировочных и тестовых данных пропуски? Укажите
> количествостолбцов тренировочной выборки, имеющих пропуски.
>
> **Задание 2**\
> a. В столбце с наибольшим количеством пропусков заполните пропуски
> средним значением по столбцу. В ответ запишите значение вычисленного
> среднего. Ответ округлите до десятых.
>
> b\. Найдите строки в тренировочных данных, где пропуски стоят в
> столбце с наименьшим количеством пропусков. Удалите эти строки.
> Сколько строк вы удалили?
>
> **Часть 2: Предобработка данных**\
> **Задание 3**\
> Выполните следующие пункты только по таблице train.
>
> a\. Сколько столбцов в таблице (не считая target) содержат меньше 5
> различных значений?
>
> b\. Вычислите долю ушедших из компании клиентов, для которых значение
> признака 2 больше среднего значения по столбцу, а значение признака 13
> меньше медианы по столбцу. Ответ округлите до сотых.
>
> **Часть 3: Обучение модели**\
> **Задание 4**\
> a. Разбейте тренировочные данные на целевой вектор y, содержащий
> значения из столбца target, и матрицу объект-признак X, содержащую
> остальные признаки.
>
> Обучите на этих данных логистическую регрессию из sklearn\
> (LogisticRegression) с параметрами по умолчанию. Выведите среднее
> значениеметрики f1-score алгоритма на кросс-валидации с тремя фолдами.
> Ответокруглите до сотых.
>
> При объявлении модели фиксируйте random_state = 42.
>
> Комментарий: параметры по умолчанию можете оставить дефолтными
>
> **Задание 5**\
> a. Подберите значение константы регуляризации C в логистической
> регрессии, перебирая гиперпараметр от 0.001 до 100 включительно,
> проходя по степеням 10. Для выбора C примените перебор по сетке по
> тренировочной выборке (GridSearchCV из библиотеки
> sklearn.model_selection) с тремя фолдами и метрикой качества -
> f1-score. Остальные параметры оставьте по умолчанию. В ответ запишите
> наилучшее среди искомых значение C.
>
> При объявлении модели фиксируйте random_state = 42.
>
> Комментарий: параметры по умолчанию можете оставить дефолтными
>
> b\. Добавьте в тренировочные и тестовые данные новый признак \'NEW\',
> равный произведению признаков \'7\' и \'11\'. На тренировочных данных
> с новым признаком заново с помощью GridSearchCV (с тремя фолдами и
> метрикой качества - f1-score) подберите оптимальное значение C
> (перебирайте те же значения C, что и в предыдущих заданиях), в ответ
> напишите наилучшее качество алгоритма (по метрике f1-score), ответ
> округлите до сотых.
>
> При объявлении модели фиксируйте random_state = 42.
>
> c\. Теперь вы можете использовать любую модель машинного обучения для
> решения задачи. Также можете делать любую другую обработку признаков.
> Ваша задача - получить наилучшее качество по метрике F1-Score на
> тестовых данных.
>
> Лучший результат будет можно будет добавить в викторину в Телеграмм,
> победительполучит +2 балла к оценке
>
> (03.06.24) Лекция 4.5\
> **Ансамблевые методы**\
> **Основные концепции ансамблевого обучения**

+-----------------------------------+-----------------------------------+
| > **Бэггинг (Bagging)**\          |   ------------------              |
| > **Бэггинг (Bootstrap            | --------------------------------- |
| > Aggregating)** - этометод, при  | --------------------------------- |
| > котором несколько               |   ![](vertopal_c0b                |
| > моделейобучаются на разных      | 099a1bf474e9590819adae366c879/med |
| > подвыборках\                    | ia/image272.png){width="2.9375in" |
| > исходных данных, а результаты   |   height="2.1666666666666665in"}  |
| > этихмоделей усредняются или\    |   ------------------              |
| > комбинируются для получения\    | --------------------------------- |
| > финального предсказания.        | --------------------------------- |
| >                                 |                                   |
| > **Пример:** Случайный лес       |   ------------------              |
| > (Random Forest)является         | --------------------------------- |
| > примером бэггинга, где\         | --------------------------------- |
| > множество деревьев решений      |                                   |
| > обучаютсяна различных           |                                   |
| > подвыборках данных.             |                                   |
| >                                 |                                   |
| > **Преимущества:** Уменьшение    |                                   |
| > дисперсиимодели, снижение       |                                   |
+===================================+===================================+
| > **Бустинг (Boosting)**\         |   -----------------------------   |
| > **Определение: Бустинг** - это  | --------------------------------- |
| > метод, прикотором модели        | --------------------------------- |
| > обучаются\                      |   ![](vertopal_c0b099a1bf474e     |
| > последовательно, и каждая       | 9590819adae366c879/media/image273 |
| > следующаямодель исправляет      | .png){width="2.926388888888889in" |
| > ошибки предыдущих.              |   height="2.1458333333333335in"}  |
| >                                 |   -----------------------------   |
| > Предсказания всех моделей\      | --------------------------------- |
| > комбинируются с весами,         | --------------------------------- |
| > которыезависят от их точности.  |                                   |
| >                                 |   -----------------------------   |
| > **Пример:** Gradient Boosting,  | --------------------------------- |
| > AdaBoost.                       | --------------------------------- |
| >                                 |                                   |
| > **Преимущества:** Увеличение    |                                   |
| > точностимодели за счет          |                                   |
| > фокусировки на трудныхдля       |                                   |
| > классификации объектах,         |                                   |
| > улучшениеобобщающей             |                                   |
| > способности.                    |                                   |
+-----------------------------------+-----------------------------------+

![](vertopal_c0b099a1bf474e9590819adae366c879/media/image275.png){width="3.7763877952755904in"
height="2.1586931321084863in"}

+-----------------------------------+-----------------------------------+
| > **Случайный лес (Random         |   ------------------------------  |
| > Forest)**\                      | --------------------------------- |
| > **Описание:** Случайный лес     | --------------------------------- |
| > состоит из множествадеревьев    |   ![](vertopal_c0b099a1bf474e9    |
| > решений, каждое из которых      | 590819adae366c879/media/image274. |
| > обучаетсяна случайной           | png){width="2.3444444444444446in" |
| > подвыборке данных с\            |   height="1.7499989063867016in"}  |
| > использованием случайного       |   ------------------------------  |
| > подмножества\                   | --------------------------------- |
| > признаков.                      | --------------------------------- |
| >                                 |                                   |
| > **Как работает:**\              |   ------------------------------  |
| > ● На каждом шаге строится       | --------------------------------- |
| > дерево решений на случайной     | --------------------------------- |
| > подвыборке данных.              |                                   |
| >                                 |                                   |
| > ● Для каждого дерева            |                                   |
| > используется случайное          |                                   |
| > подмножество признаков.         |                                   |
| >                                 |                                   |
| > Финальное предсказание          |                                   |
| > получается●\                    |                                   |
| > путем усреднения (для           |                                   |
| > регрессии) илиголосования (для  |                                   |
| > классификации) всехдеревьев.    |                                   |
| >                                 |                                   |
| > **Преимущества:** Снижение      |                                   |
| > дисперсии модели,устойчивость к |                                   |
| > переобучению, хорошая\          |                                   |
| > производительность на           |                                   |
| > высокоразмерных\                |                                   |
| > данных.                         |                                   |
| >                                 |                                   |
| > **Недостатки:** Может быть      |                                   |
| > менее\                          |                                   |
| > интерпретируемым, чем отдельное |                                   |
| > дереворешений.                  |                                   |
+===================================+===================================+
| > **Градиентный бустинг (Gradient | > **Градиентный бустинг в Spark   |
| > Boosting)**\                    | > ML**                            |
| > **Описание:** Градиентный       |                                   |
| > бустинг создает\                |   ------------------------------  |
| > ансамбль моделей, обучающихся\  |                                   |
| > последовательно, каждая из      |   ------------------------------  |
| > которых исправляетошибки        |                                   |
| > предыдущих моделей.             |                                   |
| >                                 |                                   |
| > **Как работает:**\              |                                   |
| > ● На первом шаге обучается      |                                   |
| > начальная модель.               |                                   |
| >                                 |                                   |
| > ● На каждом следующем шаге      |                                   |
| > обучается модель на остатках    |                                   |
| > (ошибках)\                      |                                   |
| > предыдущей модели.              |                                   |
| >                                 |                                   |
| > ● Все модели комбинируются для  |                                   |
| > получения финального            |                                   |
| > предсказания.                   |                                   |
| >                                 |                                   |
| > **Преимущества:** Высокая       |                                   |
| > точность,                       |                                   |
| > возможностьиспользования        |                                   |
| > различных базовых моделей.      |                                   |
| >                                 |                                   |
| > **Недостатки:** Могут быть      |                                   |
| > подвержены\                     |                                   |
| > переобучению, особенно при      |                                   |
| > большом числешагов,             |                                   |
| > требовательны к                 |                                   |
| > вычислительнымресурсам.         |                                   |
+-----------------------------------+-----------------------------------+

+-----------------------------------------------------------------------+
| > **XGBoost (Extreme Gradient Boosting)**\                            |
| > **Описание:** XGBoost - это усовершенствованная версия градиентного |
| > бустинга,оптимизированная для скорости и производительности.        |
| >                                                                     |
| > **Как работает:** Использует усовершенствованные техники для        |
| > обработки пропусков вданных, регуляризацию, параллельные вычисления |
| > и кэширование.                                                      |
| >                                                                     |
| > **Преимущества:** Высокая производительность, возможность тонкой    |
| > настройки,встроенные методы предотвращения переобучения.            |
| >                                                                     |
| > **Недостатки:** Сложнее в настройке, чем другие алгоритмы.          |
+=======================================================================+
| ![](vertopal_c0b099a1bf4                                              |
| 74e9590819adae366c879/media/image276.png){width="6.072222222222222in" |
| height="1.6041666666666667in"}                                        |
+-----------------------------------------------------------------------+

> **Кластеризация**\
> **Что такое кластеризация?**
>
> ● **Кластеризация** - это процесс организации объектов на группы,
> элементы которых схожи в некотором роде.
>
> ● **Кластер** - это группа похожих объектов.
>
> **Примечание:** Кластеризация может показаться очень похожей на●\
> классификацию. В чем же отличие? Некоторые авторы утверждают,
> чтопринципиальное отличие в количестве кластеров, которое нельзя
> задатьзаранее. Другие -- разница в методах обучения. Кластеризация
> используетметоды обучения без учителя.
>
> **Пример 1**

+-----------------------------------+-----------------------------------+
| > **Пример 1 (продолжение)**\     | ![](vertopal_c0b099a1bf474e       |
| > В примере явно просматриваются  | 9590819adae366c879/media/image277 |
| > 4кластера. В качестве критерия  | .png){width="2.977777777777778in" |
| > подобияможно использовать       | height="1.0097211286089238in"}    |
| > расстояние. Дваили более        |                                   |
| > объектов принадлежат\           |                                   |
| > одному кластеру, если они       |                                   |
| > 'близко'\                       |                                   |
| > расположены друг от друга в\    |                                   |
| > соответствии с выбранным        |                                   |
| > критерием(расстоянием). Такая   |                                   |
| > кластеризацияназывается         |                                   |
| > кластеризацией на               |                                   |
| > основерасстояния.               |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Виды кластеризации**\
> **Различают 2 вида кластеризации:**\
> ● **жесткая** (hard clastering)\
> ● **мягкая** (soft clastering)\
> - При жесткой кластеризации каждый элемент исходного data set
> принадлежит только к одному кластеру, при мягкой - может принадлежать
> к нескольким.
>
> **Как определить качество кластеризации?**
>
> Нет никаких универсальных критериев, которые в общем случае могут
> оценитькачество кластеризации (однако активные исследования в этом
> направлении ведутся).
>
> Качество кластеризации всегда привязано к специфике конкретной задачи
> и, какправило, выражается в виде какой-то целевой функции, которую
> надо минимизироватьили максимизировать.
>
> **Сферы применения кластеризации**\
> ● **Маркетинг:** определение групп клиентов с похожим поведением.
>
> ● **Биология:** кластеризация растений и животных с учетом их
> особенностей.● **Страхование:** выявление групп держателей страховых
> полисов в соответствии со степенью риска.
>
> ● **Землетрясения:** кластеризация эпицентров с целью выявления
> опасных зон.● И т.п.
>
> **Проблемы кластеризации**\
> ● Не все методы кластеризации в состоянии учитывать некоторые свойства
> атрибутов кластеризуемых объектов;\
> ● Для методов, основанных на расстояниях, эффективность сильно зависит
> от определения расстояния, которое может определяться неоднозначно; ●
> Результаты кластеризации могут трактоваться неоднозначно.
>
> **Нормализация значений атрибутов объектов**\
> Важной составляющей алгоритмов кластеризации, основанных на
> расстоянии,является измерение расстояния между объектами. Если
> атрибуты измеряются однимии теми же физическими единицам, то, как
> правило, метрики евклидова расстояниябывает достаточно. Однако в более
> сложных случаях требуется проводить\
> нормализацию (масштабирование, приведение к единой или, по крайней
> мере,соизмеримой шкале) атрибутов. Такое преобразование атрибутов в
> общем случаеможет привести к различным результатам (см. рис. на след
> слайде). Разумеется, самаяподходящая нормализация может быть выбрана
> только на основе знаний о\
> предметной области. Тем не менее универсальные приемы нормализации
> существуют.
>
> **Пример 2**

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image278.png){width="6.272222222222222in"
  height="2.25in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **MinMax нормализация**\
> Существует много подходов для нормализации данных. Один из наиболее\
> распространенных - нормализация на основе минимума-максимума. Для
> такого типанормализации используется следующая формула:

+-----------------------------------+-----------------------------------+
|   ------------------------------  | > **где X\*** - это               |
| --------------------------------- | > нормализованное значение,\      |
| --------------------------------- | > **min(X),max(X)** - минимальное |
|   ![](vertopal_c0b099a1bf474e9    | > и максимальноезначение атрибута |
| 590819adae366c879/media/image279. | > X.                              |
| png){width="2.2916666666666665in" | >                                 |
|   height="0.5833333333333334in"}  | > **Примечание:**данная формула   |
|   ------------------------------  | > располагает всекоординаты на    |
| --------------------------------- | > отрезке \[0;1\]                 |
| --------------------------------- |                                   |
|                                   |                                   |
|   ------------------------------  |                                   |
| --------------------------------- |                                   |
| --------------------------------- |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Измерение расстояний**

+-----------------------+-----------------------+-----------------------+
| > Для многомерных     | > При p=2 -           | > При p=1 -           |
| > случаев\            | > метрикаЕвклида:     | > Ма                  |
| > популярной мерой    |                       | нхэттенскоерасстояние |
| > расстоянияявляется  |                       | >                     |
| > метрика             |                       |  (расстояниегородских |
| > Минковского:        |                       | > кварталов):         |
+=======================+=======================+=======================+
| > ![](verto           | ![](vertop            | > ![](vertop          |
| pal_c0b099a1bf474e959 | al_c0b099a1bf474e9590 | al_c0b099a1bf474e9590 |
| 0819adae366c879/media | 819adae366c879/media/ | 819adae366c879/media/ |
| /image280.png){width= | image281.png){width=" | image282.png){width=" |
| "1.738888888888889in" | 1.5833333333333333in" | 1.4472211286089238in" |
| > height="0           | height="0             | > height="0           |
| .5416666666666666in"} | .4791666666666667in"} | .5527777777777778in"} |
+-----------------------+-----------------------+-----------------------+

> **Как проверить качество кластеризации на основе расстояния?**
>
> ● После получений результатов кластерного анализа можно проверить\
> правильность кластеризации (т.е. оценить, насколько кластеры
> отличаются друг от друга).
>
> ● Для этого рассчитываются средние значения для каждого кластера. При
> хорошей кластеризации должны быть получены сильно отличающиеся средние
> для всех измерений или хотя бы большей их части.
>
> **Алгоритм K-means**

+-----------------------------------+-----------------------------------+
| > Простейший алгоритм             |   ------------------------------  |
| > кластеризации, основанный на    | --------------------------------- |
| > определениирасстояний. В основе | --------------------------------- |
| > алгоритма - определение k       |   ![](vertopal_c0b099a1bf474e9    |
| > центроидов (поодному для        | 590819adae366c879/media/image283. |
| > каждого кластера). В дальнейшем | png){width="1.0416666666666667in" |
| > центроиды\                      |   height="0.4583333333333333in"}  |
| > переопределяются, однако их     |   ------------------------------  |
| > начальное местоположение        | --------------------------------- |
| > можетсильно повлиять на         | --------------------------------- |
| > конечный результат.             |                                   |
| >                                 |   ------------------------------  |
| > **Весь смысл алгоритма -        | --------------------------------- |
| > минимизация целевой функции:**  | --------------------------------- |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Шаги алгоритма K-means**\
> 1. Определить количество кластеров и выбрать начальные центроиды для
> каждого кластера.
>
> 2\. Сопоставить каждый анализируемый объект кластеру с ближайшим
> выбранным расстоянием до центроида.
>
> В каждом сформированном кластере пересчитать местоположение
> центроида3.
>
> на основе объектов, вошедших в кластер.
>
> 4\. Повторять шаги 2 и 3 пока местоположение центроидов не перестанет
> изменяться.
>
> 5\. Оценить качество кластеризации. Если плохо -- вернуться к шагу 1 и
> изменить количество кластеров.
>
> **Как пересчитать местоположение центроида?**
>
> **Простейший вариант** - среднее арифметическое соответствующих
> координат всехобъектов кластера. Например, в двумерном случае с
> координатами x и y:
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image284.png){width="3.8652777777777776in"
> height="0.5208333333333334in"}
>
> **Пример перерасчета местоположения центроидов**

+-----------------------------------+-----------------------------------+
| > **До перерасчета**              | > **После перерасчета**           |
| >                                 | >                                 |
| > ![](vertopal_c0b099a1bf474e     | > ![](vertopal_c0b099a1bf474e9    |
| 9590819adae366c879/media/image285 | 590819adae366c879/media/image286. |
| .png){width="2.259721128608924in" | png){width="2.4361100174978128in" |
| > height="1.0416666666666667in"}  | > height="1.0416666666666667in"}  |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Недостатки k-means**\
> ● Алгоритм не всегда находит глобальный минимум, соответствующий
> целевой функции.
>
> ● Алгоритм очень чувствителен к начальному определению центроидов
> (поэтому в сомнительных случаях рекомендуется задавать начальные
> центроиды несколько раз).
>
> ● Алгоритм очень чувствителен к количеству определяемых кластеров.
>
> ● И, тем не менее, это хороший алгоритм, который адаптирован для
> многих предметных областей и дает хороший результат при правильном\
> использовании.
>
> **Кластеризация DBSCAN**\
> DBSCAN (Density-Based Spatial Clustering of Applications with Noise) -
> это один изпопулярных алгоритмов кластеризации, который выделяет
> кластеры на основеплотности точек в пространстве. В отличие от других
> алгоритмов, таких как k-means, DBSCAN не требует заранее задавать
> количество кластеров и эффективно работает скластерами произвольной
> формы и с шумами в данных.

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image287.png){width="6.272222222222222in"
  height="2.3333333333333335in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **Плотность**

+-----------------------------------+-----------------------------------+
| > Плотность в контексте DBSCAN    | ![](vertopal_c0b099a1bf474e9      |
| > определяется числомточек данных | 590819adae366c879/media/image288. |
| > в окрестности определенного     | png){width="1.9166666666666667in" |
| > радиуса.                        | height="1.375in"}                 |
| >                                 |                                   |
| > **Параметры алгоритма:**\       |                                   |
| > ● **eps (ε):** Радиус           |                                   |
| > окрестности точки.              |                                   |
| >                                 |                                   |
| > ● **min_samples:** Минимальное  |                                   |
| > число точек в\                  |                                   |
| > радиусе eps, чтобы окрестность  |                                   |
| > точки считалась достаточно      |                                   |
| > плотной.                        |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Типы точек**\
> **1.** **Core Point (Основная точка):** Точка, в окрестности eps
> которой находится не менее min_samples точек, включая саму точку.
>
> **2.** **Border Point (Граничная точка):** Точка, которая находится в
> окрестности eps основной точки, но сама не является основной.
>
> **Noise Point (Шумовая точка):** Точка, которая не является ни
> основной, ни**3.**
>
> граничной.
>
> **Введение в нейронные сети и глубокое
> обучение**![](vertopal_c0b099a1bf474e9590819adae366c879/media/image291.png){width="5.933333333333334in"
> height="3.338488626421697in"}

+-----------------------------------+-----------------------------------+
| > **Основы нейронных              | > ![](vertopal_c0b099a1bf474e     |
| > сетейНейрон:**\                 | 9590819adae366c879/media/image289 |
| > ● Основная единица нейронной    | .png){width="3.448611111111111in" |
| > сети.                           | > height="2.448611111111111in"}   |
| >                                 |                                   |
| > ● Имитирует работу\             |                                   |
| > биологического нейрона.●        |                                   |
| > Выполняет взвешенное            |                                   |
| > суммирование входных сигналов,  |                                   |
| > применяет\                      |                                   |
| > функцию активации и\            |                                   |
| > передает результат на выход.    |                                   |
+===================================+===================================+
| > **Полносвязный слой (Dense      | ![](vertopal_                     |
| > Layer):**\                      | c0b099a1bf474e9590819adae366c879/ |
| > ● Слой нейронов, каждый из      | media/image290.png){width="3.5in" |
| > которых связан со всеми         | height="2.2916666666666665in"}    |
| > нейронами\                      |                                   |
| > предыдущего слоя.               |                                   |
| >                                 |                                   |
| > Каждый нейрон имеет●\           |                                   |
| > свои веса и смещение(bias).     |                                   |
+-----------------------------------+-----------------------------------+

> **Функции активации**

+-----------------------------------+-----------------------------------+
| > ● Применяются к выходу каждого  |                                   |
| > нейрона, чтобы придать          |                                   |
| > нелинейность модели             |                                   |
|                                   |                                   |
| +---------+---------+---------+   |                                   |
| |         |         | <table> |   |                                   |
| |         |         | <co     |   |                                   |
| |         |         | lgroup> |   |                                   |
| |         |         | <col    |   |                                   |
| |         |         | s       |   |                                   |
| |         |         | tyle="w |   |                                   |
| |         |         | idth: 1 |   |                                   |
| |         |         | 00%" /> |   |                                   |
| |         |         | </co    |   |                                   |
| |         |         | lgroup> |   |                                   |
| |         |         | <thead> |   |                                   |
| |         |         | <tr     |   |                                   |
| |         |         | c       |   |                                   |
| |         |         | lass="h |   |                                   |
| |         |         | eader"> |   |                                   |
| |         |         | <t      |   |                                   |
| |         |         | h><bloc |   |                                   |
| |         |         | kquote> |   |                                   |
| |         |         | <       |   |                                   |
| |         |         | p>1</p> |   |                                   |
| |         |         | </bl    |   |                                   |
| |         |         | ockquot |   |                                   |
| |         |         | e></th> |   |                                   |
| |         |         | </tr>   |   |                                   |
| |         |         | <       |   |                                   |
| |         |         | /thead> |   |                                   |
| |         |         | <tbody> |   |                                   |
| |         |         | <       |   |                                   |
| |         |         | /tbody> |   |                                   |
| |         |         | <       |   |                                   |
| |         |         | /table> |   |                                   |
| +=========+=========+=========+   |                                   |
| | ●       | **SIg   | > −𝑥1+𝑒 |   |                                   |
| |         | moid:** |         |   |                                   |
| |         | σ(𝑥) =  |         |   |                                   |
| +---------+---------+---------+   |                                   |
| | ●       |         |         |   |                                   |
| +---------+---------+---------+   |                                   |
| |         | **ReLU  |         |   |                                   |
| |         | (Re     |         |   |                                   |
| |         | ctified |         |   |                                   |
| |         | Linear  |         |   |                                   |
| |         | U       |         |   |                                   |
| |         | nit):** |         |   |                                   |
| +---------+---------+---------+   |                                   |
|                                   |                                   |
| > 𝑅𝑒𝐿𝑈(𝑥) = 𝑚𝑎𝑥(0, 𝑥)             |                                   |
|                                   |                                   |
| +--------------+--------------+   |                                   |
| | ●            | **Tanh       |   |                                   |
| |              | (Hyperbolic  |   |                                   |
| |              | Tangent):**  |   |                                   |
| +==============+==============+   |                                   |
| |              | +---------+  |   |                                   |
| |              | | 𝑡𝑎𝑛ℎ(𝑥) |  |   |                                   |
| |              | | =𝑒      |  |   |                                   |
| |              | |         |  |   |                                   |
| |              | | > 𝑒\    |  |   |                                   |
| |              | | > 𝑥−𝑒   |  |   |                                   |
| |              | | >       |  |   |                                   |
| |              | | > 𝑥+𝑒\  |  |   |                                   |
| |              | | > −𝑥    |  |   |                                   |
| |              | |         |  |   |                                   |
| |              | | −𝑥      |  |   |                                   |
| |              | +=========+  |   |                                   |
| |              | +---------+  |   |                                   |
| +--------------+--------------+   |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Архитектура нейронной сети**

+-----------------------------------+-----------------------------------+
| > **Входной слой:**\              | ![](vertopal_c0b099a1bf474e       |
| > принимает входныеданные.        | 9590819adae366c879/media/image292 |
| >                                 | .png){width="4.333333333333333in" |
| > **Скрытые слои:** одинили более | height="2.4277777777777776in"}    |
| > слоев\                          |                                   |
| > между входным и\                |                                   |
| > выходным слоями,\               |                                   |
| > которые извлекают\              |                                   |
| > признаки.                       |                                   |
| >                                 |                                   |
| > **Выходной слой:**\             |                                   |
| > выдает предсказаниямодели       |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Основные архитектуры нейронных сетей**

+-----------------------------------+-----------------------------------+
| **1. Полносвязные нейронные       |   -----------------------------   |
| сети(Fully Connected Neural       | --------------------------------- |
| Networks)**                       | --------------------------------- |
|                                   |   ![](vertopal_c0b099a1bf474e     |
| > Все нейроны каждого слоя        | 9590819adae366c879/media/image293 |
| > связанысо всеми нейронами       | .png){width="3.281943350831146in" |
| > предыдущегослоя.                |   height="1.9791666666666667in"}  |
| >                                 |   -----------------------------   |
| > Применяются для задач           | --------------------------------- |
| > регрессиии классификации.       | --------------------------------- |
|                                   |                                   |
|                                   |   -----------------------------   |
|                                   | --------------------------------- |
|                                   | --------------------------------- |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **2. Сверточные нейронные сети (Convolutional Neural Networks, CNN)**
>
> ● Специализируются на обработке данных, имеющих сеточную структуру
>
> (например, изображения).
>
> ● Основные компоненты: сверточные слои, пулинг слои, полносвязные
> слои.
>
> ● Примеры использования: распознавание объектов на изображениях,
>
> классификация изображений.
>
> ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image294.png){width="6.333333333333333in"
> height="1.9375in"}

+-----------------------------------+-----------------------------------+
| > **3. Рекуррентные нейронные     |                                   |
| > сети (Recurrent Neural          |                                   |
| > Networks, RNN)**Обрабатывают    |                                   |
| > последовательные данные,        |                                   |
| > учитывая временную              |                                   |
| > зависимость.**Основной          |                                   |
| > компонент:** рекуррентные слои. |                                   |
| >                                 |                                   |
| > **Примеры использования:**      |                                   |
| > обработка текста, временных     |                                   |
| > рядов, распознаваниеречи.       |                                   |
+===================================+===================================+
| > ![](vertopal_c0b099a1bf474e9    | > ![](vertopal_c0b                |
| 590819adae366c879/media/image295. | 099a1bf474e9590819adae366c879/med |
| png){width="2.1138877952755903in" | ia/image296.png){width="2.5625in" |
| > height="1.6666666666666667in"}  | > height="1.8847222222222222in"}  |
+-----------------------------------+-----------------------------------+

> **4. Глубокие нейронные сети (Deep Neural Networks)**

+-----------------------------------+-----------------------------------+
| > Содержат множество              | ![](vertopal_c0b099a1bf474e       |
| > скрытыхслоев.                   | 9590819adae366c879/media/image297 |
| >                                 | .png){width="3.636110017497813in" |
| > Могут обучаться                 | height="2.0416666666666665in"}    |
| > сложнымпредставлениям данных.   |                                   |
| >                                 |                                   |
| > Применяются в задачах,\         |                                   |
| > требующих высокой точности      |                                   |
| > иобработки больших              |                                   |
| > объемовданных.                  |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **Обучение нейронных сетей**

+-----------------------------------+-----------------------------------+
| > **1.**\                         | > **Прямое распространение        |
| > ●\                              | > (Forward Propagation):**\       |
| > ●                               | > Процесс, при котором входные    |
| >                                 | > данные проходят через все слои  |
| > **2.**\                         | > сети до выхода.Вычисляется      |
| > ●\                              | > выход модели на основе текущих  |
| > ●                               | > весов.                          |
|                                   | >                                 |
|                                   | > **Функция потерь (Loss          |
|                                   | > Function):**\                   |
|                                   | > Определяет, насколько хорошо    |
|                                   | > модель предсказывает целевые    |
|                                   | > значения.                       |
|                                   | >                                 |
|                                   | > **Примеры:** MSE (Mean Squared  |
|                                   | > Error) для регрессии,           |
|                                   | > CrossEntropy для                |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> классификации.
>
> **3.** **Обратное распространение ошибки (Backpropagation):**
>
> ● Процесс, при котором ошибка, вычисленная на выходе, распространяется
>
> обратно через сеть.

+-----------------------------------+-----------------------------------+
| ●                                 | > Обновляются веса всех слоев с   |
|                                   | > использованием градиентного     |
|                                   | > спуска.                         |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image298.png){width="6.115277777777778in"
  height="2.6555555555555554in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image299.png){width="6.041666666666667in"
  height="2.1152777777777776in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

> **1. Прямое распространение (Forward Propagation):**\
> - В этом этапе входные данные проходят через сеть от входного слоя к
> выходному.
>
> \- Вычисляются активации для каждого слоя и предсказание на выходе
> сети.
>
> **2. Вычисление ошибки (Error Calculation):**\
> - Ошибка (loss) вычисляется как разница между предсказанным значением
> и истинным значением.
>
> \- Используются различные функции потерь, например, среднеквадратичная
> ошибка (MSE) для регрессии или перекрестная энтропия (Cross2. Entropy)
> для классификации.
>
> **3. Обратное распространение (Backward Propagation):**\
> - Ошибка на выходе сети распространяется назад через все слои. -
> Вычисляются градиенты функции потерь относительно каждого веса и
> смещения сети с использованием правила цепочки.
>
> **4. Обновление весов (Weights Update):**\
> - Веса обновляются с использованием градиентного спуска или его
> вариаций. - На каждом шаге веса изменяются в направлении,
> противоположном градиенту функции потерь.

![](vertopal_c0b099a1bf474e9590819adae366c879/media/image300.png){width="8.113888888888889in"
height="10.023270997375327in"}

+-----------------------------------+-----------------------------------+
| > **1. Градиентный спуск          |                                   |
| > (Gradient**\                    |                                   |
| > **Descent):**\                  |                                   |
| > ● Алгоритм оптимизации,\        |                                   |
| > используемый для\               |                                   |
| > минимизации функции потерь. ●   |                                   |
| > Обновляет веса модели в\        |                                   |
| > направлении отрицательного      |                                   |
| > градиента функции потерь.       |                                   |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

> **1. Пакетный градиентный спуск (Batch Gradient Descent):**
>
> ● Использует весь тренировочный набор данных для вычисления градиента
> и
>
> обновления весов
>
> ● Медленный для больших наборов данных
>
> **2. Стохастический градиентный спуск (Stochastic Gradient Descent,
> SGD):**
>
> ● Обновляет веса для каждого отдельного примера
>
> ● Быстро, но может колебаться около минимума
>
> **3. Мини-пакетный градиентный спуск (Mini-batch Gradient Descent):**

+-----------------------------------+-----------------------------------+
| > ●\                              | > Компромисс между пакетным и     |
| > ●                               | > стохастическим градиентным      |
|                                   | > спускомОбновляет веса на основе |
|                                   | > небольших подвыборок данных     |
|                                   | > (мини-пакетов)                  |
+===================================+===================================+
+-----------------------------------+-----------------------------------+

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image301.png){width="6.272222222222222in"
  height="4.823611111111111in"}
  -----------------------------------------------------------------------------------------------

  -----------------------------------------------------------------------------------------------

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image302.png){width="3.238888888888889in"   ![](vertopal_c0b099a1bf474e9590819adae366c879/media/image303.png){width="2.6555555555555554in"
  height="2.5416666666666665in"}                                                                  height="2.0722222222222224in"}
  ----------------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------------------

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

![](vertopal_c0b099a1bf474e9590819adae366c879/media/image304.png){width="1.3611111111111112in"
height="0.20833333333333334in"}

jupyter notebook - Лекция 5\
**Ссылка:**

> (07.06.24) Семинар 4.4
